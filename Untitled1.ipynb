{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMX4iHTl+q9XCWMpfoyai6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00yZf8q7Ymaa","executionInfo":{"status":"ok","timestamp":1754383501367,"user_tz":-420,"elapsed":28641,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"ab1f5725-6c2c-4e0d-a590-b47a9bebd177"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” PHASE 1A: Environment Check & Cleanup\n","============================================================\n","âš ï¸  DO NOT RESTART after this cell!\n","============================================================\n","âœ… numpy 1.26.4 (good)\n","ğŸš€ Memulai setup lingkungan...\n","\n","ğŸ§¹ Membersihkan package yang konflik...\n","Found existing installation: peft 0.16.0\n","Uninstalling peft-0.16.0:\n","  Successfully uninstalled peft-0.16.0\n","Found existing installation: torchaudio 2.6.0+cu124\n","Uninstalling torchaudio-2.6.0+cu124:\n","  Successfully uninstalled torchaudio-2.6.0+cu124\n","Found existing installation: tensorflow 2.18.0\n","Uninstalling tensorflow-2.18.0:\n","  Successfully uninstalled tensorflow-2.18.0\n","\n","âœ… Environment cleanup completed!\n","\n","â¡ï¸ IMMEDIATELY run PHASE 1B (DO NOT RESTART)\n"]}],"source":["# ==============================================================================\n","# KOHYA LORA TRAINING - DENGAN RESTART GUIDANCE YANG JELAS\n","# Kode asli lo yang udah working, tapi dipecah dengan restart points\n","# ==============================================================================\n","\n","# ==============================================================================\n","# PHASE 1A: ENVIRONMENT CHECK & CLEANUP\n","# Jalankan ini pertama - DO NOT RESTART after this cell\n","# ==============================================================================\n","\n","print(\"ğŸ” PHASE 1A: Environment Check & Cleanup\")\n","print(\"=\" * 60)\n","print(\"âš ï¸  DO NOT RESTART after this cell!\")\n","print(\"=\" * 60)\n","\n","import os\n","import shutil\n","import subprocess\n","import sys\n","\n","def run_command(command, check=True):\n","    \"\"\"Jalankan command dengan error handling yang lebih baik\"\"\"\n","    try:\n","        result = subprocess.run(command, shell=True, check=check,\n","                              capture_output=True, text=True)\n","        if result.stdout:\n","            print(result.stdout)\n","        return result\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Error running command: {command}\")\n","        print(f\"Error: {e.stderr}\")\n","        if check:\n","            raise\n","        return e\n","\n","# Check numpy version first - CRITICAL CHECK\n","restart_needed = False\n","try:\n","    import numpy\n","    numpy_version = numpy.__version__\n","    if numpy_version.startswith('2.'):\n","        print(f\"âš ï¸ WARNING: numpy {numpy_version} detected (need <2.0)\")\n","        restart_needed = True\n","    else:\n","        print(f\"âœ… numpy {numpy_version} (good)\")\n","except ImportError:\n","    print(\"âš ï¸ numpy not found - will install correct version\")\n","\n","if restart_needed:\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"ğŸ”„ RESTART REQUIRED!\")\n","    print(\"Please restart runtime NOW, then run this cell again\")\n","    print(\"=\"*60)\n","    raise Exception(\"Restart runtime required due to numpy 2.x\")\n","\n","print(\"ğŸš€ Memulai setup lingkungan...\")\n","\n","# Pindah ke direktori content dan bersihkan jika ada\n","os.chdir('/content/')\n","if os.path.exists('/content/sd-scripts'):\n","    shutil.rmtree('/content/sd-scripts')\n","\n","# Clone repository\n","run_command('git clone https://github.com/kohya-ss/sd-scripts.git')\n","os.chdir('/content/sd-scripts/')\n","\n","print(\"\\nğŸ§¹ Membersihkan package yang konflik...\")\n","\n","# Uninstall conflicting packages dulu\n","run_command('pip uninstall -y peft torchaudio tensorflow', check=False)\n","\n","print(\"âœ… Environment cleanup completed!\")\n","print(\"\\nâ¡ï¸ IMMEDIATELY run PHASE 1B (DO NOT RESTART)\")"]},{"cell_type":"code","source":["# ==============================================================================\n","# PHASE 1B: CORE SYSTEM INSTALLATION\n","# Jalankan langsung setelah PHASE 1A - DO NOT RESTART after this cell\n","# ==============================================================================\n","\n","print(\"ğŸ”§ PHASE 1B: Core System Installation\")\n","print(\"=\" * 60)\n","print(\"âš ï¸ DO NOT RESTART after this cell!\")\n","print(\"=\" * 60)\n","\n","print(\"ğŸ”§ Memasang dependensi inti dengan urutan yang tepat...\")\n","\n","# Install torch dan xformers dulu - FOUNDATION PACKAGES\n","print(\"ğŸ”¥ Installing PyTorch + torchvision...\")\n","run_command('pip install torch==2.3.0 torchvision==0.18.0 --index-url https://download.pytorch.org/whl/cu121')\n","\n","print(\"âš¡ Installing xformers...\")\n","run_command('pip install xformers==0.0.26.post1 --index-url https://download.pytorch.org/whl/cu121')\n","\n","print(\"âœ… Core system installed!\")\n","print(\"\\n\" + \"=\"*60)\n","print(\"ğŸ”„ MANDATORY RESTART #1\")\n","print(\"REASON: PyTorch & xformers need to be loaded fresh\")\n","print(\"ACTION: Restart runtime NOW, then run PHASE 2A\")\n","print(\"=\"*60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZleYmH8mZHNn","executionInfo":{"status":"ok","timestamp":1754383764160,"user_tz":-420,"elapsed":253441,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"8fe7d8a3-1cf3-446f-e574-f6b9c8d354d3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”§ PHASE 1B: Core System Installation\n","============================================================\n","âš ï¸ DO NOT RESTART after this cell!\n","============================================================\n","ğŸ”§ Memasang dependensi inti dengan urutan yang tepat...\n","ğŸ”¥ Installing PyTorch + torchvision...\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch==2.3.0\n","  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp311-cp311-linux_x86_64.whl (781.0 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 781.0/781.0 MB 2.6 MB/s eta 0:00:00\n","Collecting torchvision==0.18.0\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.0/7.0 MB 50.3 MB/s eta 0:00:00\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23.7/23.7 MB 83.3 MB/s eta 0:00:00\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 823.6/823.6 kB 61.3 MB/s eta 0:00:00\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 14.1/14.1 MB 107.7 MB/s eta 0:00:00\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 731.7/731.7 MB 654.2 kB/s eta 0:00:00\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 410.6/410.6 MB 4.0 MB/s eta 0:00:00\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 121.6/121.6 MB 8.1 MB/s eta 0:00:00\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 56.5/56.5 MB 14.4 MB/s eta 0:00:00\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 124.2/124.2 MB 8.1 MB/s eta 0:00:00\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 196.0/196.0 MB 1.5 MB/s eta 0:00:00\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176.2/176.2 MB 6.7 MB/s eta 0:00:00\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99.1/99.1 kB 13.1 MB/s eta 0:00:00\n","Collecting triton==2.3.0 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 168.1/168.1 MB 6.8 MB/s eta 0:00:00\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchvision-0.18.0+cu121 triton-2.3.0\n","\n","âš¡ Installing xformers...\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting xformers==0.0.26.post1\n","  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl (222.8 MB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 222.8/222.8 MB 6.1 MB/s eta 0:00:00\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.26.post1) (1.26.4)\n","Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.26.post1) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->xformers==0.0.26.post1) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0->xformers==0.0.26.post1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0->xformers==0.0.26.post1) (1.3.0)\n","Installing collected packages: xformers\n","Successfully installed xformers-0.0.26.post1\n","\n","âœ… Core system installed!\n","\n","============================================================\n","ğŸ”„ MANDATORY RESTART #1\n","REASON: PyTorch & xformers need to be loaded fresh\n","ACTION: Restart runtime NOW, then run PHASE 2A\n","============================================================\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# PHASE 2A: ML STACK INSTALLATION (AFTER RESTART #1)\n","# Start here after first mandatory restart\n","# ==============================================================================\n","\n","import os\n","import subprocess\n","\n","def run_command(command, check=True):\n","    \"\"\"Jalankan command dengan error handling yang lebih baik\"\"\"\n","    try:\n","        result = subprocess.run(command, shell=True, check=check,\n","                              capture_output=True, text=True)\n","        if result.stdout:\n","            print(result.stdout)\n","        return result\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Error running command: {command}\")\n","        print(f\"Error: {e.stderr}\")\n","        if check:\n","            raise\n","        return e\n","\n","\n","print(\"ğŸ¤– PHASE 2A: ML Stack Installation (After Restart #1)\")\n","print(\"=\" * 60)\n","print(\"âš ï¸ This should be run AFTER restart #1\")\n","print(\"âš ï¸ DO NOT RESTART after this cell!\")\n","print(\"=\" * 60)\n","\n","# Verify core dependencies are properly loaded\n","try:\n","    import torch\n","    print(f\"âœ… PyTorch: {torch.__version__}\")\n","    if torch.cuda.is_available():\n","        print(f\"âœ… CUDA: {torch.cuda.get_device_name(0)}\")\n","    else:\n","        raise Exception(\"CUDA not available\")\n","except ImportError as e:\n","    print(\"âŒ Core dependencies not found after restart!\")\n","    print(\"Please run PHASE 1A and 1B again, then restart\")\n","    raise Exception(f\"Import error: {e}\")\n","\n","# Make sure we're in the right directory\n","os.chdir('/content/sd-scripts/')\n","\n","print(\"\\nğŸ“¦ Installing ML stack in correct order...\")\n","\n","# Install dependencies satu per satu untuk kontrol yang lebih baik\n","# URUTAN INI PENTING - jangan diubah!\n","ml_dependencies = [\n","    'accelerate==0.30.0',\n","    'transformers==4.44.0',\n","    'diffusers[torch]==0.25.0',\n","    'bitsandbytes==0.44.0',\n","    'safetensors==0.4.2',\n","    'huggingface_hub>=0.28.1' # Keep your original version requirement\n","]\n","\n","for dep in ml_dependencies:\n","    print(f\" Installing {dep}...\")\n","    result = run_command(f'pip install {dep}')\n","    if result.returncode != 0:\n","        raise Exception(f\"Failed to install {dep}\")\n","\n","print(\"âœ… ML stack installation completed!\")\n","print(\"\\nâ¡ï¸ IMMEDIATELY run PHASE 2B (DO NOT RESTART)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCknykPwZNbm","executionInfo":{"status":"ok","timestamp":1754383921063,"user_tz":-420,"elapsed":34652,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"5edd27d6-4ce0-4edc-fc12-c37d5afd88f2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ¤– PHASE 2A: ML Stack Installation (After Restart #1)\n","============================================================\n","âš ï¸ This should be run AFTER restart #1\n","âš ï¸ DO NOT RESTART after this cell!\n","============================================================\n","âœ… PyTorch: 2.3.0+cu121\n","âœ… CUDA: Tesla T4\n","\n","ğŸ“¦ Installing ML stack in correct order...\n"," Installing accelerate==0.30.0...\n","Collecting accelerate==0.30.0\n","  Downloading accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (6.0.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (0.34.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.30.0) (12.5.82)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.0) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.0) (1.1.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.30.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2025.7.14)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==0.30.0) (1.3.0)\n","Downloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n","   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 302.4/302.4 kB 21.7 MB/s eta 0:00:00\n","Installing collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.9.0\n","    Uninstalling accelerate-1.9.0:\n","      Successfully uninstalled accelerate-1.9.0\n","Successfully installed accelerate-0.30.0\n","\n"," Installing transformers==4.44.0...\n","Collecting transformers==4.44.0\n","  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 43.7/43.7 kB 4.6 MB/s eta 0:00:00\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (0.34.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (0.5.3)\n","Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.0)\n","  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (2025.7.14)\n","Downloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n","   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.5/9.5 MB 111.9 MB/s eta 0:00:00\n","Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 117.6 MB/s eta 0:00:00\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.2\n","    Uninstalling tokenizers-0.21.2:\n","      Successfully uninstalled tokenizers-0.21.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.54.0\n","    Uninstalling transformers-4.54.0:\n","      Successfully uninstalled transformers-4.54.0\n","Successfully installed tokenizers-0.19.1 transformers-4.44.0\n","\n"," Installing diffusers[torch]==0.25.0...\n","Collecting diffusers==0.25.0 (from diffusers[torch]==0.25.0)\n","  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (8.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (3.18.0)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (0.34.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (0.5.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (11.3.0)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.25.0) (2.3.0+cu121)\n","Requirement already satisfied: accelerate>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.25.0) (0.30.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (6.0.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (2025.3.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (1.1.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->diffusers[torch]==0.25.0) (12.5.82)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.23.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4->diffusers[torch]==0.25.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.4->diffusers[torch]==0.25.0) (1.3.0)\n","Downloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n","   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.8/1.8 MB 76.1 MB/s eta 0:00:00\n","Installing collected packages: diffusers\n","  Attempting uninstall: diffusers\n","    Found existing installation: diffusers 0.34.0\n","    Uninstalling diffusers-0.34.0:\n","      Successfully uninstalled diffusers-0.34.0\n","Successfully installed diffusers-0.25.0\n","\n"," Installing bitsandbytes==0.44.0...\n","Collecting bitsandbytes==0.44.0\n","  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.44.0) (2.3.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.44.0) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.44.0) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes==0.44.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->bitsandbytes==0.44.0) (1.3.0)\n","Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 122.4/122.4 MB 8.7 MB/s eta 0:00:00\n","Installing collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.44.0\n","\n"," Installing safetensors==0.4.2...\n","Collecting safetensors==0.4.2\n","  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.3/1.3 MB 56.9 MB/s eta 0:00:00\n","Installing collected packages: safetensors\n","  Attempting uninstall: safetensors\n","    Found existing installation: safetensors 0.5.3\n","    Uninstalling safetensors-0.5.3:\n","      Successfully uninstalled safetensors-0.5.3\n","Successfully installed safetensors-0.4.2\n","\n"," Installing huggingface_hub>=0.28.1...\n","âœ… ML stack installation completed!\n","\n","â¡ï¸ IMMEDIATELY run PHASE 2B (DO NOT RESTART)\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# PHASE 2B: UTILITIES & KOHYA SETUP\n","# Jalankan langsung setelah PHASE 2A - DO NOT RESTART after this cell\n","# ==============================================================================\n","import subprocess\n","import os\n","\n","print(\"ğŸ› ï¸ PHASE 2B: Utilities & Kohya Setup\")\n","print(\"=\" * 60)\n","print(\"âš ï¸ DO NOT RESTART after this cell!\")\n","print(\"=\" * 60)\n","\n","print(\"ğŸ“¦ Installing utility packages...\")\n","\n","\n","def run_command(command, check=True):\n","    \"\"\"Jalankan command dengan error handling yang lebih baik\"\"\"\n","    try:\n","        result = subprocess.run(command, shell=True, check=check,\n","                              capture_output=True, text=True)\n","        if result.stdout:\n","            print(result.stdout)\n","        return result\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Error running command: {command}\")\n","        print(f\"Error: {e.stderr}\")\n","        if check:\n","            raise\n","        return e\n","\n","# Install utility packages\n","utility_dependencies = [\n","    'lion-pytorch==0.0.6',\n","    'prodigyopt==1.0',\n","    'opencv-python==4.8.1.78',\n","    'einops==0.7.0',\n","    'ftfy==6.1.1',\n","    'tensorboard',\n","    'rich==13.7.0',\n","    'imagesize==1.4.1',\n","    'toml==0.10.2',\n","    'voluptuous==0.13.1'\n","]\n","\n","for dep in utility_dependencies:\n","    print(f\" Installing {dep}...\")\n","    result = run_command(f'pip install {dep}', check=False)\n","    if result.returncode != 0:\n","        print(f\"âš ï¸ Warning: Failed to install {dep}, continuing...\")\n","\n","os.chdir('/content/sd-scripts/')\n","\n","# Install package dalam editable mode\n","print(\"\\nâš™ï¸ Installing kohya-ss in editable mode...\")\n","result = run_command('pip install -e .')\n","if result.returncode != 0:\n","    raise Exception(\"Kohya-ss installation failed\")\n","\n","print(\"âœ… Utilities & Kohya setup completed!\")\n","print(\"\\n\" + \"=\"*60)\n","print(\"ğŸ”„ MANDATORY RESTART #2\")\n","print(\"REASON: All ML packages need fresh import for compatibility\")\n","print(\"ACTION: Restart runtime NOW, then run PHASE 3A\")\n","print(\"=\"*60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1l9-UC4rZR8_","executionInfo":{"status":"ok","timestamp":1754384178301,"user_tz":-420,"elapsed":28505,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"5eb508a3-7ee2-42a5-cae3-e3427e08f10b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ› ï¸ PHASE 2B: Utilities & Kohya Setup\n","============================================================\n","âš ï¸ DO NOT RESTART after this cell!\n","============================================================\n","ğŸ“¦ Installing utility packages...\n"," Installing lion-pytorch==0.0.6...\n","Requirement already satisfied: lion-pytorch==0.0.6 in /usr/local/lib/python3.11/dist-packages (0.0.6)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from lion-pytorch==0.0.6) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->lion-pytorch==0.0.6) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6->lion-pytorch==0.0.6) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.6->lion-pytorch==0.0.6) (1.3.0)\n","\n"," Installing prodigyopt==1.0...\n","Requirement already satisfied: prodigyopt==1.0 in /usr/local/lib/python3.11/dist-packages (1.0)\n","\n"," Installing opencv-python==4.8.1.78...\n","Requirement already satisfied: opencv-python==4.8.1.78 in /usr/local/lib/python3.11/dist-packages (4.8.1.78)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python==4.8.1.78) (1.26.4)\n","\n"," Installing einops==0.7.0...\n","Requirement already satisfied: einops==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n","\n"," Installing ftfy==6.1.1...\n","Requirement already satisfied: ftfy==6.1.1 in /usr/local/lib/python3.11/dist-packages (6.1.1)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy==6.1.1) (0.2.13)\n","\n"," Installing tensorboard...\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.74.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (25.0)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","\n"," Installing rich==13.7.0...\n","Requirement already satisfied: rich==13.7.0 in /usr/local/lib/python3.11/dist-packages (13.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.0) (0.1.2)\n","\n"," Installing imagesize==1.4.1...\n","Requirement already satisfied: imagesize==1.4.1 in /usr/local/lib/python3.11/dist-packages (1.4.1)\n","\n"," Installing toml==0.10.2...\n","Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.11/dist-packages (0.10.2)\n","\n"," Installing voluptuous==0.13.1...\n","Requirement already satisfied: voluptuous==0.13.1 in /usr/local/lib/python3.11/dist-packages (0.13.1)\n","\n","\n","âš™ï¸ Installing kohya-ss in editable mode...\n","Obtaining file:///content/sd-scripts\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Installing collected packages: library\n","  Running setup.py develop for library\n","Successfully installed library-0.0.0\n","\n","âœ… Utilities & Kohya setup completed!\n","\n","============================================================\n","ğŸ”„ MANDATORY RESTART #2\n","REASON: All ML packages need fresh import for compatibility\n","ACTION: Restart runtime NOW, then run PHASE 3A\n","============================================================\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# PHASE 3A: CONFIGURATION & VALIDATION (AFTER RESTART #2)\n","# Start here after second mandatory restart\n","# ==============================================================================\n","import os\n","import subprocess\n","import sys\n","\n","print(\"âš™ï¸ PHASE 3A: Configuration & Validation (After Restart #2)\")\n","print(\"=\" * 60)\n","print(\"âš ï¸ This should be run AFTER restart #2\")\n","print(\"âš ï¸ DO NOT RESTART after this cell!\")\n","print(\"=\" * 60)\n","\n","# Make sure we're in the right directory\n","os.chdir('/content/sd-scripts/')\n","\n","# Configure Accelerate\n","print(\"âš™ï¸ Mengkonfigurasi accelerate...\")\n","\n","accelerate_config = \"\"\"compute_environment: LOCAL_MACHINE\n","deepspeed_config: {}\n","distributed_type: 'NO'\n","downcast_bf16: 'no'\n","gpu_ids: all\n","machine_rank: 0\n","main_training_function: main\n","mixed_precision: fp16\n","num_machines: 1\n","num_processes: 1\n","rdzv_backend: static\n","same_network: true\n","tpu_env: []\n","tpu_use_cluster: false\n","tpu_use_sudo: false\n","use_cpu: false\n","\"\"\"\n","\n","# Simpan konfigurasi\n","os.makedirs(os.path.expanduser('~/.cache/huggingface/accelerate'), exist_ok=True)\n","with open(os.path.expanduser('~/.cache/huggingface/accelerate/default_config.yaml'), 'w') as f:\n","    f.write(accelerate_config)\n","\n","print(\"âœ… Accelerate dikonfigurasi\")\n","\n","# Mount Google Drive\n","print(\"\\nğŸ”— Menghubungkan ke Google Drive...\")\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    print(\"âœ… Google Drive mounted!\")\n","except Exception as e:\n","    raise Exception(f\"Drive mount failed: {e}\")\n","\n","# CRITICAL: Full validation with fresh imports\n","print(\"\\nğŸ” Validating installation with fresh imports...\")\n","\n","# Test import critical modules\n","validation_success = True\n","try:\n","    import torch\n","    import transformers\n","    import diffusers\n","    import accelerate\n","    import huggingface_hub\n","    import bitsandbytes\n","    import safetensors\n","\n","    print(f\"âœ… PyTorch: {torch.__version__}\")\n","    print(f\"âœ… Transformers: {transformers.__version__}\")\n","    print(f\"âœ… Diffusers: {diffusers.__version__}\")\n","    print(f\"âœ… Accelerate: {accelerate.__version__}\")\n","    print(f\"âœ… HuggingFace Hub: {huggingface_hub.__version__}\")\n","    print(f\"âœ… BitsAndBytes: {bitsandbytes.__version__}\")\n","    print(f\"âœ… SafeTensors: {safetensors.__version__}\")\n","    print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n","\n","    if torch.cuda.is_available():\n","        print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n","        print(f\"âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n","    else:\n","        print(\"âŒ CUDA not available\")\n","        validation_success = False\n","\n","except ImportError as e:\n","    print(f\"âŒ Import error: {e}\")\n","    validation_success = False\n","\n","# Test critical functionality that was causing problems\n","print(\"\\nğŸ¯ Testing problematic imports...\")\n","try:\n","    from huggingface_hub import cached_download\n","    print(\"âœ… huggingface_hub.cached_download: OK\")\n","except ImportError as e:\n","    print(f\"âŒ huggingface_hub.cached_download: FAILED - {str(e)}\")\n","    validation_success = False\n","\n","try:\n","    from diffusers import DDPMScheduler\n","    print(\"âœ… diffusers.DDPMScheduler: OK\")\n","except ImportError as e:\n","    print(f\"âŒ diffusers.DDPMScheduler: FAILED - {str(e)}\")\n","    validation_success = False\n","\n","if not validation_success:\n","    print(f\"\\nâŒ VALIDATION FAILED!\")\n","    print(\"TROUBLESHOOTING:\")\n","    print(\"1. Restart runtime\")\n","    print(\"2. Run PHASE 1A â†’ PHASE 1B â†’ Restart #1\")\n","    print(\"3. Run PHASE 2A â†’ PHASE 2B â†’ Restart #2\")\n","    print(\"4. Run this PHASE 3A again\")\n","    raise Exception(\"Validation failed\")\n","\n","print(\"\\nğŸ‰ VALIDATION SUCCESS!\")\n","print(\"All systems operational! Ready for training!\")\n","print(\"\\nâ¡ï¸ IMMEDIATELY run PHASE 3B for functions setup\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"859sao9AZXeb","executionInfo":{"status":"ok","timestamp":1754384564974,"user_tz":-420,"elapsed":7870,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"34a58f92-2696-4f34-f501-7a2ee72cbaca"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["âš™ï¸ PHASE 3A: Configuration & Validation (After Restart #2)\n","============================================================\n","âš ï¸ This should be run AFTER restart #2\n","âš ï¸ DO NOT RESTART after this cell!\n","============================================================\n","âš™ï¸ Mengkonfigurasi accelerate...\n","âœ… Accelerate dikonfigurasi\n","\n","ğŸ”— Menghubungkan ke Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","âœ… Google Drive mounted!\n","\n","ğŸ” Validating installation with fresh imports...\n","âœ… PyTorch: 2.3.0+cu121\n","âœ… Transformers: 4.44.0\n","âœ… Diffusers: 0.25.0\n","âœ… Accelerate: 0.30.0\n","âœ… HuggingFace Hub: 0.24.5\n","âœ… BitsAndBytes: 0.44.0\n","âœ… SafeTensors: 0.4.2\n","âœ… CUDA available: True\n","âœ… GPU: Tesla T4\n","âœ… VRAM: 14.7 GB\n","\n","ğŸ¯ Testing problematic imports...\n","âœ… huggingface_hub.cached_download: OK\n","âœ… diffusers.DDPMScheduler: OK\n","\n","ğŸ‰ VALIDATION SUCCESS!\n","All systems operational! Ready for training!\n","\n","â¡ï¸ IMMEDIATELY run PHASE 3B for functions setup\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n"]}]},{"cell_type":"code","source":["!pip uninstall huggingface_hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHQ8uG2JdieI","executionInfo":{"status":"ok","timestamp":1754384463559,"user_tz":-420,"elapsed":4572,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"12952f4c-b283-41aa-92df-2eebec500117"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: huggingface-hub 0.34.1\n","Uninstalling huggingface-hub-0.34.1:\n","  Would remove:\n","    /usr/local/bin/hf\n","    /usr/local/bin/huggingface-cli\n","    /usr/local/bin/tiny-agents\n","    /usr/local/lib/python3.11/dist-packages/huggingface_hub-0.34.1.dist-info/*\n","    /usr/local/lib/python3.11/dist-packages/huggingface_hub/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled huggingface-hub-0.34.1\n"]}]},{"cell_type":"code","source":["!pip install \"huggingface-hub==0.24.5\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":533},"id":"Rrv_x3bQdoLJ","executionInfo":{"status":"ok","timestamp":1754384514198,"user_tz":-420,"elapsed":5059,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"e2c6a32d-7ab2-4819-f150-3891c5ed2a87"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting huggingface-hub==0.24.5\n","  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (4.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (2025.7.14)\n","Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n","\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/417.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: huggingface-hub\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gradio 5.38.2 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.24.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.24.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["huggingface_hub"]},"id":"aa0f4ac3672b4b45ba169f39ca758a0b"}},"metadata":{}}]},{"cell_type":"code","source":["# ==============================================================================\n","# PHASE 3B: TRAINING FUNCTIONS SETUP\n","# Jalankan langsung setelah PHASE 3A - NO RESTART needed\n","# ==============================================================================\n","\n","\n","print(\"ğŸ”§ PHASE 3B: Training Functions Setup\")\n","print(\"=\" * 60)\n","print(\"âš ï¸ NO RESTART needed after this cell\")\n","print(\"=\" * 60)\n","\n","\n","# Parameter default training yang bisa dioverride\n","default_params = {\n","    'network_dim': 64,\n","    'network_alpha': 32,\n","    'resolution': '512,512',\n","    'train_batch_size': 1,\n","    'max_train_epochs': 10,\n","    'learning_rate': 2e-4,\n","    'lr_scheduler': 'constant',\n","    'lr_warmup_steps': 0,\n","    'save_model_as': 'safetensors',\n","    'mixed_precision': 'fp16',\n","    'gradient_checkpointing': True,\n","    'save_every_n_epochs': 1,\n","    'sample_every_n_steps': 100,\n","}\n","\n","def setup_training_paths(project_name, instance_name=None, class_name=\"person\", repeats=10):\n","    \"\"\"Setup path training dengan validasi dan penamaan folder yang tepat\"\"\"\n","    base_model_path = \"/content/drive/MyDrive/AI/models/stable-diffusion-v1-5-fp16\"\n","    project_folder = f\"/content/drive/MyDrive/AI/training/{project_name}\"\n","\n","    # Gunakan project_name sebagai instance_name jika tidak dispesifikasi\n","    if instance_name is None:\n","        instance_name = project_name.lower().replace(\"_\", \"\").replace(\"-\", \"\")\n","\n","    # Format folder DreamBooth yang benar\n","    dreambooth_folder_name = f\"{repeats}_{instance_name}_{class_name}\"\n","\n","    paths = {\n","        'base_model': base_model_path,\n","        'project_folder': project_folder,\n","        'train_data_dir': project_folder, # Root project folder untuk DreamBooth\n","        'images_folder': f\"{project_folder}/images\",\n","        'output_dir': f\"{project_folder}/model\",\n","        'logging_dir': f\"{project_folder}/log\",\n","        'dreambooth_folder': os.path.join(project_folder, dreambooth_folder_name), # Langsung di root\n","        'instance_name': instance_name,\n","        'class_name': class_name,\n","        'repeats': repeats\n","    }\n","\n","    # Validasi base model\n","    if not os.path.exists(paths['base_model']):\n","        print(f\"âŒ Base model tidak ditemukan: {paths['base_model']}\")\n","        print(\"Pastikan model Stable Diffusion 1.5 sudah ada di Drive\")\n","        return None\n","\n","    # Cek struktur folder dan perbaiki jika perlu\n","    images_folder = paths['images_folder']\n","\n","    # Cek apakah menggunakan struktur DreamBooth atau dataset biasa\n","    image_extensions = ('.jpg', '.jpeg', '.png', '.webp', '.bmp')\n","\n","    # Cek gambar langsung di folder images\n","    direct_images = []\n","    if os.path.exists(images_folder):\n","        for file in os.listdir(images_folder):\n","            if file.lower().endswith(image_extensions):\n","                direct_images.append(file)\n","\n","    # Cek subfolder DreamBooth yang sudah ada di root project\n","    existing_dreambooth_folders = []\n","    if os.path.exists(paths['project_folder']):\n","        for item in os.listdir(paths['project_folder']):\n","            item_path = os.path.join(paths['project_folder'], item)\n","            if os.path.isdir(item_path) and '_' in item:\n","                # Cek format DreamBooth: number_name_class\n","                parts = item.split('_')\n","                if len(parts) >= 3 and parts[0].isdigit():\n","                    # Cek apakah folder berisi gambar\n","                    subfolder_images = [f for f in os.listdir(item_path)\n","                                      if f.lower().endswith(image_extensions)]\n","                    if subfolder_images:\n","                        existing_dreambooth_folders.append((item, len(subfolder_images)))\n","\n","    print(f\"ğŸ“Š Ditemukan {len(direct_images)} gambar di folder images\")\n","    print(f\"ğŸ“ Ditemukan {len(existing_dreambooth_folders)} folder DreamBooth yang sudah ada\")\n","\n","    # Jika ada gambar di folder images, pindahkan ke struktur DreamBooth\n","    if direct_images:\n","        print(f\"ğŸ”„ Membuat folder DreamBooth: {dreambooth_folder_name}\")\n","        os.makedirs(paths['dreambooth_folder'], exist_ok=True)\n","\n","        # Pindahkan semua gambar ke folder DreamBooth di root project\n","        moved_count = 0\n","        for img_file in direct_images:\n","            src = os.path.join(images_folder, img_file)\n","            dst = os.path.join(paths['dreambooth_folder'], img_file)\n","            if not os.path.exists(dst): # Hindari overwrite\n","                shutil.move(src, dst)\n","                moved_count += 1\n","\n","            # Cek dan pindahkan caption file jika ada\n","            caption_file = os.path.splitext(img_file)[0] + '.txt'\n","            src_caption = os.path.join(images_folder, caption_file)\n","            dst_caption = os.path.join(paths['dreambooth_folder'], caption_file)\n","            if os.path.exists(src_caption) and not os.path.exists(dst_caption):\n","                shutil.move(src_caption, dst_caption)\n","\n","        print(f\"âœ… Dipindahkan {moved_count} gambar ke {paths['dreambooth_folder']}\")\n","        existing_dreambooth_folders.append((dreambooth_folder_name, moved_count))\n","\n","    # Hitung total gambar dari semua folder DreamBooth\n","    total_images = sum(count for _, count in existing_dreambooth_folders)\n","\n","    if total_images == 0:\n","        print(\"âŒ Tidak ada gambar training yang ditemukan\")\n","        print(\"ğŸ’¡ Struktur folder yang benar:\")\n","        print(f\" ğŸ“ {project_name}/\")\n","        print(f\" â”œâ”€â”€ ğŸ“ {dreambooth_folder_name}/\")\n","        print(\" â”‚ â”œâ”€â”€ ğŸ–¼ï¸ image1.jpg\")\n","        print(\" â”‚ â”œâ”€â”€ ğŸ“ image1.txt (opsional)\")\n","        print(\" â”‚ â””â”€â”€ ...\")\n","        print(f\" â”œâ”€â”€ ğŸ“ model/ (output)\")\n","        print(f\" â””â”€â”€ ğŸ“ log/ (logging)\")\n","        print(f\"\\nğŸ¯ Instance name: '{instance_name}' (trigger word untuk memanggil LoRA)\")\n","        print(f\"ğŸ¯ Class name: '{class_name}' (kategori umum)\")\n","        print(f\"ğŸ¯ Repeats: {repeats}x per epoch\")\n","        return None\n","\n","    print(f\"âœ… Total {total_images} gambar siap untuk training\")\n","    print(f\"ğŸ¯ Instance name: '{instance_name}' (gunakan ini sebagai trigger word)\")\n","    print(f\"ğŸ¯ Class name: '{class_name}'\")\n","    print(f\"ğŸ¯ Repeats: {repeats}x per epoch\")\n","    print(f\"ğŸ“ Folder training: {dreambooth_folder_name}\")\n","\n","    # Validasi caption files\n","    print(\"\\nğŸ” Memvalidasi caption files...\")\n","    validate_caption_files(paths['dreambooth_folder'])\n","\n","    # Buat direktori output\n","    os.makedirs(paths['output_dir'], exist_ok=True)\n","    os.makedirs(paths['logging_dir'], exist_ok=True)\n","\n","    return paths\n","\n","def validate_caption_files(dreambooth_folder):\n","    \"\"\"Validasi dan perbaiki caption files\"\"\"\n","    if not os.path.exists(dreambooth_folder):\n","        print(f\"âŒ Folder tidak ditemukan: {dreambooth_folder}\")\n","        return False\n","\n","    image_extensions = ('.jpg', '.jpeg', '.png', '.webp', '.bmp')\n","    images = [f for f in os.listdir(dreambooth_folder) if f.lower().endswith(image_extensions)]\n","\n","    caption_count = 0\n","    missing_captions = []\n","\n","    for img_file in images:\n","        base_name = os.path.splitext(img_file)[0]\n","        txt_file = f\"{base_name}.txt\"\n","        txt_path = os.path.join(dreambooth_folder, txt_file)\n","\n","        if os.path.exists(txt_path):\n","            caption_count += 1\n","            # Cek isi caption\n","            with open(txt_path, 'r', encoding='utf-8') as f:\n","                content = f.read().strip()\n","                if not content:\n","                    print(f\"âš ï¸ Caption kosong: {txt_file}\")\n","        else:\n","            missing_captions.append(img_file)\n","\n","    print(f\"ğŸ“ Caption files ditemukan: {caption_count}/{len(images)}\")\n","\n","    if missing_captions:\n","        print(f\"âš ï¸ Missing caption files untuk:\")\n","        for img in missing_captions[:5]: # Show first 5\n","            print(f\" - {img}\")\n","        if len(missing_captions) > 5:\n","            print(f\" ... dan {len(missing_captions) - 5} lainnya\")\n","\n","        # Auto-generate missing captions\n","        print(\"ğŸ”„ Membuat caption files yang hilang...\")\n","        for img_file in missing_captions:\n","            base_name = os.path.splitext(img_file)[0]\n","            txt_file = f\"{base_name}.txt\"\n","            txt_path = os.path.join(dreambooth_folder, txt_file)\n","\n","            # Default caption berdasarkan folder name\n","            folder_name = os.path.basename(dreambooth_folder)\n","            parts = folder_name.split('_')\n","            if len(parts) >= 3:\n","                instance_name = parts[1]\n","                class_name = parts[2]\n","                default_caption = f\"a photo of {instance_name} {class_name}, high quality\"\n","            else:\n","                default_caption = \"a high quality photo\"\n","\n","            with open(txt_path, 'w', encoding='utf-8') as f:\n","                f.write(default_caption)\n","\n","            print(f\" âœ… Dibuat: {txt_file} -> '{default_caption}'\")\n","\n","    return True\n","\n","def start_training(project_name, instance_name=None, class_name=\"person\", repeats=10, **kwargs):\n","    \"\"\"Mulai training dengan parameter yang lebih optimal\"\"\"\n","\n","    # Make sure we're in the right directory\n","    os.chdir('/content/sd-scripts/')\n","\n","    # Setup paths\n","    paths = setup_training_paths(project_name, instance_name, class_name, repeats)\n","    if not paths:\n","        return False\n","\n","    # Parameter default yang sudah dioptimalkan\n","    default_params.update(kwargs)\n","\n","    # Build command dengan handling boolean yang benar\n","    cmd_parts = [\n","        'python', 'train_network.py',\n","        f'--pretrained_model_name_or_path=\"{paths[\"base_model\"]}\"',\n","        f'--train_data_dir=\"{paths[\"train_data_dir\"]}\"',  # Project folder untuk DreamBooth\n","        f'--output_dir=\"{paths[\"output_dir\"]}\"',\n","        f'--logging_dir=\"{paths[\"logging_dir\"]}\"',\n","        f'--output_name=\"{project_name}\"',\n","        '--network_module=networks.lora',\n","        '--enable_bucket',\n","        '--cache_latents',\n","        '--cache_latents_to_disk',\n","        '--caption_extension=.txt',  # PERBAIKAN: Gunakan .txt bukan .caption\n","        '--shuffle_caption',\n","        '--keep_tokens=1',\n","        '--bucket_reso_steps=64',\n","        '--console_log_simple',  # Penting untuk Colab\n","        '--xformers'  # Untuk memory efficiency\n","    ]\n","\n","    # Tambahkan parameter dengan handling khusus untuk boolean\n","    for key, value in default_params.items():\n","        if isinstance(value, bool):\n","            if value:\n","                cmd_parts.append(f'--{key}')\n","            # Boolean False tidak perlu ditambahkan ke command\n","        else:\n","            cmd_parts.append(f'--{key}={value}')\n","\n","    # Gabungkan command\n","    command = ' '.join(cmd_parts)\n","\n","    print(f\"\\nğŸ”¥ Memulai pelatihan untuk '{project_name}'...\")\n","    print(f\"ğŸ“ Command: {command[:100]}...\")\n","\n","    try:\n","        # Jalankan training\n","        process = subprocess.Popen(\n","            command,\n","            shell=True,\n","            stdout=subprocess.PIPE,\n","            stderr=subprocess.STDOUT,\n","            universal_newlines=True,\n","            bufsize=1\n","        )\n","\n","        # Stream output real-time\n","        for line in iter(process.stdout.readline, ''):\n","            print(line.strip())\n","\n","        process.wait()\n","\n","        if process.returncode == 0:\n","            print(\"\\nğŸ‰ Training selesai dengan sukses!\")\n","            return True\n","        else:\n","            print(f\"\\nâŒ Training gagal dengan return code: {process.returncode}\")\n","            return False\n","\n","    except Exception as e:\n","        print(f\"\\nâŒ Error saat training: {e}\")\n","        return False\n","\n","def quick_test_training(project_name, instance_name=None, class_name=\"person\", repeats=10):\n","    \"\"\"Test training dengan parameter minimal untuk debugging\"\"\"\n","\n","    # Make sure we're in the right directory\n","    os.chdir('/content/sd-scripts/')\n","\n","    paths = setup_training_paths(project_name, instance_name, class_name, repeats)\n","    if not paths:\n","        return False\n","\n","    # Command yang sangat sederhana untuk test - menggunakan project folder sebagai train_data_dir\n","    cmd_parts = [\n","        'python', 'train_network.py',\n","        f'--pretrained_model_name_or_path={paths[\"base_model\"]}',\n","        f'--train_data_dir={paths[\"train_data_dir\"]}',  # Project folder yang berisi folder DreamBooth\n","        f'--output_dir={paths[\"output_dir\"]}',\n","        f'--output_name={project_name}',\n","        '--network_module=networks.lora',\n","        '--dr\n","        '--mixed_precision=fp16',\n","        '--save_model_as=safetensors',\n","        '--caption_extension=.txt',  # PERBAIKAN: Gunakan .txt\n","        '--enable_bucket',\n","        '--console_log_simple'\n","    ]\n","\n","    command = ' '.join(cmd_parts)\n","\n","    print(f\"\\nğŸ§ª Menjalankan test training untuk '{project_name}'...\")\n","    print(f\"ğŸ¯ Trigger word: '{paths['instance_name']}'\")\n","    print(f\"ğŸ“ Training data path: {paths['train_data_dir']}\")\n","    print(f\"ğŸ“ Command: {command}\")\n","\n","    try:\n","        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=1800)  # 30 menit timeout\n","\n","        print(\"STDOUT:\")\n","        print(result.stdout)\n","\n","        if result.stderr:\n","            print(\"STDERR:\")\n","            print(result.stderr)\n","\n","        if result.returncode == 0:\n","            print(\"\\nğŸ‰ Test training berhasil!\")\n","            print(f\"ğŸ’¡ Untuk generate gambar, gunakan prompt: '{paths['instance_name']} {paths['class_name']}'\")\n","            return True\n","        else:\n","            print(f\"\\nâŒ Test training gagal dengan return code: {result.returncode}\")\n","            return False\n","\n","    except subprocess.TimeoutExpired:\n","        print(\"\\nâ° Training timeout (30 menit)\")\n","        return False\n","    except Exception as e:\n","        print(f\"\\nâŒ Error: {e}\")\n","        return False\n","\n","print(\"âœ… Training functions setup completed!\")\n","print(\"\\nâ¡ï¸ Now you can run training anytime (NO RESTART needed)\")\n","\n","# ==============================================================================\n","# PHASE 4: TRAINING EXECUTION (NO RESTART NEEDED)\n","# Run this anytime after Phase 3 completion\n","# ==============================================================================\n","\n","print(\"\"\"\n","ğŸ¯ TRAINING EXECUTION - NO RESTART NEEDED\n","\n","USAGE EXAMPLES:\n","\n","1. Full training:\n","   start_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\", repeats=10)\n","\n","2. Quick test (1 epoch):\n","   quick_test_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\")\n","\n","3. Custom parameters:\n","   start_training(\"MyProject\",\n","                 instance_name=\"mychar\",\n","                 max_train_epochs=15,\n","                 learning_rate=5e-5,\n","                 network_dim=64)\n","\n","ğŸ¯ PANDUAN PENAMAAN FOLDER DREAMBOOTH:\n","\n","Format: [repeats]_[instance_name]_[class_name]\n","\n","ğŸ“– CONTOH PENAMAAN:\n","1. Untuk karakter \"Rezcty\": 10_rezcty_person\n","2. Untuk karakter anime \"Sakura\": 15_sakura_girl\n","3. Untuk objek mobil: 20_mycar_car\n","4. Untuk hewan \"Fluffy\": 12_fluffy_cat\n","\n","ğŸ’¡ TIPS:\n","- Instance name = trigger word untuk memanggil LoRA\n","- Gunakan nama unik, hindari kata umum\n","- Semakin sedikit gambar â†’ repeats lebih tinggi\n","- 5-10 gambar = 15-20 repeats\n","- 10-20 gambar = 10-15 repeats\n","- 20+ gambar = 5-10 repeats\n","\n","ğŸ“ STRUKTUR FOLDER AKHIR:\n","/content/drive/MyDrive/AI/training/Rezcty_project/\n","â””â”€â”€ 10_rezcty_person/\n","    â”œâ”€â”€ photo1.jpg\n","    â”œâ”€â”€ photo1.txt (auto-generated if missing)\n","    â””â”€â”€ ...\n","\"\"\")\n","\n","# =============================================================================="],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvNLPLn5Zb30","executionInfo":{"status":"ok","timestamp":1754385278353,"user_tz":-420,"elapsed":59,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"b08e388b-e376-4dc3-d476-91f284b62479"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”§ PHASE 3B: Training Functions Setup\n","============================================================\n","âš ï¸ NO RESTART needed after this cell\n","============================================================\n","âœ… Training functions setup completed!\n","\n","â¡ï¸ Now you can run training anytime (NO RESTART needed)\n","\n","ğŸ¯ TRAINING EXECUTION - NO RESTART NEEDED\n","\n","USAGE EXAMPLES:\n","\n","1. Full training:\n","   start_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\", repeats=10)\n","\n","2. Quick test (1 epoch):\n","   quick_test_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\")\n","\n","3. Custom parameters:\n","   start_training(\"MyProject\", \n","                 instance_name=\"mychar\",\n","                 max_train_epochs=15, \n","                 learning_rate=5e-5,\n","                 network_dim=64)\n","\n","ğŸ¯ PANDUAN PENAMAAN FOLDER DREAMBOOTH:\n","\n","Format: [repeats]_[instance_name]_[class_name]\n","\n","ğŸ“– CONTOH PENAMAAN:\n","1. Untuk karakter \"Rezcty\": 10_rezcty_person\n","2. Untuk karakter anime \"Sakura\": 15_sakura_girl  \n","3. Untuk objek mobil: 20_mycar_car\n","4. Untuk hewan \"Fluffy\": 12_fluffy_cat\n","\n","ğŸ’¡ TIPS:\n","- Instance name = trigger word untuk memanggil LoRA\n","- Gunakan nama unik, hindari kata umum\n","- Semakin sedikit gambar â†’ repeats lebih tinggi\n","- 5-10 gambar = 15-20 repeats\n","- 10-20 gambar = 10-15 repeats  \n","- 20+ gambar = 5-10 repeats\n","\n","ğŸ“ STRUKTUR FOLDER AKHIR:\n","/content/drive/MyDrive/AI/training/Rezcty_project/\n","â””â”€â”€ 10_rezcty_person/\n","    â”œâ”€â”€ photo1.jpg\n","    â”œâ”€â”€ photo1.txt (auto-generated if missing)\n","    â””â”€â”€ ...\n","\n"]}]},{"cell_type":"code","source":["import shutil"],"metadata":{"id":"JnCj3IalfPY7","executionInfo":{"status":"ok","timestamp":1754384894071,"user_tz":-420,"elapsed":43,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["start_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"view\", repeats=20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"KEt5B2_ge251","executionInfo":{"status":"ok","timestamp":1754388227653,"user_tz":-420,"elapsed":1135012,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"7cc22720-4791-40cd-8300-58ebc59f0395"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“Š Ditemukan 10 gambar di folder images\n","ğŸ“ Ditemukan 0 folder DreamBooth yang sudah ada\n","ğŸ”„ Membuat folder DreamBooth: 20_rezcty_view\n","âœ… Dipindahkan 10 gambar ke /content/drive/MyDrive/AI/training/Rezcty_project/20_rezcty_view\n","âœ… Total 10 gambar siap untuk training\n","ğŸ¯ Instance name: 'rezcty' (gunakan ini sebagai trigger word)\n","ğŸ¯ Class name: 'view'\n","ğŸ¯ Repeats: 20x per epoch\n","ğŸ“ Folder training: 20_rezcty_view\n","\n","ğŸ” Memvalidasi caption files...\n","ğŸ“ Caption files ditemukan: 10/10\n","\n","ğŸ”¥ Memulai pelatihan untuk 'Rezcty_project'...\n","ğŸ“ Command: python train_network.py --pretrained_model_name_or_path=\"/content/drive/MyDrive/AI/models/stable-dif...\n","/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","torch.utils._pytree._register_pytree_node(\n","/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","torch.utils._pytree._register_pytree_node(\n","/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","torch.utils._pytree._register_pytree_node(\n","prepare tokenizer\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","warnings.warn(\n","Using DreamBooth method.\n","ignore directory without repeats / ç¹°ã‚Šè¿”ã—å›æ•°ã®ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç„¡è¦–ã—ã¾ã™: images\n","ignore directory without repeats / ç¹°ã‚Šè¿”ã—å›æ•°ã®ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç„¡è¦–ã—ã¾ã™: model\n","ignore directory without repeats / ç¹°ã‚Šè¿”ã—å›æ•°ã®ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç„¡è¦–ã—ã¾ã™: log\n","prepare images.\n","found directory /content/drive/MyDrive/AI/training/Rezcty_project/20_rezcty_view contains 10 image files\n","200 train images with repeating.\n","0 reg images.\n","no regularization images / æ­£å‰‡åŒ–ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n","[Dataset 0]\n","batch_size: 1\n","resolution: (512, 512)\n","enable_bucket: True\n","network_multiplier: 1.0\n","min_bucket_reso: 256\n","max_bucket_reso: 1024\n","bucket_reso_steps: 64\n","bucket_no_upscale: False\n","\n","[Subset 0 of Dataset 0]\n","image_dir: \"/content/drive/MyDrive/AI/training/Rezcty_project/20_rezcty_view\"\n","image_count: 10\n","num_repeats: 20\n","shuffle_caption: True\n","keep_tokens: 1\n","keep_tokens_separator:\n","caption_separator: ,\n","secondary_separator: None\n","enable_wildcard: False\n","caption_dropout_rate: 0.0\n","caption_dropout_every_n_epoches: 0\n","caption_tag_dropout_rate: 0.0\n","caption_prefix: None\n","caption_suffix: None\n","color_aug: False\n","flip_aug: False\n","face_crop_aug_range: None\n","random_crop: False\n","token_warmup_min: 1,\n","token_warmup_step: 0,\n","alpha_mask: False,\n","is_reg: False\n","class_tokens: rezcty_view\n","caption_extension: .txt\n","\n","\n","[Dataset 0]\n","loading image sizes.\n","\n","0%|          | 0/10 [00:00<?, ?it/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 512.53it/s]\n","make buckets\n","number of images (including repeats) / å„bucketã®ç”»åƒæšæ•°ï¼ˆç¹°ã‚Šè¿”ã—å›æ•°ã‚’å«ã‚€ï¼‰\n","bucket 0: resolution (384, 640), count: 160\n","bucket 1: resolution (640, 384), count: 40\n","mean ar error (without repeats): 0.08666666666666667\n","preparing accelerator\n","accelerator device: cuda\n","loading model for process 0/1\n","load Diffusers pretrained models: /content/drive/MyDrive/AI/models/stable-diffusion-v1-5-fp16\n","\n","Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\n","Loading pipeline components...:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.25it/s]\n","Loading pipeline components...:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05<00:03,  1.98s/it]\n","Loading pipeline components...:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:06<00:01,  1.53s/it]\n","Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  1.25s/it]\n","You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","UNet2DConditionModel: 64, 8, 768, False, False\n","U-Net converted to original U-Net\n","Enable xformers for U-Net\n","import network module: networks.lora\n","[Dataset 0]\n","caching latents.\n","checking cache validity...\n","\n","0%|          | 0/10 [00:00<?, ?it/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 4886.19it/s]\n","caching latents...\n","\n","0%|          | 0/10 [00:00<?, ?it/s]\n","10%|â–ˆ         | 1/10 [00:01<00:13,  1.49s/it]\n","20%|â–ˆâ–ˆ        | 2/10 [00:01<00:03,  2.62it/s]\n","30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:02<00:02,  2.85it/s]\n","40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:02<00:02,  2.67it/s]\n","50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:02<00:01,  2.87it/s]\n","60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:03<00:01,  3.03it/s]\n","70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:03<00:01,  2.95it/s]\n","80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:03<00:00,  3.06it/s]\n","90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:04<00:00,  2.96it/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.49it/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.13it/s]\n","create LoRA network. base dim (rank): 32, alpha: 16.0\n","neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n","create LoRA for Text Encoder:\n","create LoRA for Text Encoder: 72 modules.\n","create LoRA for U-Net: 192 modules.\n","enable LoRA for text encoder: 72 modules\n","enable LoRA for U-Net: 192 modules\n","prepare optimizer, data loader etc.\n","use 8-bit AdamW optimizer | {}\n","override steps. steps for 10 epochs is / æŒ‡å®šã‚¨ãƒãƒƒã‚¯ã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°: 500\n","running training / å­¦ç¿’é–‹å§‹\n","num train images * repeats / å­¦ç¿’ç”»åƒã®æ•°Ã—ç¹°ã‚Šè¿”ã—å›æ•°: 200\n","num reg images / æ­£å‰‡åŒ–ç”»åƒã®æ•°: 0\n","num batches per epoch / 1epochã®ãƒãƒƒãƒæ•°: 200\n","num epochs / epochæ•°: 10\n","batch size per device / ãƒãƒƒãƒã‚µã‚¤ã‚º: 1\n","gradient accumulation steps / å‹¾é…ã‚’åˆè¨ˆã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•° = 4\n","total optimization steps / å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°: 500\n","\n","steps:   0%|          | 0/500 [00:00<?, ?it/s]\n","epoch 1/10\n","epoch is incremented. current_epoch: 0, epoch: 1\n","epoch is incremented. current_epoch: 0, epoch: 1\n","\n","steps:   0%|          | 0/500 [00:02<?, ?it/s, avr_loss=0.0287]\n","steps:   0%|          | 0/500 [00:03<?, ?it/s, avr_loss=0.0542]\n","steps:   0%|          | 0/500 [00:03<?, ?it/s, avr_loss=0.0888]\n","steps:   0%|          | 1/500 [00:04<36:34,  4.40s/it, avr_loss=0.0888]\n","steps:   0%|          | 1/500 [00:04<36:34,  4.40s/it, avr_loss=0.146]\n","steps:   0%|          | 1/500 [00:04<40:36,  4.88s/it, avr_loss=0.168]\n","steps:   0%|          | 1/500 [00:05<44:41,  5.37s/it, avr_loss=0.14]\n","steps:   0%|          | 1/500 [00:05<48:44,  5.86s/it, avr_loss=0.159]\n","steps:   0%|          | 2/500 [00:06<26:35,  3.20s/it, avr_loss=0.159]\n","steps:   0%|          | 2/500 [00:06<26:35,  3.20s/it, avr_loss=0.143]\n","steps:   0%|          | 2/500 [00:06<28:30,  3.44s/it, avr_loss=0.13]\n","steps:   0%|          | 2/500 [00:07<30:32,  3.68s/it, avr_loss=0.161]\n","steps:   0%|          | 2/500 [00:07<32:35,  3.93s/it, avr_loss=0.148]\n","steps:   1%|          | 3/500 [00:08<23:31,  2.84s/it, avr_loss=0.148]\n","steps:   1%|          | 3/500 [00:08<23:31,  2.84s/it, avr_loss=0.142]\n","steps:   1%|          | 3/500 [00:09<24:57,  3.01s/it, avr_loss=0.141]\n","steps:   1%|          | 3/500 [00:09<26:26,  3.19s/it, avr_loss=0.134]\n","steps:   1%|          | 3/500 [00:10<27:59,  3.38s/it, avr_loss=0.131]\n","steps:   1%|          | 4/500 [00:10<22:23,  2.71s/it, avr_loss=0.131]\n","steps:   1%|          | 4/500 [00:10<22:23,  2.71s/it, avr_loss=0.145]\n","steps:   1%|          | 4/500 [00:11<23:35,  2.85s/it, avr_loss=0.145]\n","steps:   1%|          | 4/500 [00:11<24:34,  2.97s/it, avr_loss=0.138]\n","steps:   1%|          | 4/500 [00:12<25:33,  3.09s/it, avr_loss=0.149]\n","steps:   1%|          | 5/500 [00:12<21:19,  2.59s/it, avr_loss=0.149]\n","steps:   1%|          | 5/500 [00:12<21:20,  2.59s/it, avr_loss=0.142]\n","steps:   1%|          | 5/500 [00:13<22:06,  2.68s/it, avr_loss=0.137]\n","steps:   1%|          | 5/500 [00:13<22:53,  2.77s/it, avr_loss=0.148]\n","steps:   1%|          | 5/500 [00:14<23:40,  2.87s/it, avr_loss=0.142]\n","steps:   1%|          | 6/500 [00:14<20:26,  2.48s/it, avr_loss=0.142]\n","steps:   1%|          | 6/500 [00:14<20:26,  2.48s/it, avr_loss=0.146]\n","steps:   1%|          | 6/500 [00:15<21:06,  2.56s/it, avr_loss=0.14]\n","steps:   1%|          | 6/500 [00:15<21:47,  2.65s/it, avr_loss=0.138]\n","steps:   1%|          | 6/500 [00:16<22:27,  2.73s/it, avr_loss=0.134]\n","steps:   1%|â–         | 7/500 [00:16<19:53,  2.42s/it, avr_loss=0.134]\n","steps:   1%|â–         | 7/500 [00:16<19:53,  2.42s/it, avr_loss=0.129]\n","steps:   1%|â–         | 7/500 [00:17<20:27,  2.49s/it, avr_loss=0.125]\n","steps:   1%|â–         | 7/500 [00:17<21:02,  2.56s/it, avr_loss=0.125]\n","steps:   1%|â–         | 7/500 [00:18<21:36,  2.63s/it, avr_loss=0.125]\n","steps:   2%|â–         | 8/500 [00:18<19:27,  2.37s/it, avr_loss=0.125]\n","steps:   2%|â–         | 8/500 [00:18<19:27,  2.37s/it, avr_loss=0.128]\n","steps:   2%|â–         | 8/500 [00:19<19:57,  2.43s/it, avr_loss=0.124]\n","steps:   2%|â–         | 8/500 [00:19<20:28,  2.50s/it, avr_loss=0.13]\n","steps:   2%|â–         | 8/500 [00:20<20:57,  2.56s/it, avr_loss=0.129]\n","steps:   2%|â–         | 9/500 [00:21<19:07,  2.34s/it, avr_loss=0.129]\n","steps:   2%|â–         | 9/500 [00:21<19:07,  2.34s/it, avr_loss=0.126]\n","steps:   2%|â–         | 9/500 [00:21<19:34,  2.39s/it, avr_loss=0.128]\n","steps:   2%|â–         | 9/500 [00:22<20:04,  2.45s/it, avr_loss=0.138]\n","steps:   2%|â–         | 9/500 [00:22<20:33,  2.51s/it, avr_loss=0.139]\n","steps:   2%|â–         | 10/500 [00:23<19:07,  2.34s/it, avr_loss=0.139]\n","steps:   2%|â–         | 10/500 [00:23<19:07,  2.34s/it, avr_loss=0.144]\n","steps:   2%|â–         | 10/500 [00:23<19:32,  2.39s/it, avr_loss=0.141]\n","steps:   2%|â–         | 10/500 [00:24<20:00,  2.45s/it, avr_loss=0.138]\n","steps:   2%|â–         | 10/500 [00:25<20:28,  2.51s/it, avr_loss=0.135]\n","steps:   2%|â–         | 11/500 [00:25<18:58,  2.33s/it, avr_loss=0.135]\n","steps:   2%|â–         | 11/500 [00:25<18:58,  2.33s/it, avr_loss=0.135]\n","steps:   2%|â–         | 11/500 [00:26<19:19,  2.37s/it, avr_loss=0.133]\n","steps:   2%|â–         | 11/500 [00:26<19:40,  2.41s/it, avr_loss=0.133]\n","steps:   2%|â–         | 11/500 [00:27<20:02,  2.46s/it, avr_loss=0.13]\n","steps:   2%|â–         | 12/500 [00:27<18:42,  2.30s/it, avr_loss=0.13]\n","steps:   2%|â–         | 12/500 [00:27<18:42,  2.30s/it, avr_loss=0.128]\n","steps:   2%|â–         | 12/500 [00:28<19:01,  2.34s/it, avr_loss=0.126]\n","steps:   2%|â–         | 12/500 [00:28<19:21,  2.38s/it, avr_loss=0.124]\n","steps:   2%|â–         | 12/500 [00:29<19:41,  2.42s/it, avr_loss=0.121]\n","steps:   3%|â–         | 13/500 [00:29<18:28,  2.28s/it, avr_loss=0.121]\n","steps:   3%|â–         | 13/500 [00:29<18:28,  2.28s/it, avr_loss=0.122]\n","steps:   3%|â–         | 13/500 [00:30<18:47,  2.31s/it, avr_loss=0.122]\n","steps:   3%|â–         | 13/500 [00:30<19:05,  2.35s/it, avr_loss=0.119]\n","steps:   3%|â–         | 13/500 [00:31<19:23,  2.39s/it, avr_loss=0.117]\n","steps:   3%|â–         | 14/500 [00:31<18:17,  2.26s/it, avr_loss=0.117]\n","steps:   3%|â–         | 14/500 [00:31<18:17,  2.26s/it, avr_loss=0.117]\n","steps:   3%|â–         | 14/500 [00:32<18:34,  2.29s/it, avr_loss=0.119]\n","steps:   3%|â–         | 14/500 [00:32<18:51,  2.33s/it, avr_loss=0.121]\n","steps:   3%|â–         | 14/500 [00:33<19:08,  2.36s/it, avr_loss=0.123]\n","steps:   3%|â–         | 15/500 [00:33<18:08,  2.24s/it, avr_loss=0.123]\n","steps:   3%|â–         | 15/500 [00:33<18:08,  2.24s/it, avr_loss=0.123]\n","steps:   3%|â–         | 15/500 [00:34<18:24,  2.28s/it, avr_loss=0.123]\n","steps:   3%|â–         | 15/500 [00:34<18:40,  2.31s/it, avr_loss=0.122]\n","steps:   3%|â–         | 15/500 [00:35<18:57,  2.35s/it, avr_loss=0.12]\n","steps:   3%|â–         | 16/500 [00:35<18:06,  2.24s/it, avr_loss=0.12]\n","steps:   3%|â–         | 16/500 [00:35<18:06,  2.24s/it, avr_loss=0.121]\n","steps:   3%|â–         | 16/500 [00:36<18:23,  2.28s/it, avr_loss=0.119]\n","steps:   3%|â–         | 16/500 [00:37<18:39,  2.31s/it, avr_loss=0.118]\n","steps:   3%|â–         | 16/500 [00:37<18:56,  2.35s/it, avr_loss=0.117]\n","steps:   3%|â–         | 17/500 [00:38<18:07,  2.25s/it, avr_loss=0.117]\n","steps:   3%|â–         | 17/500 [00:38<18:07,  2.25s/it, avr_loss=0.116]\n","steps:   3%|â–         | 17/500 [00:38<18:23,  2.29s/it, avr_loss=0.118]\n","steps:   3%|â–         | 17/500 [00:39<18:37,  2.31s/it, avr_loss=0.117]\n","steps:   3%|â–         | 17/500 [00:39<18:51,  2.34s/it, avr_loss=0.116]\n","steps:   4%|â–         | 18/500 [00:40<18:01,  2.24s/it, avr_loss=0.116]\n","steps:   4%|â–         | 18/500 [00:40<18:01,  2.24s/it, avr_loss=0.115]\n","steps:   4%|â–         | 18/500 [00:40<18:14,  2.27s/it, avr_loss=0.118]\n","steps:   4%|â–         | 18/500 [00:41<18:27,  2.30s/it, avr_loss=0.12]\n","steps:   4%|â–         | 18/500 [00:41<18:40,  2.33s/it, avr_loss=0.119]\n","steps:   4%|â–         | 19/500 [00:42<17:54,  2.23s/it, avr_loss=0.119]\n","steps:   4%|â–         | 19/500 [00:42<17:54,  2.23s/it, avr_loss=0.117]\n","steps:   4%|â–         | 19/500 [00:42<18:06,  2.26s/it, avr_loss=0.117]\n","steps:   4%|â–         | 19/500 [00:43<18:18,  2.28s/it, avr_loss=0.116]\n","steps:   4%|â–         | 19/500 [00:43<18:31,  2.31s/it, avr_loss=0.115]\n","steps:   4%|â–         | 20/500 [00:44<17:47,  2.22s/it, avr_loss=0.115]\n","steps:   4%|â–         | 20/500 [00:44<17:47,  2.22s/it, avr_loss=0.117]\n","steps:   4%|â–         | 20/500 [00:44<17:59,  2.25s/it, avr_loss=0.116]\n","steps:   4%|â–         | 20/500 [00:45<18:10,  2.27s/it, avr_loss=0.116]\n","steps:   4%|â–         | 20/500 [00:45<18:22,  2.30s/it, avr_loss=0.115]\n","steps:   4%|â–         | 21/500 [00:46<17:40,  2.21s/it, avr_loss=0.115]\n","steps:   4%|â–         | 21/500 [00:46<17:40,  2.21s/it, avr_loss=0.117]\n","steps:   4%|â–         | 21/500 [00:46<17:51,  2.24s/it, avr_loss=0.117]\n","steps:   4%|â–         | 21/500 [00:47<18:02,  2.26s/it, avr_loss=0.12]\n","steps:   4%|â–         | 21/500 [00:47<18:13,  2.28s/it, avr_loss=0.121]\n","steps:   4%|â–         | 22/500 [00:48<17:35,  2.21s/it, avr_loss=0.121]\n","steps:   4%|â–         | 22/500 [00:48<17:35,  2.21s/it, avr_loss=0.12]\n","steps:   4%|â–         | 22/500 [00:49<17:47,  2.23s/it, avr_loss=0.12]\n","steps:   4%|â–         | 22/500 [00:49<17:58,  2.26s/it, avr_loss=0.119]\n","steps:   4%|â–         | 22/500 [00:50<18:11,  2.28s/it, avr_loss=0.124]\n","steps:   5%|â–         | 23/500 [00:50<17:35,  2.21s/it, avr_loss=0.124]\n","steps:   5%|â–         | 23/500 [00:50<17:35,  2.21s/it, avr_loss=0.123]\n","steps:   5%|â–         | 23/500 [00:51<17:47,  2.24s/it, avr_loss=0.124]\n","steps:   5%|â–         | 23/500 [00:52<17:59,  2.26s/it, avr_loss=0.129]\n","steps:   5%|â–         | 23/500 [00:52<18:09,  2.28s/it, avr_loss=0.129]\n","steps:   5%|â–         | 24/500 [00:53<17:33,  2.21s/it, avr_loss=0.129]\n","steps:   5%|â–         | 24/500 [00:53<17:33,  2.21s/it, avr_loss=0.128]\n","steps:   5%|â–         | 24/500 [00:53<17:43,  2.23s/it, avr_loss=0.132]\n","steps:   5%|â–         | 24/500 [00:54<17:53,  2.25s/it, avr_loss=0.131]\n","steps:   5%|â–         | 24/500 [00:54<18:03,  2.28s/it, avr_loss=0.13]\n","steps:   5%|â–Œ         | 25/500 [00:55<17:28,  2.21s/it, avr_loss=0.13]\n","steps:   5%|â–Œ         | 25/500 [00:55<17:28,  2.21s/it, avr_loss=0.129]\n","steps:   5%|â–Œ         | 25/500 [00:55<17:37,  2.23s/it, avr_loss=0.127]\n","steps:   5%|â–Œ         | 25/500 [00:56<17:46,  2.25s/it, avr_loss=0.131]\n","steps:   5%|â–Œ         | 25/500 [00:56<17:56,  2.27s/it, avr_loss=0.13]\n","steps:   5%|â–Œ         | 26/500 [00:57<17:22,  2.20s/it, avr_loss=0.13]\n","steps:   5%|â–Œ         | 26/500 [00:57<17:22,  2.20s/it, avr_loss=0.129]\n","steps:   5%|â–Œ         | 26/500 [00:57<17:31,  2.22s/it, avr_loss=0.128]\n","steps:   5%|â–Œ         | 26/500 [00:58<17:40,  2.24s/it, avr_loss=0.129]\n","steps:   5%|â–Œ         | 26/500 [00:58<17:50,  2.26s/it, avr_loss=0.131]\n","steps:   5%|â–Œ         | 27/500 [00:59<17:17,  2.19s/it, avr_loss=0.131]\n","steps:   5%|â–Œ         | 27/500 [00:59<17:17,  2.19s/it, avr_loss=0.138]\n","steps:   5%|â–Œ         | 27/500 [00:59<17:26,  2.21s/it, avr_loss=0.137]\n","steps:   5%|â–Œ         | 27/500 [01:00<17:34,  2.23s/it, avr_loss=0.137]\n","steps:   5%|â–Œ         | 27/500 [01:00<17:43,  2.25s/it, avr_loss=0.136]\n","steps:   6%|â–Œ         | 28/500 [01:01<17:12,  2.19s/it, avr_loss=0.136]\n","steps:   6%|â–Œ         | 28/500 [01:01<17:12,  2.19s/it, avr_loss=0.135]\n","steps:   6%|â–Œ         | 28/500 [01:01<17:21,  2.21s/it, avr_loss=0.134]\n","steps:   6%|â–Œ         | 28/500 [01:02<17:29,  2.22s/it, avr_loss=0.134]\n","steps:   6%|â–Œ         | 28/500 [01:02<17:38,  2.24s/it, avr_loss=0.133]\n","steps:   6%|â–Œ         | 29/500 [01:03<17:10,  2.19s/it, avr_loss=0.133]\n","steps:   6%|â–Œ         | 29/500 [01:03<17:10,  2.19s/it, avr_loss=0.132]\n","steps:   6%|â–Œ         | 29/500 [01:04<17:20,  2.21s/it, avr_loss=0.133]\n","steps:   6%|â–Œ         | 29/500 [01:04<17:28,  2.23s/it, avr_loss=0.133]\n","steps:   6%|â–Œ         | 29/500 [01:05<17:39,  2.25s/it, avr_loss=0.134]\n","steps:   6%|â–Œ         | 30/500 [01:05<17:12,  2.20s/it, avr_loss=0.134]\n","steps:   6%|â–Œ         | 30/500 [01:05<17:12,  2.20s/it, avr_loss=0.133]\n","steps:   6%|â–Œ         | 30/500 [01:06<17:19,  2.21s/it, avr_loss=0.135]\n","steps:   6%|â–Œ         | 30/500 [01:06<17:27,  2.23s/it, avr_loss=0.134]\n","steps:   6%|â–Œ         | 30/500 [01:07<17:35,  2.25s/it, avr_loss=0.136]\n","steps:   6%|â–Œ         | 31/500 [01:07<17:08,  2.19s/it, avr_loss=0.136]\n","steps:   6%|â–Œ         | 31/500 [01:07<17:08,  2.19s/it, avr_loss=0.137]\n","steps:   6%|â–Œ         | 31/500 [01:08<17:15,  2.21s/it, avr_loss=0.136]\n","steps:   6%|â–Œ         | 31/500 [01:08<17:22,  2.22s/it, avr_loss=0.135]\n","steps:   6%|â–Œ         | 31/500 [01:09<17:30,  2.24s/it, avr_loss=0.134]\n","steps:   6%|â–‹         | 32/500 [01:09<17:03,  2.19s/it, avr_loss=0.134]\n","steps:   6%|â–‹         | 32/500 [01:09<17:03,  2.19s/it, avr_loss=0.134]\n","steps:   6%|â–‹         | 32/500 [01:10<17:10,  2.20s/it, avr_loss=0.134]\n","steps:   6%|â–‹         | 32/500 [01:10<17:17,  2.22s/it, avr_loss=0.137]\n","steps:   6%|â–‹         | 32/500 [01:11<17:25,  2.23s/it, avr_loss=0.136]\n","steps:   7%|â–‹         | 33/500 [01:12<16:59,  2.18s/it, avr_loss=0.136]\n","steps:   7%|â–‹         | 33/500 [01:12<16:59,  2.18s/it, avr_loss=0.136]\n","steps:   7%|â–‹         | 33/500 [01:12<17:06,  2.20s/it, avr_loss=0.138]\n","steps:   7%|â–‹         | 33/500 [01:13<17:13,  2.21s/it, avr_loss=0.139]\n","steps:   7%|â–‹         | 33/500 [01:13<17:20,  2.23s/it, avr_loss=0.138]\n","steps:   7%|â–‹         | 34/500 [01:14<16:55,  2.18s/it, avr_loss=0.138]\n","steps:   7%|â–‹         | 34/500 [01:14<16:55,  2.18s/it, avr_loss=0.137]\n","steps:   7%|â–‹         | 34/500 [01:14<17:02,  2.19s/it, avr_loss=0.14]\n","steps:   7%|â–‹         | 34/500 [01:15<17:09,  2.21s/it, avr_loss=0.139]\n","steps:   7%|â–‹         | 34/500 [01:15<17:16,  2.22s/it, avr_loss=0.141]\n","steps:   7%|â–‹         | 35/500 [01:16<16:53,  2.18s/it, avr_loss=0.141]\n","steps:   7%|â–‹         | 35/500 [01:16<16:53,  2.18s/it, avr_loss=0.141]\n","steps:   7%|â–‹         | 35/500 [01:16<17:00,  2.20s/it, avr_loss=0.14]\n","steps:   7%|â–‹         | 35/500 [01:17<17:08,  2.21s/it, avr_loss=0.139]\n","steps:   7%|â–‹         | 35/500 [01:17<17:15,  2.23s/it, avr_loss=0.139]\n","steps:   7%|â–‹         | 36/500 [01:18<16:53,  2.19s/it, avr_loss=0.139]\n","steps:   7%|â–‹         | 36/500 [01:18<16:53,  2.19s/it, avr_loss=0.138]\n","steps:   7%|â–‹         | 36/500 [01:19<17:01,  2.20s/it, avr_loss=0.137]\n","steps:   7%|â–‹         | 36/500 [01:19<17:07,  2.22s/it, avr_loss=0.137]\n","steps:   7%|â–‹         | 36/500 [01:20<17:14,  2.23s/it, avr_loss=0.137]\n","steps:   7%|â–‹         | 37/500 [01:20<16:51,  2.18s/it, avr_loss=0.137]\n","steps:   7%|â–‹         | 37/500 [01:20<16:51,  2.18s/it, avr_loss=0.137]\n","steps:   7%|â–‹         | 37/500 [01:21<16:57,  2.20s/it, avr_loss=0.136]\n","steps:   7%|â–‹         | 37/500 [01:21<17:03,  2.21s/it, avr_loss=0.137]\n","steps:   7%|â–‹         | 37/500 [01:22<17:09,  2.22s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 38/500 [01:22<16:46,  2.18s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 38/500 [01:22<16:46,  2.18s/it, avr_loss=0.137]\n","steps:   8%|â–Š         | 38/500 [01:23<16:52,  2.19s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 38/500 [01:23<16:58,  2.21s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 38/500 [01:24<17:04,  2.22s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 39/500 [01:24<16:42,  2.18s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 39/500 [01:24<16:42,  2.18s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 39/500 [01:25<16:48,  2.19s/it, avr_loss=0.134]\n","steps:   8%|â–Š         | 39/500 [01:25<16:54,  2.20s/it, avr_loss=0.133]\n","steps:   8%|â–Š         | 39/500 [01:26<17:00,  2.21s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 40/500 [01:26<16:38,  2.17s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 40/500 [01:26<16:38,  2.17s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 40/500 [01:27<16:44,  2.18s/it, avr_loss=0.138]\n","steps:   8%|â–Š         | 40/500 [01:27<16:50,  2.20s/it, avr_loss=0.137]\n","steps:   8%|â–Š         | 40/500 [01:28<16:55,  2.21s/it, avr_loss=0.137]\n","steps:   8%|â–Š         | 41/500 [01:28<16:35,  2.17s/it, avr_loss=0.137]\n","steps:   8%|â–Š         | 41/500 [01:28<16:35,  2.17s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 41/500 [01:29<16:40,  2.18s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 41/500 [01:29<16:47,  2.19s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 41/500 [01:30<16:53,  2.21s/it, avr_loss=0.134]\n","steps:   8%|â–Š         | 42/500 [01:31<16:35,  2.17s/it, avr_loss=0.134]\n","steps:   8%|â–Š         | 42/500 [01:31<16:35,  2.17s/it, avr_loss=0.136]\n","steps:   8%|â–Š         | 42/500 [01:31<16:40,  2.19s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 42/500 [01:32<16:46,  2.20s/it, avr_loss=0.135]\n","steps:   8%|â–Š         | 42/500 [01:32<16:53,  2.21s/it, avr_loss=0.135]\n","steps:   9%|â–Š         | 43/500 [01:33<16:34,  2.18s/it, avr_loss=0.135]\n","steps:   9%|â–Š         | 43/500 [01:33<16:34,  2.18s/it, avr_loss=0.135]\n","steps:   9%|â–Š         | 43/500 [01:34<16:39,  2.19s/it, avr_loss=0.135]\n","steps:   9%|â–Š         | 43/500 [01:34<16:44,  2.20s/it, avr_loss=0.135]\n","steps:   9%|â–Š         | 43/500 [01:35<16:50,  2.21s/it, avr_loss=0.135]\n","steps:   9%|â–‰         | 44/500 [01:35<16:31,  2.17s/it, avr_loss=0.135]\n","steps:   9%|â–‰         | 44/500 [01:35<16:31,  2.17s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 44/500 [01:36<16:36,  2.19s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 44/500 [01:36<16:41,  2.20s/it, avr_loss=0.133]\n","steps:   9%|â–‰         | 44/500 [01:37<16:47,  2.21s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 45/500 [01:37<16:28,  2.17s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 45/500 [01:37<16:28,  2.17s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 45/500 [01:38<16:33,  2.18s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 45/500 [01:38<16:38,  2.20s/it, avr_loss=0.133]\n","steps:   9%|â–‰         | 45/500 [01:39<16:43,  2.21s/it, avr_loss=0.133]\n","steps:   9%|â–‰         | 46/500 [01:39<16:25,  2.17s/it, avr_loss=0.133]\n","steps:   9%|â–‰         | 46/500 [01:39<16:25,  2.17s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 46/500 [01:40<16:30,  2.18s/it, avr_loss=0.135]\n","steps:   9%|â–‰         | 46/500 [01:40<16:35,  2.19s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 46/500 [01:41<16:40,  2.20s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 47/500 [01:41<16:22,  2.17s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 47/500 [01:41<16:22,  2.17s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 47/500 [01:42<16:27,  2.18s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 47/500 [01:42<16:32,  2.19s/it, avr_loss=0.134]\n","steps:   9%|â–‰         | 47/500 [01:43<16:37,  2.20s/it, avr_loss=0.133]\n","steps:  10%|â–‰         | 48/500 [01:44<16:21,  2.17s/it, avr_loss=0.133]\n","steps:  10%|â–‰         | 48/500 [01:44<16:21,  2.17s/it, avr_loss=0.132]\n","steps:  10%|â–‰         | 48/500 [01:44<16:26,  2.18s/it, avr_loss=0.136]\n","steps:  10%|â–‰         | 48/500 [01:45<16:32,  2.19s/it, avr_loss=0.136]\n","steps:  10%|â–‰         | 48/500 [01:45<16:37,  2.21s/it, avr_loss=0.135]\n","steps:  10%|â–‰         | 49/500 [01:46<16:20,  2.18s/it, avr_loss=0.135]\n","steps:  10%|â–‰         | 49/500 [01:46<16:20,  2.18s/it, avr_loss=0.137]\n","steps:  10%|â–‰         | 49/500 [01:47<16:25,  2.19s/it, avr_loss=0.136]\n","steps:  10%|â–‰         | 49/500 [01:47<16:29,  2.20s/it, avr_loss=0.136]\n","steps:  10%|â–‰         | 49/500 [01:48<16:34,  2.21s/it, avr_loss=0.136]\n","steps:  10%|â–ˆ         | 50/500 [01:48<16:18,  2.17s/it, avr_loss=0.136]\n","steps:  10%|â–ˆ         | 50/500 [01:48<16:18,  2.17s/it, avr_loss=0.139]\n","epoch 2/10\n","epoch is incremented. current_epoch: 0, epoch: 2\n","epoch is incremented. current_epoch: 0, epoch: 2\n","\n","steps:  10%|â–ˆ         | 50/500 [01:49<16:25,  2.19s/it, avr_loss=0.139]\n","steps:  10%|â–ˆ         | 50/500 [01:49<16:29,  2.20s/it, avr_loss=0.139]\n","steps:  10%|â–ˆ         | 50/500 [01:50<16:34,  2.21s/it, avr_loss=0.139]\n","steps:  10%|â–ˆ         | 51/500 [01:51<16:17,  2.18s/it, avr_loss=0.139]\n","steps:  10%|â–ˆ         | 51/500 [01:51<16:17,  2.18s/it, avr_loss=0.138]\n","steps:  10%|â–ˆ         | 51/500 [01:51<16:22,  2.19s/it, avr_loss=0.137]\n","steps:  10%|â–ˆ         | 51/500 [01:52<16:26,  2.20s/it, avr_loss=0.138]\n","steps:  10%|â–ˆ         | 51/500 [01:52<16:30,  2.21s/it, avr_loss=0.137]\n","steps:  10%|â–ˆ         | 52/500 [01:53<16:14,  2.18s/it, avr_loss=0.137]\n","steps:  10%|â–ˆ         | 52/500 [01:53<16:14,  2.18s/it, avr_loss=0.137]\n","steps:  10%|â–ˆ         | 52/500 [01:53<16:18,  2.18s/it, avr_loss=0.137]\n","steps:  10%|â–ˆ         | 52/500 [01:54<16:23,  2.19s/it, avr_loss=0.135]\n","steps:  10%|â–ˆ         | 52/500 [01:54<16:27,  2.20s/it, avr_loss=0.137]\n","steps:  11%|â–ˆ         | 53/500 [01:55<16:11,  2.17s/it, avr_loss=0.137]\n","steps:  11%|â–ˆ         | 53/500 [01:55<16:11,  2.17s/it, avr_loss=0.137]\n","steps:  11%|â–ˆ         | 53/500 [01:55<16:15,  2.18s/it, avr_loss=0.138]\n","steps:  11%|â–ˆ         | 53/500 [01:56<16:19,  2.19s/it, avr_loss=0.141]\n","steps:  11%|â–ˆ         | 53/500 [01:56<16:23,  2.20s/it, avr_loss=0.142]\n","steps:  11%|â–ˆ         | 54/500 [01:57<16:09,  2.17s/it, avr_loss=0.142]\n","steps:  11%|â–ˆ         | 54/500 [01:57<16:09,  2.17s/it, avr_loss=0.141]\n","steps:  11%|â–ˆ         | 54/500 [01:57<16:13,  2.18s/it, avr_loss=0.142]\n","steps:  11%|â–ˆ         | 54/500 [01:58<16:18,  2.19s/it, avr_loss=0.143]\n","steps:  11%|â–ˆ         | 54/500 [01:58<16:22,  2.20s/it, avr_loss=0.143]\n","steps:  11%|â–ˆ         | 55/500 [01:59<16:08,  2.18s/it, avr_loss=0.143]\n","steps:  11%|â–ˆ         | 55/500 [01:59<16:08,  2.18s/it, avr_loss=0.143]\n","steps:  11%|â–ˆ         | 55/500 [02:00<16:13,  2.19s/it, avr_loss=0.143]\n","steps:  11%|â–ˆ         | 55/500 [02:00<16:17,  2.20s/it, avr_loss=0.142]\n","steps:  11%|â–ˆ         | 55/500 [02:01<16:21,  2.20s/it, avr_loss=0.142]\n","steps:  11%|â–ˆ         | 56/500 [02:01<16:06,  2.18s/it, avr_loss=0.142]\n","steps:  11%|â–ˆ         | 56/500 [02:01<16:06,  2.18s/it, avr_loss=0.141]\n","steps:  11%|â–ˆ         | 56/500 [02:02<16:09,  2.18s/it, avr_loss=0.141]\n","steps:  11%|â–ˆ         | 56/500 [02:02<16:13,  2.19s/it, avr_loss=0.141]\n","steps:  11%|â–ˆ         | 56/500 [02:03<16:17,  2.20s/it, avr_loss=0.143]\n","steps:  11%|â–ˆâ–        | 57/500 [02:03<16:02,  2.17s/it, avr_loss=0.143]\n","steps:  11%|â–ˆâ–        | 57/500 [02:03<16:02,  2.17s/it, avr_loss=0.143]\n","steps:  11%|â–ˆâ–        | 57/500 [02:04<16:06,  2.18s/it, avr_loss=0.143]\n","steps:  11%|â–ˆâ–        | 57/500 [02:04<16:10,  2.19s/it, avr_loss=0.142]\n","steps:  11%|â–ˆâ–        | 57/500 [02:05<16:14,  2.20s/it, avr_loss=0.142]\n","steps:  12%|â–ˆâ–        | 58/500 [02:05<15:59,  2.17s/it, avr_loss=0.142]\n","steps:  12%|â–ˆâ–        | 58/500 [02:05<15:59,  2.17s/it, avr_loss=0.143]\n","steps:  12%|â–ˆâ–        | 58/500 [02:06<16:03,  2.18s/it, avr_loss=0.143]\n","steps:  12%|â–ˆâ–        | 58/500 [02:06<16:07,  2.19s/it, avr_loss=0.142]\n","steps:  12%|â–ˆâ–        | 58/500 [02:07<16:10,  2.20s/it, avr_loss=0.142]\n","steps:  12%|â–ˆâ–        | 59/500 [02:07<15:56,  2.17s/it, avr_loss=0.142]\n","steps:  12%|â–ˆâ–        | 59/500 [02:07<15:56,  2.17s/it, avr_loss=0.144]\n","steps:  12%|â–ˆâ–        | 59/500 [02:08<15:59,  2.18s/it, avr_loss=0.145]\n","steps:  12%|â–ˆâ–        | 59/500 [02:08<16:03,  2.19s/it, avr_loss=0.144]\n","steps:  12%|â–ˆâ–        | 59/500 [02:09<16:07,  2.19s/it, avr_loss=0.145]\n","steps:  12%|â–ˆâ–        | 60/500 [02:09<15:53,  2.17s/it, avr_loss=0.145]\n","steps:  12%|â–ˆâ–        | 60/500 [02:09<15:53,  2.17s/it, avr_loss=0.143]\n","steps:  12%|â–ˆâ–        | 60/500 [02:10<15:57,  2.18s/it, avr_loss=0.144]\n","steps:  12%|â–ˆâ–        | 60/500 [02:11<16:01,  2.18s/it, avr_loss=0.148]\n","steps:  12%|â–ˆâ–        | 60/500 [02:11<16:05,  2.19s/it, avr_loss=0.148]\n","steps:  12%|â–ˆâ–        | 61/500 [02:12<15:52,  2.17s/it, avr_loss=0.148]\n","steps:  12%|â–ˆâ–        | 61/500 [02:12<15:52,  2.17s/it, avr_loss=0.147]\n","steps:  12%|â–ˆâ–        | 61/500 [02:12<15:55,  2.18s/it, avr_loss=0.148]\n","steps:  12%|â–ˆâ–        | 61/500 [02:13<16:00,  2.19s/it, avr_loss=0.148]\n","steps:  12%|â–ˆâ–        | 61/500 [02:13<16:04,  2.20s/it, avr_loss=0.148]\n","steps:  12%|â–ˆâ–        | 62/500 [02:14<15:50,  2.17s/it, avr_loss=0.148]\n","steps:  12%|â–ˆâ–        | 62/500 [02:14<15:50,  2.17s/it, avr_loss=0.149]\n","steps:  12%|â–ˆâ–        | 62/500 [02:15<15:53,  2.18s/it, avr_loss=0.152]\n","steps:  12%|â–ˆâ–        | 62/500 [02:15<15:57,  2.19s/it, avr_loss=0.152]\n","steps:  12%|â–ˆâ–        | 62/500 [02:16<16:00,  2.19s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 63/500 [02:16<15:47,  2.17s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 63/500 [02:16<15:47,  2.17s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 63/500 [02:17<15:50,  2.18s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 63/500 [02:17<15:54,  2.18s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 63/500 [02:18<15:57,  2.19s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 64/500 [02:18<15:44,  2.17s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 64/500 [02:18<15:44,  2.17s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 64/500 [02:19<15:47,  2.17s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 64/500 [02:19<15:51,  2.18s/it, avr_loss=0.152]\n","steps:  13%|â–ˆâ–        | 64/500 [02:20<15:54,  2.19s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 65/500 [02:20<15:41,  2.16s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 65/500 [02:20<15:41,  2.16s/it, avr_loss=0.152]\n","steps:  13%|â–ˆâ–        | 65/500 [02:21<15:44,  2.17s/it, avr_loss=0.152]\n","steps:  13%|â–ˆâ–        | 65/500 [02:21<15:47,  2.18s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 65/500 [02:22<15:51,  2.19s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 66/500 [02:22<15:38,  2.16s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 66/500 [02:22<15:38,  2.16s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 66/500 [02:23<15:41,  2.17s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 66/500 [02:23<15:44,  2.18s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 66/500 [02:24<15:48,  2.19s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 67/500 [02:24<15:36,  2.16s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 67/500 [02:24<15:36,  2.16s/it, avr_loss=0.154]\n","steps:  13%|â–ˆâ–        | 67/500 [02:25<15:39,  2.17s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 67/500 [02:25<15:43,  2.18s/it, avr_loss=0.153]\n","steps:  13%|â–ˆâ–        | 67/500 [02:26<15:47,  2.19s/it, avr_loss=0.154]\n","steps:  14%|â–ˆâ–        | 68/500 [02:27<15:35,  2.17s/it, avr_loss=0.154]\n","steps:  14%|â–ˆâ–        | 68/500 [02:27<15:35,  2.17s/it, avr_loss=0.154]\n","steps:  14%|â–ˆâ–        | 68/500 [02:27<15:38,  2.17s/it, avr_loss=0.153]\n","steps:  14%|â–ˆâ–        | 68/500 [02:28<15:41,  2.18s/it, avr_loss=0.154]\n","steps:  14%|â–ˆâ–        | 68/500 [02:28<15:44,  2.19s/it, avr_loss=0.155]\n","steps:  14%|â–ˆâ–        | 69/500 [02:29<15:32,  2.16s/it, avr_loss=0.155]\n","steps:  14%|â–ˆâ–        | 69/500 [02:29<15:32,  2.16s/it, avr_loss=0.156]\n","steps:  14%|â–ˆâ–        | 69/500 [02:29<15:35,  2.17s/it, avr_loss=0.156]\n","steps:  14%|â–ˆâ–        | 69/500 [02:30<15:38,  2.18s/it, avr_loss=0.159]\n","steps:  14%|â–ˆâ–        | 69/500 [02:30<15:41,  2.18s/it, avr_loss=0.16]\n","steps:  14%|â–ˆâ–        | 70/500 [02:31<15:29,  2.16s/it, avr_loss=0.16]\n","steps:  14%|â–ˆâ–        | 70/500 [02:31<15:29,  2.16s/it, avr_loss=0.159]\n","steps:  14%|â–ˆâ–        | 70/500 [02:31<15:32,  2.17s/it, avr_loss=0.159]\n","steps:  14%|â–ˆâ–        | 70/500 [02:32<15:35,  2.18s/it, avr_loss=0.16]\n","steps:  14%|â–ˆâ–        | 70/500 [02:32<15:38,  2.18s/it, avr_loss=0.16]\n","steps:  14%|â–ˆâ–        | 71/500 [02:33<15:26,  2.16s/it, avr_loss=0.16]\n","steps:  14%|â–ˆâ–        | 71/500 [02:33<15:26,  2.16s/it, avr_loss=0.158]\n","steps:  14%|â–ˆâ–        | 71/500 [02:33<15:29,  2.17s/it, avr_loss=0.158]\n","steps:  14%|â–ˆâ–        | 71/500 [02:34<15:32,  2.17s/it, avr_loss=0.156]\n","steps:  14%|â–ˆâ–        | 71/500 [02:34<15:35,  2.18s/it, avr_loss=0.155]\n","steps:  14%|â–ˆâ–        | 72/500 [02:35<15:23,  2.16s/it, avr_loss=0.155]\n","steps:  14%|â–ˆâ–        | 72/500 [02:35<15:23,  2.16s/it, avr_loss=0.156]\n","steps:  14%|â–ˆâ–        | 72/500 [02:35<15:26,  2.16s/it, avr_loss=0.156]\n","steps:  14%|â–ˆâ–        | 72/500 [02:36<15:29,  2.17s/it, avr_loss=0.156]\n","steps:  14%|â–ˆâ–        | 72/500 [02:36<15:32,  2.18s/it, avr_loss=0.154]\n","steps:  15%|â–ˆâ–        | 73/500 [02:37<15:20,  2.16s/it, avr_loss=0.154]\n","steps:  15%|â–ˆâ–        | 73/500 [02:37<15:20,  2.16s/it, avr_loss=0.154]\n","steps:  15%|â–ˆâ–        | 73/500 [02:38<15:24,  2.16s/it, avr_loss=0.153]\n","steps:  15%|â–ˆâ–        | 73/500 [02:38<15:27,  2.17s/it, avr_loss=0.15]\n","steps:  15%|â–ˆâ–        | 73/500 [02:39<15:30,  2.18s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–        | 74/500 [02:39<15:19,  2.16s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–        | 74/500 [02:39<15:19,  2.16s/it, avr_loss=0.15]\n","steps:  15%|â–ˆâ–        | 74/500 [02:40<15:23,  2.17s/it, avr_loss=0.147]\n","steps:  15%|â–ˆâ–        | 74/500 [02:40<15:26,  2.17s/it, avr_loss=0.147]\n","steps:  15%|â–ˆâ–        | 74/500 [02:41<15:29,  2.18s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 75/500 [02:41<15:17,  2.16s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 75/500 [02:41<15:17,  2.16s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 75/500 [02:42<15:20,  2.17s/it, avr_loss=0.151]\n","steps:  15%|â–ˆâ–Œ        | 75/500 [02:42<15:23,  2.17s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 75/500 [02:43<15:26,  2.18s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 76/500 [02:43<15:14,  2.16s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 76/500 [02:43<15:14,  2.16s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 76/500 [02:44<15:17,  2.16s/it, avr_loss=0.151]\n","steps:  15%|â–ˆâ–Œ        | 76/500 [02:44<15:20,  2.17s/it, avr_loss=0.15]\n","steps:  15%|â–ˆâ–Œ        | 76/500 [02:45<15:22,  2.18s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 77/500 [02:46<15:12,  2.16s/it, avr_loss=0.149]\n","steps:  15%|â–ˆâ–Œ        | 77/500 [02:46<15:12,  2.16s/it, avr_loss=0.145]\n","steps:  15%|â–ˆâ–Œ        | 77/500 [02:46<15:14,  2.16s/it, avr_loss=0.145]\n","steps:  15%|â–ˆâ–Œ        | 77/500 [02:46<15:17,  2.17s/it, avr_loss=0.144]\n","steps:  15%|â–ˆâ–Œ        | 77/500 [02:47<15:20,  2.18s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 78/500 [02:48<15:09,  2.15s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 78/500 [02:48<15:09,  2.15s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 78/500 [02:48<15:11,  2.16s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 78/500 [02:49<15:14,  2.17s/it, avr_loss=0.145]\n","steps:  16%|â–ˆâ–Œ        | 78/500 [02:49<15:17,  2.17s/it, avr_loss=0.146]\n","steps:  16%|â–ˆâ–Œ        | 79/500 [02:50<15:06,  2.15s/it, avr_loss=0.146]\n","steps:  16%|â–ˆâ–Œ        | 79/500 [02:50<15:06,  2.15s/it, avr_loss=0.147]\n","steps:  16%|â–ˆâ–Œ        | 79/500 [02:50<15:09,  2.16s/it, avr_loss=0.146]\n","steps:  16%|â–ˆâ–Œ        | 79/500 [02:51<15:12,  2.17s/it, avr_loss=0.147]\n","steps:  16%|â–ˆâ–Œ        | 79/500 [02:51<15:14,  2.17s/it, avr_loss=0.147]\n","steps:  16%|â–ˆâ–Œ        | 80/500 [02:52<15:04,  2.15s/it, avr_loss=0.147]\n","steps:  16%|â–ˆâ–Œ        | 80/500 [02:52<15:04,  2.15s/it, avr_loss=0.147]\n","steps:  16%|â–ˆâ–Œ        | 80/500 [02:52<15:07,  2.16s/it, avr_loss=0.146]\n","steps:  16%|â–ˆâ–Œ        | 80/500 [02:53<15:10,  2.17s/it, avr_loss=0.145]\n","steps:  16%|â–ˆâ–Œ        | 80/500 [02:53<15:13,  2.17s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 81/500 [02:54<15:03,  2.16s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 81/500 [02:54<15:03,  2.16s/it, avr_loss=0.143]\n","steps:  16%|â–ˆâ–Œ        | 81/500 [02:55<15:05,  2.16s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 81/500 [02:55<15:08,  2.17s/it, avr_loss=0.144]\n","steps:  16%|â–ˆâ–Œ        | 81/500 [02:56<15:10,  2.17s/it, avr_loss=0.143]\n","steps:  16%|â–ˆâ–‹        | 82/500 [02:56<15:00,  2.15s/it, avr_loss=0.143]\n","steps:  16%|â–ˆâ–‹        | 82/500 [02:56<15:00,  2.15s/it, avr_loss=0.143]\n","steps:  16%|â–ˆâ–‹        | 82/500 [02:57<15:02,  2.16s/it, avr_loss=0.143]\n","steps:  16%|â–ˆâ–‹        | 82/500 [02:57<15:05,  2.17s/it, avr_loss=0.143]\n","steps:  16%|â–ˆâ–‹        | 82/500 [02:58<15:07,  2.17s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 83/500 [02:58<14:57,  2.15s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 83/500 [02:58<14:57,  2.15s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 83/500 [02:59<14:59,  2.16s/it, avr_loss=0.14]\n","steps:  17%|â–ˆâ–‹        | 83/500 [02:59<15:02,  2.16s/it, avr_loss=0.14]\n","steps:  17%|â–ˆâ–‹        | 83/500 [03:00<15:04,  2.17s/it, avr_loss=0.14]\n","steps:  17%|â–ˆâ–‹        | 84/500 [03:00<14:54,  2.15s/it, avr_loss=0.14]\n","steps:  17%|â–ˆâ–‹        | 84/500 [03:00<14:54,  2.15s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 84/500 [03:01<14:57,  2.16s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 84/500 [03:01<14:59,  2.16s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 84/500 [03:02<15:01,  2.17s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 85/500 [03:02<14:51,  2.15s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 85/500 [03:02<14:51,  2.15s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 85/500 [03:03<14:54,  2.15s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 85/500 [03:03<14:56,  2.16s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 85/500 [03:04<14:59,  2.17s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 86/500 [03:04<14:49,  2.15s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 86/500 [03:04<14:49,  2.15s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 86/500 [03:05<14:52,  2.16s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 86/500 [03:05<14:55,  2.16s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 86/500 [03:06<14:57,  2.17s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 87/500 [03:07<14:48,  2.15s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 87/500 [03:07<14:48,  2.15s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 87/500 [03:07<14:51,  2.16s/it, avr_loss=0.142]\n","steps:  17%|â–ˆâ–‹        | 87/500 [03:08<14:53,  2.16s/it, avr_loss=0.143]\n","steps:  17%|â–ˆâ–‹        | 87/500 [03:08<14:55,  2.17s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 88/500 [03:09<14:46,  2.15s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 88/500 [03:09<14:46,  2.15s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 88/500 [03:09<14:48,  2.16s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 88/500 [03:10<14:50,  2.16s/it, avr_loss=0.144]\n","steps:  18%|â–ˆâ–Š        | 88/500 [03:10<14:52,  2.17s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 89/500 [03:11<14:43,  2.15s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 89/500 [03:11<14:43,  2.15s/it, avr_loss=0.145]\n","steps:  18%|â–ˆâ–Š        | 89/500 [03:11<14:45,  2.15s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 89/500 [03:12<14:47,  2.16s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 89/500 [03:12<14:49,  2.17s/it, avr_loss=0.145]\n","steps:  18%|â–ˆâ–Š        | 90/500 [03:13<14:40,  2.15s/it, avr_loss=0.145]\n","steps:  18%|â–ˆâ–Š        | 90/500 [03:13<14:40,  2.15s/it, avr_loss=0.145]\n","steps:  18%|â–ˆâ–Š        | 90/500 [03:13<14:42,  2.15s/it, avr_loss=0.142]\n","steps:  18%|â–ˆâ–Š        | 90/500 [03:14<14:44,  2.16s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 90/500 [03:14<14:47,  2.16s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 91/500 [03:15<14:37,  2.15s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 91/500 [03:15<14:37,  2.15s/it, avr_loss=0.143]\n","steps:  18%|â–ˆâ–Š        | 91/500 [03:15<14:39,  2.15s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 91/500 [03:16<14:42,  2.16s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 91/500 [03:16<14:44,  2.16s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 92/500 [03:17<14:35,  2.14s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 92/500 [03:17<14:35,  2.14s/it, avr_loss=0.144]\n","steps:  18%|â–ˆâ–Š        | 92/500 [03:17<14:37,  2.15s/it, avr_loss=0.146]\n","steps:  18%|â–ˆâ–Š        | 92/500 [03:18<14:39,  2.16s/it, avr_loss=0.149]\n","steps:  18%|â–ˆâ–Š        | 92/500 [03:18<14:42,  2.16s/it, avr_loss=0.149]\n","steps:  19%|â–ˆâ–Š        | 93/500 [03:19<14:33,  2.15s/it, avr_loss=0.149]\n","steps:  19%|â–ˆâ–Š        | 93/500 [03:19<14:33,  2.15s/it, avr_loss=0.149]\n","steps:  19%|â–ˆâ–Š        | 93/500 [03:20<14:35,  2.15s/it, avr_loss=0.149]\n","steps:  19%|â–ˆâ–Š        | 93/500 [03:20<14:38,  2.16s/it, avr_loss=0.148]\n","steps:  19%|â–ˆâ–Š        | 93/500 [03:21<14:40,  2.16s/it, avr_loss=0.148]\n","steps:  19%|â–ˆâ–‰        | 94/500 [03:21<14:31,  2.15s/it, avr_loss=0.148]\n","steps:  19%|â–ˆâ–‰        | 94/500 [03:21<14:31,  2.15s/it, avr_loss=0.15]\n","steps:  19%|â–ˆâ–‰        | 94/500 [03:22<14:33,  2.15s/it, avr_loss=0.151]\n","steps:  19%|â–ˆâ–‰        | 94/500 [03:22<14:35,  2.16s/it, avr_loss=0.151]\n","steps:  19%|â–ˆâ–‰        | 94/500 [03:23<14:37,  2.16s/it, avr_loss=0.15]\n","steps:  19%|â–ˆâ–‰        | 95/500 [03:23<14:28,  2.15s/it, avr_loss=0.15]\n","steps:  19%|â–ˆâ–‰        | 95/500 [03:23<14:29,  2.15s/it, avr_loss=0.152]\n","steps:  19%|â–ˆâ–‰        | 95/500 [03:24<14:31,  2.15s/it, avr_loss=0.153]\n","steps:  19%|â–ˆâ–‰        | 95/500 [03:24<14:33,  2.16s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 95/500 [03:25<14:35,  2.16s/it, avr_loss=0.155]\n","steps:  19%|â–ˆâ–‰        | 96/500 [03:25<14:26,  2.14s/it, avr_loss=0.155]\n","steps:  19%|â–ˆâ–‰        | 96/500 [03:25<14:26,  2.14s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 96/500 [03:26<14:28,  2.15s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 96/500 [03:26<14:30,  2.15s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 96/500 [03:27<14:32,  2.16s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 97/500 [03:27<14:23,  2.14s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 97/500 [03:27<14:23,  2.14s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 97/500 [03:28<14:25,  2.15s/it, avr_loss=0.154]\n","steps:  19%|â–ˆâ–‰        | 97/500 [03:28<14:27,  2.15s/it, avr_loss=0.156]\n","steps:  19%|â–ˆâ–‰        | 97/500 [03:29<14:29,  2.16s/it, avr_loss=0.157]\n","steps:  20%|â–ˆâ–‰        | 98/500 [03:29<14:21,  2.14s/it, avr_loss=0.157]\n","steps:  20%|â–ˆâ–‰        | 98/500 [03:29<14:21,  2.14s/it, avr_loss=0.159]\n","steps:  20%|â–ˆâ–‰        | 98/500 [03:30<14:23,  2.15s/it, avr_loss=0.156]\n","steps:  20%|â–ˆâ–‰        | 98/500 [03:30<14:25,  2.15s/it, avr_loss=0.156]\n","steps:  20%|â–ˆâ–‰        | 98/500 [03:31<14:27,  2.16s/it, avr_loss=0.157]\n","steps:  20%|â–ˆâ–‰        | 99/500 [03:32<14:19,  2.14s/it, avr_loss=0.157]\n","steps:  20%|â–ˆâ–‰        | 99/500 [03:32<14:19,  2.14s/it, avr_loss=0.156]\n","steps:  20%|â–ˆâ–‰        | 99/500 [03:32<14:21,  2.15s/it, avr_loss=0.156]\n","steps:  20%|â–ˆâ–‰        | 99/500 [03:33<14:24,  2.16s/it, avr_loss=0.156]\n","steps:  20%|â–ˆâ–‰        | 99/500 [03:33<14:26,  2.16s/it, avr_loss=0.157]\n","steps:  20%|â–ˆâ–ˆ        | 100/500 [03:34<14:19,  2.15s/it, avr_loss=0.157]\n","steps:  20%|â–ˆâ–ˆ        | 100/500 [03:34<14:19,  2.15s/it, avr_loss=0.153]\n","saving checkpoint: /content/drive/MyDrive/AI/training/Rezcty_project/model/Rezcty_project-000002.safetensors\n","\n","epoch 3/10\n","epoch is incremented. current_epoch: 0, epoch: 3\n","epoch is incremented. current_epoch: 0, epoch: 3\n","\n","steps:  20%|â–ˆâ–ˆ        | 100/500 [03:36<14:27,  2.17s/it, avr_loss=0.153]\n","steps:  20%|â–ˆâ–ˆ        | 100/500 [03:37<14:29,  2.17s/it, avr_loss=0.154]\n","steps:  20%|â–ˆâ–ˆ        | 100/500 [03:37<14:31,  2.18s/it, avr_loss=0.153]\n","steps:  20%|â–ˆâ–ˆ        | 101/500 [03:38<14:23,  2.16s/it, avr_loss=0.153]\n","steps:  20%|â–ˆâ–ˆ        | 101/500 [03:38<14:23,  2.16s/it, avr_loss=0.153]\n","steps:  20%|â–ˆâ–ˆ        | 101/500 [03:38<14:25,  2.17s/it, avr_loss=0.155]\n","steps:  20%|â–ˆâ–ˆ        | 101/500 [03:39<14:26,  2.17s/it, avr_loss=0.154]\n","steps:  20%|â–ˆâ–ˆ        | 101/500 [03:39<14:28,  2.18s/it, avr_loss=0.154]\n","steps:  20%|â–ˆâ–ˆ        | 102/500 [03:40<14:20,  2.16s/it, avr_loss=0.154]\n","steps:  20%|â–ˆâ–ˆ        | 102/500 [03:40<14:20,  2.16s/it, avr_loss=0.154]\n","steps:  20%|â–ˆâ–ˆ        | 102/500 [03:40<14:22,  2.17s/it, avr_loss=0.154]\n","steps:  20%|â–ˆâ–ˆ        | 102/500 [03:41<14:24,  2.17s/it, avr_loss=0.154]\n","steps:  20%|â–ˆâ–ˆ        | 102/500 [03:41<14:26,  2.18s/it, avr_loss=0.154]\n","steps:  21%|â–ˆâ–ˆ        | 103/500 [03:42<14:17,  2.16s/it, avr_loss=0.154]\n","steps:  21%|â–ˆâ–ˆ        | 103/500 [03:42<14:17,  2.16s/it, avr_loss=0.154]\n","steps:  21%|â–ˆâ–ˆ        | 103/500 [03:43<14:19,  2.17s/it, avr_loss=0.153]\n","steps:  21%|â–ˆâ–ˆ        | 103/500 [03:43<14:21,  2.17s/it, avr_loss=0.149]\n","steps:  21%|â–ˆâ–ˆ        | 103/500 [03:44<14:23,  2.17s/it, avr_loss=0.149]\n","steps:  21%|â–ˆâ–ˆ        | 104/500 [03:44<14:15,  2.16s/it, avr_loss=0.149]\n","steps:  21%|â–ˆâ–ˆ        | 104/500 [03:44<14:15,  2.16s/it, avr_loss=0.148]\n","steps:  21%|â–ˆâ–ˆ        | 104/500 [03:45<14:17,  2.16s/it, avr_loss=0.147]\n","steps:  21%|â–ˆâ–ˆ        | 104/500 [03:45<14:19,  2.17s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 104/500 [03:46<14:21,  2.17s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 105/500 [03:46<14:13,  2.16s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 105/500 [03:46<14:13,  2.16s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 105/500 [03:47<14:15,  2.17s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 105/500 [03:47<14:17,  2.17s/it, avr_loss=0.145]\n","steps:  21%|â–ˆâ–ˆ        | 105/500 [03:48<14:19,  2.18s/it, avr_loss=0.144]\n","steps:  21%|â–ˆâ–ˆ        | 106/500 [03:49<14:11,  2.16s/it, avr_loss=0.144]\n","steps:  21%|â–ˆâ–ˆ        | 106/500 [03:49<14:11,  2.16s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 106/500 [03:49<14:13,  2.17s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 106/500 [03:50<14:16,  2.17s/it, avr_loss=0.146]\n","steps:  21%|â–ˆâ–ˆ        | 106/500 [03:50<14:17,  2.18s/it, avr_loss=0.147]\n","steps:  21%|â–ˆâ–ˆâ–       | 107/500 [03:51<14:09,  2.16s/it, avr_loss=0.147]\n","steps:  21%|â–ˆâ–ˆâ–       | 107/500 [03:51<14:09,  2.16s/it, avr_loss=0.148]\n","steps:  21%|â–ˆâ–ˆâ–       | 107/500 [03:51<14:11,  2.17s/it, avr_loss=0.149]\n","steps:  21%|â–ˆâ–ˆâ–       | 107/500 [03:52<14:13,  2.17s/it, avr_loss=0.15]\n","steps:  21%|â–ˆâ–ˆâ–       | 107/500 [03:52<14:15,  2.18s/it, avr_loss=0.15]\n","steps:  22%|â–ˆâ–ˆâ–       | 108/500 [03:53<14:07,  2.16s/it, avr_loss=0.15]\n","steps:  22%|â–ˆâ–ˆâ–       | 108/500 [03:53<14:07,  2.16s/it, avr_loss=0.148]\n","steps:  22%|â–ˆâ–ˆâ–       | 108/500 [03:53<14:08,  2.17s/it, avr_loss=0.147]\n","steps:  22%|â–ˆâ–ˆâ–       | 108/500 [03:54<14:10,  2.17s/it, avr_loss=0.149]\n","steps:  22%|â–ˆâ–ˆâ–       | 108/500 [03:54<14:12,  2.17s/it, avr_loss=0.151]\n","steps:  22%|â–ˆâ–ˆâ–       | 109/500 [03:55<14:04,  2.16s/it, avr_loss=0.151]\n","steps:  22%|â–ˆâ–ˆâ–       | 109/500 [03:55<14:04,  2.16s/it, avr_loss=0.148]\n","steps:  22%|â–ˆâ–ˆâ–       | 109/500 [03:55<14:06,  2.16s/it, avr_loss=0.146]\n","steps:  22%|â–ˆâ–ˆâ–       | 109/500 [03:56<14:08,  2.17s/it, avr_loss=0.147]\n","steps:  22%|â–ˆâ–ˆâ–       | 109/500 [03:56<14:09,  2.17s/it, avr_loss=0.146]\n","steps:  22%|â–ˆâ–ˆâ–       | 110/500 [03:57<14:01,  2.16s/it, avr_loss=0.146]\n","steps:  22%|â–ˆâ–ˆâ–       | 110/500 [03:57<14:01,  2.16s/it, avr_loss=0.146]\n","steps:  22%|â–ˆâ–ˆâ–       | 110/500 [03:57<14:03,  2.16s/it, avr_loss=0.147]\n","steps:  22%|â–ˆâ–ˆâ–       | 110/500 [03:58<14:05,  2.17s/it, avr_loss=0.144]\n","steps:  22%|â–ˆâ–ˆâ–       | 110/500 [03:58<14:07,  2.17s/it, avr_loss=0.143]\n","steps:  22%|â–ˆâ–ˆâ–       | 111/500 [03:59<13:59,  2.16s/it, avr_loss=0.143]\n","steps:  22%|â–ˆâ–ˆâ–       | 111/500 [03:59<13:59,  2.16s/it, avr_loss=0.143]\n","steps:  22%|â–ˆâ–ˆâ–       | 111/500 [03:59<14:01,  2.16s/it, avr_loss=0.145]\n","steps:  22%|â–ˆâ–ˆâ–       | 111/500 [04:00<14:03,  2.17s/it, avr_loss=0.147]\n","steps:  22%|â–ˆâ–ˆâ–       | 111/500 [04:01<14:04,  2.17s/it, avr_loss=0.147]\n","steps:  22%|â–ˆâ–ˆâ–       | 112/500 [04:01<13:57,  2.16s/it, avr_loss=0.147]\n","steps:  22%|â–ˆâ–ˆâ–       | 112/500 [04:01<13:57,  2.16s/it, avr_loss=0.148]\n","steps:  22%|â–ˆâ–ˆâ–       | 112/500 [04:02<13:59,  2.16s/it, avr_loss=0.145]\n","steps:  22%|â–ˆâ–ˆâ–       | 112/500 [04:02<14:01,  2.17s/it, avr_loss=0.145]\n","steps:  22%|â–ˆâ–ˆâ–       | 112/500 [04:03<14:03,  2.17s/it, avr_loss=0.144]\n","steps:  23%|â–ˆâ–ˆâ–       | 113/500 [04:04<13:55,  2.16s/it, avr_loss=0.144]\n","steps:  23%|â–ˆâ–ˆâ–       | 113/500 [04:04<13:55,  2.16s/it, avr_loss=0.144]\n","steps:  23%|â–ˆâ–ˆâ–       | 113/500 [04:04<13:57,  2.16s/it, avr_loss=0.144]\n","steps:  23%|â–ˆâ–ˆâ–       | 113/500 [04:04<13:59,  2.17s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 113/500 [04:05<14:00,  2.17s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 114/500 [04:06<13:53,  2.16s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 114/500 [04:06<13:53,  2.16s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 114/500 [04:06<13:54,  2.16s/it, avr_loss=0.146]\n","steps:  23%|â–ˆâ–ˆâ–       | 114/500 [04:07<13:56,  2.17s/it, avr_loss=0.146]\n","steps:  23%|â–ˆâ–ˆâ–       | 114/500 [04:07<13:58,  2.17s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 115/500 [04:08<13:50,  2.16s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 115/500 [04:08<13:50,  2.16s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 115/500 [04:08<13:52,  2.16s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 115/500 [04:09<13:53,  2.17s/it, avr_loss=0.144]\n","steps:  23%|â–ˆâ–ˆâ–       | 115/500 [04:09<13:55,  2.17s/it, avr_loss=0.144]\n","steps:  23%|â–ˆâ–ˆâ–       | 116/500 [04:10<13:47,  2.16s/it, avr_loss=0.144]\n","steps:  23%|â–ˆâ–ˆâ–       | 116/500 [04:10<13:47,  2.16s/it, avr_loss=0.145]\n","steps:  23%|â–ˆâ–ˆâ–       | 116/500 [04:10<13:49,  2.16s/it, avr_loss=0.148]\n","steps:  23%|â–ˆâ–ˆâ–       | 116/500 [04:11<13:51,  2.16s/it, avr_loss=0.148]\n","steps:  23%|â–ˆâ–ˆâ–       | 116/500 [04:11<13:52,  2.17s/it, avr_loss=0.149]\n","steps:  23%|â–ˆâ–ˆâ–       | 117/500 [04:12<13:45,  2.16s/it, avr_loss=0.149]\n","steps:  23%|â–ˆâ–ˆâ–       | 117/500 [04:12<13:45,  2.16s/it, avr_loss=0.149]\n","steps:  23%|â–ˆâ–ˆâ–       | 117/500 [04:12<13:46,  2.16s/it, avr_loss=0.149]\n","steps:  23%|â–ˆâ–ˆâ–       | 117/500 [04:13<13:48,  2.16s/it, avr_loss=0.148]\n","steps:  23%|â–ˆâ–ˆâ–       | 117/500 [04:13<13:50,  2.17s/it, avr_loss=0.147]\n","steps:  24%|â–ˆâ–ˆâ–       | 118/500 [04:14<13:43,  2.16s/it, avr_loss=0.147]\n","steps:  24%|â–ˆâ–ˆâ–       | 118/500 [04:14<13:43,  2.16s/it, avr_loss=0.147]\n","steps:  24%|â–ˆâ–ˆâ–       | 118/500 [04:14<13:44,  2.16s/it, avr_loss=0.146]\n","steps:  24%|â–ˆâ–ˆâ–       | 118/500 [04:15<13:46,  2.16s/it, avr_loss=0.144]\n","steps:  24%|â–ˆâ–ˆâ–       | 118/500 [04:15<13:48,  2.17s/it, avr_loss=0.143]\n","steps:  24%|â–ˆâ–ˆâ–       | 119/500 [04:16<13:41,  2.16s/it, avr_loss=0.143]\n","steps:  24%|â–ˆâ–ˆâ–       | 119/500 [04:16<13:41,  2.16s/it, avr_loss=0.143]\n","steps:  24%|â–ˆâ–ˆâ–       | 119/500 [04:17<13:43,  2.16s/it, avr_loss=0.144]\n","steps:  24%|â–ˆâ–ˆâ–       | 119/500 [04:17<13:44,  2.17s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 119/500 [04:18<13:46,  2.17s/it, avr_loss=0.14]\n","steps:  24%|â–ˆâ–ˆâ–       | 120/500 [04:18<13:39,  2.16s/it, avr_loss=0.14]\n","steps:  24%|â–ˆâ–ˆâ–       | 120/500 [04:18<13:39,  2.16s/it, avr_loss=0.14]\n","steps:  24%|â–ˆâ–ˆâ–       | 120/500 [04:19<13:40,  2.16s/it, avr_loss=0.14]\n","steps:  24%|â–ˆâ–ˆâ–       | 120/500 [04:19<13:42,  2.16s/it, avr_loss=0.14]\n","steps:  24%|â–ˆâ–ˆâ–       | 120/500 [04:20<13:43,  2.17s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 121/500 [04:20<13:36,  2.15s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 121/500 [04:20<13:36,  2.15s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 121/500 [04:21<13:38,  2.16s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 121/500 [04:21<13:39,  2.16s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 121/500 [04:22<13:41,  2.17s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 122/500 [04:22<13:33,  2.15s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 122/500 [04:22<13:33,  2.15s/it, avr_loss=0.14]\n","steps:  24%|â–ˆâ–ˆâ–       | 122/500 [04:23<13:35,  2.16s/it, avr_loss=0.14]\n","steps:  24%|â–ˆâ–ˆâ–       | 122/500 [04:23<13:36,  2.16s/it, avr_loss=0.141]\n","steps:  24%|â–ˆâ–ˆâ–       | 122/500 [04:24<13:38,  2.17s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–       | 123/500 [04:24<13:31,  2.15s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–       | 123/500 [04:24<13:31,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–       | 123/500 [04:25<13:32,  2.16s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–       | 123/500 [04:25<13:34,  2.16s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–       | 123/500 [04:26<13:35,  2.16s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–       | 124/500 [04:26<13:28,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–       | 124/500 [04:26<13:28,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–       | 124/500 [04:27<13:30,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–       | 124/500 [04:27<13:31,  2.16s/it, avr_loss=0.142]\n","steps:  25%|â–ˆâ–ˆâ–       | 124/500 [04:28<13:33,  2.16s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 125/500 [04:28<13:26,  2.15s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 125/500 [04:28<13:26,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 125/500 [04:29<13:28,  2.16s/it, avr_loss=0.139]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 125/500 [04:30<13:30,  2.16s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 125/500 [04:30<13:31,  2.17s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 126/500 [04:31<13:25,  2.15s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 126/500 [04:31<13:25,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 126/500 [04:31<13:27,  2.16s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 126/500 [04:32<13:28,  2.16s/it, avr_loss=0.14]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 126/500 [04:32<13:30,  2.17s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 127/500 [04:33<13:23,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 127/500 [04:33<13:23,  2.15s/it, avr_loss=0.141]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 127/500 [04:33<13:24,  2.16s/it, avr_loss=0.143]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 127/500 [04:34<13:25,  2.16s/it, avr_loss=0.143]\n","steps:  25%|â–ˆâ–ˆâ–Œ       | 127/500 [04:34<13:27,  2.16s/it, avr_loss=0.143]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 128/500 [04:35<13:20,  2.15s/it, avr_loss=0.143]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 128/500 [04:35<13:20,  2.15s/it, avr_loss=0.143]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 128/500 [04:35<13:21,  2.16s/it, avr_loss=0.144]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 128/500 [04:36<13:23,  2.16s/it, avr_loss=0.143]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 128/500 [04:36<13:24,  2.16s/it, avr_loss=0.143]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 129/500 [04:37<13:17,  2.15s/it, avr_loss=0.143]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 129/500 [04:37<13:17,  2.15s/it, avr_loss=0.141]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 129/500 [04:37<13:19,  2.15s/it, avr_loss=0.141]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 129/500 [04:38<13:20,  2.16s/it, avr_loss=0.139]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 129/500 [04:38<13:22,  2.16s/it, avr_loss=0.139]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 130/500 [04:39<13:15,  2.15s/it, avr_loss=0.139]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 130/500 [04:39<13:15,  2.15s/it, avr_loss=0.139]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 130/500 [04:39<13:16,  2.15s/it, avr_loss=0.139]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 130/500 [04:40<13:18,  2.16s/it, avr_loss=0.139]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 130/500 [04:40<13:19,  2.16s/it, avr_loss=0.14]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 131/500 [04:41<13:13,  2.15s/it, avr_loss=0.14]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 131/500 [04:41<13:13,  2.15s/it, avr_loss=0.14]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 131/500 [04:42<13:14,  2.15s/it, avr_loss=0.14]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 131/500 [04:42<13:16,  2.16s/it, avr_loss=0.141]\n","steps:  26%|â–ˆâ–ˆâ–Œ       | 131/500 [04:43<13:17,  2.16s/it, avr_loss=0.141]\n","steps:  26%|â–ˆâ–ˆâ–‹       | 132/500 [04:43<13:11,  2.15s/it, avr_loss=0.141]\n","steps:  26%|â–ˆâ–ˆâ–‹       | 132/500 [04:43<13:11,  2.15s/it, avr_loss=0.141]\n","steps:  26%|â–ˆâ–ˆâ–‹       | 132/500 [04:44<13:12,  2.15s/it, avr_loss=0.145]\n","steps:  26%|â–ˆâ–ˆâ–‹       | 132/500 [04:44<13:14,  2.16s/it, avr_loss=0.142]\n","steps:  26%|â–ˆâ–ˆâ–‹       | 132/500 [04:45<13:15,  2.16s/it, avr_loss=0.141]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 133/500 [04:45<13:08,  2.15s/it, avr_loss=0.141]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 133/500 [04:45<13:08,  2.15s/it, avr_loss=0.141]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 133/500 [04:46<13:10,  2.15s/it, avr_loss=0.143]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 133/500 [04:46<13:11,  2.16s/it, avr_loss=0.143]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 133/500 [04:47<13:12,  2.16s/it, avr_loss=0.145]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 134/500 [04:47<13:06,  2.15s/it, avr_loss=0.145]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 134/500 [04:47<13:06,  2.15s/it, avr_loss=0.144]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 134/500 [04:48<13:07,  2.15s/it, avr_loss=0.141]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 134/500 [04:48<13:08,  2.16s/it, avr_loss=0.142]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 134/500 [04:49<13:10,  2.16s/it, avr_loss=0.14]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 135/500 [04:49<13:03,  2.15s/it, avr_loss=0.14]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 135/500 [04:49<13:03,  2.15s/it, avr_loss=0.142]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 135/500 [04:50<13:05,  2.15s/it, avr_loss=0.142]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 135/500 [04:50<13:06,  2.15s/it, avr_loss=0.146]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 135/500 [04:51<13:07,  2.16s/it, avr_loss=0.146]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 136/500 [04:51<13:01,  2.15s/it, avr_loss=0.146]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 136/500 [04:51<13:01,  2.15s/it, avr_loss=0.146]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 136/500 [04:52<13:02,  2.15s/it, avr_loss=0.147]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 136/500 [04:52<13:03,  2.15s/it, avr_loss=0.148]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 136/500 [04:53<13:05,  2.16s/it, avr_loss=0.148]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 137/500 [04:53<12:58,  2.15s/it, avr_loss=0.148]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 137/500 [04:53<12:58,  2.15s/it, avr_loss=0.148]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 137/500 [04:54<13:00,  2.15s/it, avr_loss=0.15]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 137/500 [04:55<13:01,  2.15s/it, avr_loss=0.148]\n","steps:  27%|â–ˆâ–ˆâ–‹       | 137/500 [04:55<13:03,  2.16s/it, avr_loss=0.148]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 138/500 [04:56<12:57,  2.15s/it, avr_loss=0.148]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 138/500 [04:56<12:57,  2.15s/it, avr_loss=0.149]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 138/500 [04:56<12:58,  2.15s/it, avr_loss=0.147]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 138/500 [04:57<13:00,  2.15s/it, avr_loss=0.147]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 138/500 [04:57<13:01,  2.16s/it, avr_loss=0.145]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 139/500 [04:58<12:54,  2.15s/it, avr_loss=0.145]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 139/500 [04:58<12:54,  2.15s/it, avr_loss=0.146]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 139/500 [04:58<12:56,  2.15s/it, avr_loss=0.147]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 139/500 [04:59<12:57,  2.15s/it, avr_loss=0.146]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 139/500 [04:59<12:58,  2.16s/it, avr_loss=0.145]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 140/500 [05:00<12:52,  2.15s/it, avr_loss=0.145]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 140/500 [05:00<12:52,  2.15s/it, avr_loss=0.145]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 140/500 [05:00<12:53,  2.15s/it, avr_loss=0.146]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 140/500 [05:01<12:54,  2.15s/it, avr_loss=0.147]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 140/500 [05:01<12:56,  2.16s/it, avr_loss=0.146]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 141/500 [05:02<12:49,  2.14s/it, avr_loss=0.146]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 141/500 [05:02<12:49,  2.14s/it, avr_loss=0.146]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 141/500 [05:02<12:51,  2.15s/it, avr_loss=0.144]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 141/500 [05:03<12:52,  2.15s/it, avr_loss=0.144]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 141/500 [05:03<12:53,  2.15s/it, avr_loss=0.144]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 142/500 [05:04<12:47,  2.14s/it, avr_loss=0.144]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 142/500 [05:04<12:47,  2.14s/it, avr_loss=0.143]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 142/500 [05:04<12:48,  2.15s/it, avr_loss=0.141]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 142/500 [05:05<12:49,  2.15s/it, avr_loss=0.138]\n","steps:  28%|â–ˆâ–ˆâ–Š       | 142/500 [05:05<12:51,  2.15s/it, avr_loss=0.139]\n","steps:  29%|â–ˆâ–ˆâ–Š       | 143/500 [05:06<12:45,  2.14s/it, avr_loss=0.139]\n","steps:  29%|â–ˆâ–ˆâ–Š       | 143/500 [05:06<12:45,  2.14s/it, avr_loss=0.139]\n","steps:  29%|â–ˆâ–ˆâ–Š       | 143/500 [05:06<12:46,  2.15s/it, avr_loss=0.138]\n","steps:  29%|â–ˆâ–ˆâ–Š       | 143/500 [05:07<12:47,  2.15s/it, avr_loss=0.139]\n","steps:  29%|â–ˆâ–ˆâ–Š       | 143/500 [05:08<12:48,  2.15s/it, avr_loss=0.139]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 144/500 [05:08<12:43,  2.14s/it, avr_loss=0.139]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 144/500 [05:08<12:43,  2.14s/it, avr_loss=0.138]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 144/500 [05:09<12:44,  2.15s/it, avr_loss=0.137]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 144/500 [05:09<12:45,  2.15s/it, avr_loss=0.137]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 144/500 [05:10<12:47,  2.16s/it, avr_loss=0.138]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 145/500 [05:10<12:41,  2.14s/it, avr_loss=0.138]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 145/500 [05:10<12:41,  2.14s/it, avr_loss=0.136]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 145/500 [05:11<12:42,  2.15s/it, avr_loss=0.137]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 145/500 [05:11<12:43,  2.15s/it, avr_loss=0.137]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 145/500 [05:12<12:44,  2.15s/it, avr_loss=0.138]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 146/500 [05:12<12:38,  2.14s/it, avr_loss=0.138]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 146/500 [05:12<12:38,  2.14s/it, avr_loss=0.137]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 146/500 [05:13<12:39,  2.15s/it, avr_loss=0.136]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 146/500 [05:13<12:41,  2.15s/it, avr_loss=0.135]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 146/500 [05:14<12:42,  2.15s/it, avr_loss=0.135]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 147/500 [05:14<12:36,  2.14s/it, avr_loss=0.135]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 147/500 [05:14<12:36,  2.14s/it, avr_loss=0.134]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 147/500 [05:15<12:37,  2.15s/it, avr_loss=0.135]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 147/500 [05:15<12:38,  2.15s/it, avr_loss=0.132]\n","steps:  29%|â–ˆâ–ˆâ–‰       | 147/500 [05:16<12:39,  2.15s/it, avr_loss=0.132]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 148/500 [05:16<12:33,  2.14s/it, avr_loss=0.132]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 148/500 [05:16<12:33,  2.14s/it, avr_loss=0.129]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 148/500 [05:17<12:35,  2.14s/it, avr_loss=0.128]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 148/500 [05:17<12:36,  2.15s/it, avr_loss=0.129]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 148/500 [05:18<12:37,  2.15s/it, avr_loss=0.127]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 149/500 [05:18<12:31,  2.14s/it, avr_loss=0.127]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 149/500 [05:18<12:31,  2.14s/it, avr_loss=0.127]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 149/500 [05:19<12:32,  2.14s/it, avr_loss=0.128]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 149/500 [05:19<12:33,  2.15s/it, avr_loss=0.129]\n","steps:  30%|â–ˆâ–ˆâ–‰       | 149/500 [05:20<12:34,  2.15s/it, avr_loss=0.13]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 150/500 [05:21<12:30,  2.14s/it, avr_loss=0.13]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 150/500 [05:21<12:30,  2.14s/it, avr_loss=0.133]\n","epoch 4/10\n","epoch is incremented. current_epoch: 0, epoch: 4\n","epoch is incremented. current_epoch: 0, epoch: 4\n","\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 150/500 [05:22<12:32,  2.15s/it, avr_loss=0.134]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 150/500 [05:22<12:33,  2.15s/it, avr_loss=0.132]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 150/500 [05:23<12:34,  2.16s/it, avr_loss=0.133]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 151/500 [05:24<12:28,  2.15s/it, avr_loss=0.133]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 151/500 [05:24<12:28,  2.15s/it, avr_loss=0.134]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 151/500 [05:24<12:30,  2.15s/it, avr_loss=0.132]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 151/500 [05:25<12:31,  2.15s/it, avr_loss=0.133]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 151/500 [05:25<12:32,  2.16s/it, avr_loss=0.133]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 152/500 [05:26<12:26,  2.14s/it, avr_loss=0.133]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 152/500 [05:26<12:26,  2.14s/it, avr_loss=0.133]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 152/500 [05:26<12:27,  2.15s/it, avr_loss=0.134]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 152/500 [05:26<12:28,  2.15s/it, avr_loss=0.137]\n","steps:  30%|â–ˆâ–ˆâ–ˆ       | 152/500 [05:27<12:29,  2.15s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 153/500 [05:28<12:23,  2.14s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 153/500 [05:28<12:23,  2.14s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 153/500 [05:28<12:25,  2.15s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 153/500 [05:28<12:26,  2.15s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 153/500 [05:29<12:27,  2.15s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 154/500 [05:30<12:21,  2.14s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 154/500 [05:30<12:21,  2.14s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 154/500 [05:30<12:22,  2.15s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 154/500 [05:30<12:23,  2.15s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 154/500 [05:31<12:24,  2.15s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 155/500 [05:31<12:18,  2.14s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 155/500 [05:31<12:18,  2.14s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 155/500 [05:32<12:20,  2.14s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 155/500 [05:32<12:21,  2.15s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 155/500 [05:33<12:22,  2.15s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 156/500 [05:33<12:16,  2.14s/it, avr_loss=0.136]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 156/500 [05:33<12:16,  2.14s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 156/500 [05:34<12:17,  2.14s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 156/500 [05:35<12:18,  2.15s/it, avr_loss=0.135]\n","steps:  31%|â–ˆâ–ˆâ–ˆ       | 156/500 [05:35<12:20,  2.15s/it, avr_loss=0.134]\n","steps:  31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [05:36<12:14,  2.14s/it, avr_loss=0.134]\n","steps:  31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [05:36<12:14,  2.14s/it, avr_loss=0.132]\n","steps:  31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [05:36<12:15,  2.15s/it, avr_loss=0.134]\n","steps:  31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [05:37<12:17,  2.15s/it, avr_loss=0.132]\n","steps:  31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [05:37<12:18,  2.15s/it, avr_loss=0.132]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [05:38<12:12,  2.14s/it, avr_loss=0.132]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [05:38<12:12,  2.14s/it, avr_loss=0.132]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [05:38<12:13,  2.15s/it, avr_loss=0.132]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [05:39<12:14,  2.15s/it, avr_loss=0.132]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [05:39<12:15,  2.15s/it, avr_loss=0.13]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [05:40<12:10,  2.14s/it, avr_loss=0.13]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [05:40<12:10,  2.14s/it, avr_loss=0.131]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [05:40<12:11,  2.14s/it, avr_loss=0.131]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [05:41<12:12,  2.15s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [05:41<12:13,  2.15s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [05:42<12:07,  2.14s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [05:42<12:07,  2.14s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [05:42<12:08,  2.14s/it, avr_loss=0.132]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [05:43<12:09,  2.15s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [05:43<12:10,  2.15s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [05:44<12:05,  2.14s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [05:44<12:05,  2.14s/it, avr_loss=0.133]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [05:44<12:06,  2.14s/it, avr_loss=0.131]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [05:45<12:07,  2.15s/it, avr_loss=0.128]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [05:45<12:08,  2.15s/it, avr_loss=0.129]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [05:46<12:02,  2.14s/it, avr_loss=0.129]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [05:46<12:02,  2.14s/it, avr_loss=0.129]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [05:46<12:03,  2.14s/it, avr_loss=0.129]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [05:47<12:04,  2.14s/it, avr_loss=0.129]\n","steps:  32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [05:47<12:05,  2.15s/it, avr_loss=0.128]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [05:48<12:00,  2.14s/it, avr_loss=0.128]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [05:48<12:00,  2.14s/it, avr_loss=0.128]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [05:49<12:01,  2.14s/it, avr_loss=0.129]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [05:49<12:02,  2.15s/it, avr_loss=0.128]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [05:50<12:04,  2.15s/it, avr_loss=0.127]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [05:50<11:58,  2.14s/it, avr_loss=0.127]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [05:50<11:58,  2.14s/it, avr_loss=0.127]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [05:51<11:59,  2.14s/it, avr_loss=0.127]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [05:51<12:00,  2.15s/it, avr_loss=0.126]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [05:52<12:01,  2.15s/it, avr_loss=0.126]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [05:52<11:56,  2.14s/it, avr_loss=0.126]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [05:52<11:56,  2.14s/it, avr_loss=0.126]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [05:53<11:57,  2.14s/it, avr_loss=0.128]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [05:53<11:58,  2.14s/it, avr_loss=0.129]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [05:54<11:59,  2.15s/it, avr_loss=0.128]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [05:54<11:54,  2.14s/it, avr_loss=0.128]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [05:54<11:54,  2.14s/it, avr_loss=0.127]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [05:55<11:54,  2.14s/it, avr_loss=0.124]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [05:55<11:55,  2.14s/it, avr_loss=0.123]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [05:56<11:56,  2.15s/it, avr_loss=0.123]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [05:56<11:51,  2.14s/it, avr_loss=0.123]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [05:56<11:51,  2.14s/it, avr_loss=0.125]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [05:57<11:52,  2.14s/it, avr_loss=0.125]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [05:57<11:53,  2.14s/it, avr_loss=0.127]\n","steps:  33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [05:58<11:54,  2.15s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [05:58<11:49,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [05:58<11:49,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [05:59<11:50,  2.14s/it, avr_loss=0.128]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [05:59<11:51,  2.14s/it, avr_loss=0.128]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [06:00<11:52,  2.14s/it, avr_loss=0.129]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [06:00<11:46,  2.14s/it, avr_loss=0.129]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [06:00<11:46,  2.14s/it, avr_loss=0.131]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [06:01<11:47,  2.14s/it, avr_loss=0.13]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [06:01<11:48,  2.14s/it, avr_loss=0.13]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [06:02<11:50,  2.15s/it, avr_loss=0.13]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [06:03<11:45,  2.14s/it, avr_loss=0.13]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [06:03<11:45,  2.14s/it, avr_loss=0.129]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [06:03<11:46,  2.14s/it, avr_loss=0.129]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [06:04<11:47,  2.14s/it, avr_loss=0.129]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [06:04<11:48,  2.15s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [06:05<11:42,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [06:05<11:42,  2.14s/it, avr_loss=0.128]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [06:05<11:43,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [06:06<11:44,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [06:06<11:45,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [06:07<11:40,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [06:07<11:40,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [06:07<11:41,  2.14s/it, avr_loss=0.127]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [06:08<11:42,  2.14s/it, avr_loss=0.126]\n","steps:  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [06:08<11:43,  2.14s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [06:09<11:38,  2.13s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [06:09<11:38,  2.13s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [06:09<11:38,  2.14s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [06:10<11:39,  2.14s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [06:10<11:40,  2.14s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [06:11<11:35,  2.13s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [06:11<11:35,  2.13s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [06:11<11:36,  2.14s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [06:12<11:37,  2.14s/it, avr_loss=0.125]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [06:12<11:38,  2.14s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [06:13<11:33,  2.13s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [06:13<11:33,  2.13s/it, avr_loss=0.125]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [06:13<11:34,  2.14s/it, avr_loss=0.125]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [06:14<11:35,  2.14s/it, avr_loss=0.126]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [06:14<11:35,  2.14s/it, avr_loss=0.125]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [06:15<11:31,  2.13s/it, avr_loss=0.125]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [06:15<11:31,  2.13s/it, avr_loss=0.124]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [06:15<11:32,  2.14s/it, avr_loss=0.122]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [06:16<11:33,  2.14s/it, avr_loss=0.122]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [06:17<11:34,  2.14s/it, avr_loss=0.123]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [06:17<11:29,  2.13s/it, avr_loss=0.123]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [06:17<11:29,  2.13s/it, avr_loss=0.123]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [06:18<11:30,  2.14s/it, avr_loss=0.122]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [06:18<11:30,  2.14s/it, avr_loss=0.123]\n","steps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [06:19<11:31,  2.14s/it, avr_loss=0.122]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [06:19<11:26,  2.13s/it, avr_loss=0.122]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [06:19<11:26,  2.13s/it, avr_loss=0.123]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [06:20<11:27,  2.14s/it, avr_loss=0.123]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [06:20<11:28,  2.14s/it, avr_loss=0.125]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [06:21<11:29,  2.14s/it, avr_loss=0.125]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [06:21<11:24,  2.13s/it, avr_loss=0.125]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [06:21<11:24,  2.13s/it, avr_loss=0.125]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [06:22<11:25,  2.13s/it, avr_loss=0.127]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [06:22<11:26,  2.14s/it, avr_loss=0.127]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [06:23<11:26,  2.14s/it, avr_loss=0.127]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [06:23<11:21,  2.13s/it, avr_loss=0.127]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [06:23<11:21,  2.13s/it, avr_loss=0.131]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [06:24<11:22,  2.13s/it, avr_loss=0.132]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [06:24<11:23,  2.14s/it, avr_loss=0.132]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [06:25<11:24,  2.14s/it, avr_loss=0.131]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [06:25<11:19,  2.13s/it, avr_loss=0.131]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [06:25<11:19,  2.13s/it, avr_loss=0.131]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [06:26<11:20,  2.13s/it, avr_loss=0.131]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [06:26<11:21,  2.14s/it, avr_loss=0.13]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [06:27<11:22,  2.14s/it, avr_loss=0.131]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [06:27<11:17,  2.13s/it, avr_loss=0.131]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [06:27<11:17,  2.13s/it, avr_loss=0.13]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [06:28<11:18,  2.13s/it, avr_loss=0.128]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [06:28<11:19,  2.14s/it, avr_loss=0.128]\n","steps:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [06:29<11:19,  2.14s/it, avr_loss=0.131]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [06:29<11:15,  2.13s/it, avr_loss=0.131]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [06:29<11:15,  2.13s/it, avr_loss=0.131]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [06:30<11:16,  2.13s/it, avr_loss=0.129]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [06:30<11:17,  2.14s/it, avr_loss=0.131]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [06:31<11:18,  2.14s/it, avr_loss=0.128]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [06:31<11:13,  2.13s/it, avr_loss=0.128]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [06:31<11:13,  2.13s/it, avr_loss=0.128]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [06:32<11:13,  2.13s/it, avr_loss=0.129]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [06:32<11:14,  2.14s/it, avr_loss=0.128]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [06:33<11:15,  2.14s/it, avr_loss=0.129]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [06:33<11:10,  2.13s/it, avr_loss=0.129]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [06:33<11:10,  2.13s/it, avr_loss=0.126]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [06:34<11:11,  2.13s/it, avr_loss=0.126]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [06:34<11:12,  2.13s/it, avr_loss=0.124]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [06:35<11:13,  2.14s/it, avr_loss=0.124]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [06:35<11:08,  2.13s/it, avr_loss=0.124]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [06:35<11:08,  2.13s/it, avr_loss=0.126]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [06:36<11:09,  2.13s/it, avr_loss=0.126]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [06:36<11:10,  2.13s/it, avr_loss=0.126]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [06:37<11:10,  2.14s/it, avr_loss=0.126]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [06:37<11:06,  2.13s/it, avr_loss=0.126]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [06:37<11:06,  2.13s/it, avr_loss=0.127]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [06:38<11:06,  2.13s/it, avr_loss=0.125]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [06:38<11:07,  2.13s/it, avr_loss=0.124]\n","steps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [06:39<11:08,  2.14s/it, avr_loss=0.125]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [06:39<11:03,  2.13s/it, avr_loss=0.125]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [06:39<11:03,  2.13s/it, avr_loss=0.125]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [06:40<11:04,  2.13s/it, avr_loss=0.126]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [06:40<11:05,  2.13s/it, avr_loss=0.128]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [06:41<11:06,  2.13s/it, avr_loss=0.128]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [06:42<11:01,  2.13s/it, avr_loss=0.128]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [06:42<11:01,  2.13s/it, avr_loss=0.127]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [06:42<11:02,  2.13s/it, avr_loss=0.127]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [06:43<11:03,  2.13s/it, avr_loss=0.127]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [06:43<11:04,  2.14s/it, avr_loss=0.128]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [06:44<10:59,  2.13s/it, avr_loss=0.128]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [06:44<10:59,  2.13s/it, avr_loss=0.129]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [06:44<11:00,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [06:45<11:01,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [06:45<11:01,  2.14s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [06:46<10:57,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [06:46<10:57,  2.13s/it, avr_loss=0.129]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [06:46<10:57,  2.13s/it, avr_loss=0.129]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [06:47<10:58,  2.13s/it, avr_loss=0.129]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [06:47<10:59,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [06:48<10:54,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [06:48<10:54,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [06:48<10:55,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [06:49<10:56,  2.13s/it, avr_loss=0.13]\n","steps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [06:49<10:57,  2.13s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [06:50<10:52,  2.12s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [06:50<10:52,  2.12s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [06:50<10:53,  2.13s/it, avr_loss=0.131]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [06:51<10:53,  2.13s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [06:51<10:54,  2.13s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [06:52<10:50,  2.12s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [06:52<10:50,  2.12s/it, avr_loss=0.131]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [06:52<10:50,  2.13s/it, avr_loss=0.131]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [06:53<10:51,  2.13s/it, avr_loss=0.132]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [06:53<10:52,  2.13s/it, avr_loss=0.131]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [06:54<10:47,  2.12s/it, avr_loss=0.131]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [06:54<10:47,  2.12s/it, avr_loss=0.131]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [06:54<10:48,  2.13s/it, avr_loss=0.129]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [06:55<10:49,  2.13s/it, avr_loss=0.129]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [06:55<10:50,  2.13s/it, avr_loss=0.128]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [06:56<10:46,  2.13s/it, avr_loss=0.128]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [06:56<10:46,  2.13s/it, avr_loss=0.128]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [06:57<10:46,  2.13s/it, avr_loss=0.128]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [06:57<10:47,  2.13s/it, avr_loss=0.128]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [06:58<10:48,  2.13s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [06:58<10:43,  2.13s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [06:58<10:43,  2.13s/it, avr_loss=0.129]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [06:59<10:44,  2.13s/it, avr_loss=0.13]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [06:59<10:45,  2.13s/it, avr_loss=0.131]\n","steps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [07:00<10:46,  2.13s/it, avr_loss=0.133]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [07:00<10:41,  2.12s/it, avr_loss=0.133]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [07:00<10:41,  2.12s/it, avr_loss=0.133]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [07:01<10:42,  2.13s/it, avr_loss=0.133]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [07:01<10:43,  2.13s/it, avr_loss=0.133]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [07:02<10:43,  2.13s/it, avr_loss=0.134]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [07:02<10:39,  2.12s/it, avr_loss=0.134]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [07:02<10:39,  2.12s/it, avr_loss=0.135]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [07:03<10:40,  2.13s/it, avr_loss=0.138]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [07:03<10:40,  2.13s/it, avr_loss=0.136]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [07:04<10:41,  2.13s/it, avr_loss=0.135]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [07:04<10:37,  2.12s/it, avr_loss=0.135]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [07:04<10:37,  2.12s/it, avr_loss=0.132]\n","saving checkpoint: /content/drive/MyDrive/AI/training/Rezcty_project/model/Rezcty_project-000004.safetensors\n","\n","epoch 5/10\n","epoch is incremented. current_epoch: 0, epoch: 5\n","epoch is incremented. current_epoch: 0, epoch: 5\n","\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [07:06<10:39,  2.13s/it, avr_loss=0.131]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [07:06<10:40,  2.13s/it, avr_loss=0.131]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [07:07<10:40,  2.14s/it, avr_loss=0.131]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [07:07<10:36,  2.13s/it, avr_loss=0.131]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [07:07<10:36,  2.13s/it, avr_loss=0.134]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [07:08<10:37,  2.13s/it, avr_loss=0.136]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [07:08<10:38,  2.13s/it, avr_loss=0.134]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [07:09<10:38,  2.14s/it, avr_loss=0.137]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [07:10<10:34,  2.13s/it, avr_loss=0.137]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [07:10<10:34,  2.13s/it, avr_loss=0.138]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [07:10<10:35,  2.13s/it, avr_loss=0.138]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [07:11<10:36,  2.13s/it, avr_loss=0.137]\n","steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [07:11<10:36,  2.14s/it, avr_loss=0.136]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [07:12<10:32,  2.13s/it, avr_loss=0.136]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [07:12<10:32,  2.13s/it, avr_loss=0.136]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [07:12<10:33,  2.13s/it, avr_loss=0.137]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [07:13<10:33,  2.13s/it, avr_loss=0.137]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [07:13<10:34,  2.14s/it, avr_loss=0.137]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [07:14<10:30,  2.13s/it, avr_loss=0.137]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [07:14<10:30,  2.13s/it, avr_loss=0.136]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [07:14<10:31,  2.13s/it, avr_loss=0.137]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [07:15<10:31,  2.13s/it, avr_loss=0.138]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [07:16<10:32,  2.14s/it, avr_loss=0.139]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [07:16<10:28,  2.13s/it, avr_loss=0.139]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [07:16<10:28,  2.13s/it, avr_loss=0.14]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [07:17<10:29,  2.13s/it, avr_loss=0.14]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [07:17<10:29,  2.13s/it, avr_loss=0.139]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [07:18<10:30,  2.14s/it, avr_loss=0.141]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [07:18<10:26,  2.13s/it, avr_loss=0.141]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [07:18<10:26,  2.13s/it, avr_loss=0.142]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [07:19<10:26,  2.13s/it, avr_loss=0.143]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [07:19<10:27,  2.13s/it, avr_loss=0.143]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [07:20<10:28,  2.14s/it, avr_loss=0.143]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [07:20<10:23,  2.13s/it, avr_loss=0.143]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [07:20<10:23,  2.13s/it, avr_loss=0.144]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [07:21<10:24,  2.13s/it, avr_loss=0.144]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [07:21<10:25,  2.13s/it, avr_loss=0.145]\n","steps:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [07:22<10:26,  2.14s/it, avr_loss=0.145]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [07:23<10:21,  2.13s/it, avr_loss=0.145]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [07:23<10:21,  2.13s/it, avr_loss=0.145]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [07:23<10:22,  2.13s/it, avr_loss=0.147]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [07:24<10:23,  2.14s/it, avr_loss=0.147]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [07:24<10:24,  2.14s/it, avr_loss=0.146]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [07:25<10:19,  2.13s/it, avr_loss=0.146]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [07:25<10:19,  2.13s/it, avr_loss=0.147]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [07:25<10:20,  2.13s/it, avr_loss=0.148]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [07:26<10:21,  2.13s/it, avr_loss=0.146]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [07:26<10:21,  2.14s/it, avr_loss=0.145]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [07:27<10:17,  2.13s/it, avr_loss=0.145]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [07:27<10:17,  2.13s/it, avr_loss=0.145]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [07:27<10:18,  2.13s/it, avr_loss=0.146]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [07:28<10:18,  2.13s/it, avr_loss=0.146]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [07:28<10:19,  2.14s/it, avr_loss=0.146]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [07:29<10:15,  2.13s/it, avr_loss=0.146]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [07:29<10:15,  2.13s/it, avr_loss=0.147]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [07:29<10:15,  2.13s/it, avr_loss=0.147]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [07:30<10:16,  2.13s/it, avr_loss=0.148]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [07:30<10:17,  2.14s/it, avr_loss=0.149]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [07:31<10:12,  2.13s/it, avr_loss=0.149]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [07:31<10:12,  2.13s/it, avr_loss=0.147]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [07:31<10:13,  2.13s/it, avr_loss=0.148]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [07:32<10:14,  2.13s/it, avr_loss=0.148]\n","steps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [07:32<10:14,  2.14s/it, avr_loss=0.149]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [07:33<10:10,  2.13s/it, avr_loss=0.149]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [07:33<10:10,  2.13s/it, avr_loss=0.152]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [07:33<10:11,  2.13s/it, avr_loss=0.153]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [07:34<10:11,  2.13s/it, avr_loss=0.153]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [07:34<10:12,  2.13s/it, avr_loss=0.153]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [07:35<10:08,  2.13s/it, avr_loss=0.153]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [07:35<10:08,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [07:35<10:09,  2.13s/it, avr_loss=0.153]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [07:36<10:10,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [07:36<10:10,  2.14s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [07:37<10:06,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [07:37<10:06,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [07:38<10:07,  2.13s/it, avr_loss=0.153]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [07:38<10:07,  2.13s/it, avr_loss=0.153]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [07:39<10:08,  2.14s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [07:39<10:04,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [07:39<10:04,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [07:40<10:04,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [07:40<10:05,  2.13s/it, avr_loss=0.155]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [07:41<10:06,  2.13s/it, avr_loss=0.156]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [07:41<10:02,  2.13s/it, avr_loss=0.156]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [07:41<10:02,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [07:42<10:02,  2.13s/it, avr_loss=0.155]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [07:42<10:03,  2.13s/it, avr_loss=0.154]\n","steps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [07:43<10:03,  2.13s/it, avr_loss=0.153]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [07:43<09:59,  2.13s/it, avr_loss=0.153]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [07:43<09:59,  2.13s/it, avr_loss=0.155]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [07:44<10:00,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [07:44<10:00,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [07:45<10:01,  2.13s/it, avr_loss=0.155]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [07:45<09:57,  2.13s/it, avr_loss=0.155]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [07:45<09:57,  2.13s/it, avr_loss=0.152]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [07:46<09:58,  2.13s/it, avr_loss=0.153]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [07:46<09:58,  2.13s/it, avr_loss=0.153]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [07:47<09:59,  2.13s/it, avr_loss=0.153]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [07:47<09:55,  2.13s/it, avr_loss=0.153]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [07:47<09:55,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [07:48<09:55,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [07:48<09:56,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [07:49<09:57,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [07:49<09:53,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [07:49<09:53,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [07:50<09:54,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [07:51<09:54,  2.13s/it, avr_loss=0.154]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [07:51<09:55,  2.13s/it, avr_loss=0.155]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [07:52<09:51,  2.13s/it, avr_loss=0.155]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [07:52<09:51,  2.13s/it, avr_loss=0.155]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [07:52<09:51,  2.13s/it, avr_loss=0.156]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [07:53<09:52,  2.13s/it, avr_loss=0.156]\n","steps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [07:53<09:53,  2.13s/it, avr_loss=0.156]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [07:54<09:49,  2.13s/it, avr_loss=0.156]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [07:54<09:49,  2.13s/it, avr_loss=0.156]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [07:54<09:49,  2.13s/it, avr_loss=0.157]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [07:55<09:50,  2.13s/it, avr_loss=0.157]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [07:55<09:50,  2.13s/it, avr_loss=0.157]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [07:56<09:46,  2.13s/it, avr_loss=0.157]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [07:56<09:46,  2.13s/it, avr_loss=0.16]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [07:56<09:47,  2.13s/it, avr_loss=0.159]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [07:57<09:47,  2.13s/it, avr_loss=0.16]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [07:57<09:48,  2.13s/it, avr_loss=0.159]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [07:58<09:44,  2.13s/it, avr_loss=0.159]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [07:58<09:44,  2.13s/it, avr_loss=0.16]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [07:58<09:45,  2.13s/it, avr_loss=0.161]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [07:59<09:45,  2.13s/it, avr_loss=0.16]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [07:59<09:46,  2.13s/it, avr_loss=0.16]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [08:00<09:42,  2.12s/it, avr_loss=0.16]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [08:00<09:42,  2.12s/it, avr_loss=0.16]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [08:00<09:42,  2.13s/it, avr_loss=0.161]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [08:01<09:43,  2.13s/it, avr_loss=0.163]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [08:01<09:44,  2.13s/it, avr_loss=0.162]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [08:02<09:40,  2.12s/it, avr_loss=0.162]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [08:02<09:40,  2.12s/it, avr_loss=0.163]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [08:02<09:40,  2.13s/it, avr_loss=0.165]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [08:03<09:41,  2.13s/it, avr_loss=0.163]\n","steps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [08:04<09:42,  2.13s/it, avr_loss=0.163]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [08:04<09:38,  2.13s/it, avr_loss=0.163]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [08:04<09:38,  2.13s/it, avr_loss=0.163]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [08:05<09:38,  2.13s/it, avr_loss=0.162]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [08:05<09:39,  2.13s/it, avr_loss=0.16]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [08:06<09:39,  2.13s/it, avr_loss=0.161]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [08:06<09:35,  2.13s/it, avr_loss=0.161]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [08:06<09:35,  2.13s/it, avr_loss=0.161]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [08:07<09:36,  2.13s/it, avr_loss=0.158]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [08:07<09:37,  2.13s/it, avr_loss=0.16]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [08:08<09:37,  2.13s/it, avr_loss=0.16]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [08:08<09:33,  2.13s/it, avr_loss=0.16]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [08:08<09:33,  2.13s/it, avr_loss=0.157]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [08:09<09:34,  2.13s/it, avr_loss=0.156]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [08:09<09:35,  2.13s/it, avr_loss=0.156]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [08:10<09:35,  2.13s/it, avr_loss=0.157]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [08:10<09:31,  2.13s/it, avr_loss=0.157]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [08:10<09:31,  2.13s/it, avr_loss=0.157]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [08:11<09:32,  2.13s/it, avr_loss=0.157]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [08:11<09:32,  2.13s/it, avr_loss=0.157]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [08:12<09:33,  2.13s/it, avr_loss=0.156]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [08:13<09:29,  2.13s/it, avr_loss=0.156]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [08:13<09:29,  2.13s/it, avr_loss=0.156]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [08:13<09:30,  2.13s/it, avr_loss=0.156]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [08:14<09:30,  2.13s/it, avr_loss=0.156]\n","steps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [08:14<09:31,  2.13s/it, avr_loss=0.153]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [08:15<09:27,  2.13s/it, avr_loss=0.153]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [08:15<09:27,  2.13s/it, avr_loss=0.153]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [08:16<09:28,  2.13s/it, avr_loss=0.153]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [08:16<09:29,  2.13s/it, avr_loss=0.152]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [08:17<09:30,  2.14s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [08:18<09:26,  2.13s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [08:18<09:26,  2.13s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [08:18<09:27,  2.13s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [08:19<09:27,  2.13s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [08:20<09:28,  2.14s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [08:20<09:24,  2.13s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [08:20<09:24,  2.13s/it, avr_loss=0.152]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [08:21<09:25,  2.13s/it, avr_loss=0.151]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [08:21<09:25,  2.13s/it, avr_loss=0.15]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [08:22<09:26,  2.14s/it, avr_loss=0.15]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [08:22<09:22,  2.13s/it, avr_loss=0.15]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [08:22<09:22,  2.13s/it, avr_loss=0.149]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [08:23<09:22,  2.13s/it, avr_loss=0.148]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [08:23<09:23,  2.13s/it, avr_loss=0.149]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [08:24<09:24,  2.14s/it, avr_loss=0.148]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [08:24<09:20,  2.13s/it, avr_loss=0.148]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [08:24<09:20,  2.13s/it, avr_loss=0.147]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [08:25<09:20,  2.13s/it, avr_loss=0.147]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [08:25<09:21,  2.13s/it, avr_loss=0.147]\n","steps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [08:26<09:21,  2.14s/it, avr_loss=0.146]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [08:26<09:18,  2.13s/it, avr_loss=0.146]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [08:26<09:18,  2.13s/it, avr_loss=0.146]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [08:27<09:18,  2.13s/it, avr_loss=0.145]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [08:27<09:19,  2.13s/it, avr_loss=0.144]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [08:28<09:19,  2.14s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [08:29<09:15,  2.13s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [08:29<09:15,  2.13s/it, avr_loss=0.144]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [08:29<09:16,  2.13s/it, avr_loss=0.145]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [08:30<09:17,  2.13s/it, avr_loss=0.145]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [08:30<09:17,  2.14s/it, avr_loss=0.144]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [08:31<09:13,  2.13s/it, avr_loss=0.144]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [08:31<09:13,  2.13s/it, avr_loss=0.144]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [08:31<09:14,  2.13s/it, avr_loss=0.141]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [08:32<09:15,  2.14s/it, avr_loss=0.141]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [08:33<09:15,  2.14s/it, avr_loss=0.142]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [08:33<09:12,  2.13s/it, avr_loss=0.142]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [08:33<09:12,  2.13s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [08:34<09:12,  2.13s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [08:34<09:13,  2.14s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [08:35<09:13,  2.14s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [08:35<09:10,  2.13s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [08:35<09:10,  2.13s/it, avr_loss=0.143]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [08:36<09:10,  2.13s/it, avr_loss=0.146]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [08:36<09:11,  2.14s/it, avr_loss=0.146]\n","steps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [08:37<09:11,  2.14s/it, avr_loss=0.145]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [08:38<09:07,  2.13s/it, avr_loss=0.145]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [08:38<09:07,  2.13s/it, avr_loss=0.144]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [08:38<09:08,  2.13s/it, avr_loss=0.145]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [08:39<09:08,  2.14s/it, avr_loss=0.146]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [08:39<09:09,  2.14s/it, avr_loss=0.147]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [08:40<09:05,  2.13s/it, avr_loss=0.147]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [08:40<09:05,  2.13s/it, avr_loss=0.145]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [08:40<09:06,  2.13s/it, avr_loss=0.145]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [08:41<09:06,  2.14s/it, avr_loss=0.145]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [08:41<09:07,  2.14s/it, avr_loss=0.144]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [08:42<09:03,  2.13s/it, avr_loss=0.144]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [08:42<09:03,  2.13s/it, avr_loss=0.143]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [08:42<09:04,  2.13s/it, avr_loss=0.143]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [08:43<09:04,  2.14s/it, avr_loss=0.143]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [08:43<09:05,  2.14s/it, avr_loss=0.143]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [08:44<09:01,  2.13s/it, avr_loss=0.143]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [08:44<09:01,  2.13s/it, avr_loss=0.144]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [08:45<09:02,  2.14s/it, avr_loss=0.143]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [08:46<09:03,  2.14s/it, avr_loss=0.143]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [08:46<09:03,  2.14s/it, avr_loss=0.142]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [08:48<09:01,  2.14s/it, avr_loss=0.142]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [08:48<09:01,  2.14s/it, avr_loss=0.142]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [08:49<09:02,  2.14s/it, avr_loss=0.14]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [08:49<09:02,  2.14s/it, avr_loss=0.14]\n","steps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [08:50<09:03,  2.15s/it, avr_loss=0.139]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [08:50<08:59,  2.14s/it, avr_loss=0.139]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [08:50<08:59,  2.14s/it, avr_loss=0.138]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [08:51<09:00,  2.14s/it, avr_loss=0.139]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [08:52<09:00,  2.15s/it, avr_loss=0.138]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [08:52<09:01,  2.15s/it, avr_loss=0.137]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [08:53<08:57,  2.14s/it, avr_loss=0.137]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [08:53<08:57,  2.14s/it, avr_loss=0.136]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [08:53<08:58,  2.14s/it, avr_loss=0.132]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [08:54<08:58,  2.15s/it, avr_loss=0.133]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [08:54<08:59,  2.15s/it, avr_loss=0.133]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [08:55<08:55,  2.14s/it, avr_loss=0.133]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [08:55<08:55,  2.14s/it, avr_loss=0.133]\n","epoch 6/10\n","epoch is incremented. current_epoch: 0, epoch: 6\n","epoch is incremented. current_epoch: 0, epoch: 6\n","\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [08:56<08:56,  2.14s/it, avr_loss=0.134]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [08:56<08:56,  2.15s/it, avr_loss=0.134]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [08:57<08:57,  2.15s/it, avr_loss=0.135]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [08:57<08:53,  2.14s/it, avr_loss=0.135]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [08:57<08:53,  2.14s/it, avr_loss=0.132]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [08:58<08:54,  2.14s/it, avr_loss=0.129]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [08:58<08:54,  2.15s/it, avr_loss=0.131]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [08:59<08:55,  2.15s/it, avr_loss=0.128]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [09:00<08:51,  2.14s/it, avr_loss=0.128]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [09:00<08:51,  2.14s/it, avr_loss=0.127]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [09:00<08:52,  2.15s/it, avr_loss=0.126]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [09:01<08:52,  2.15s/it, avr_loss=0.124]\n","steps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [09:02<08:53,  2.15s/it, avr_loss=0.124]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [09:02<08:49,  2.14s/it, avr_loss=0.124]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [09:02<08:49,  2.14s/it, avr_loss=0.126]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [09:03<08:50,  2.15s/it, avr_loss=0.126]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [09:03<08:50,  2.15s/it, avr_loss=0.126]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [09:04<08:51,  2.15s/it, avr_loss=0.125]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [09:04<08:47,  2.14s/it, avr_loss=0.125]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [09:04<08:47,  2.14s/it, avr_loss=0.126]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [09:05<08:48,  2.15s/it, avr_loss=0.125]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [09:05<08:48,  2.15s/it, avr_loss=0.125]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [09:06<08:49,  2.15s/it, avr_loss=0.124]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [09:06<08:45,  2.14s/it, avr_loss=0.124]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [09:06<08:45,  2.14s/it, avr_loss=0.123]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [09:07<08:45,  2.15s/it, avr_loss=0.124]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [09:07<08:46,  2.15s/it, avr_loss=0.124]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [09:08<08:46,  2.15s/it, avr_loss=0.122]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [09:08<08:43,  2.14s/it, avr_loss=0.122]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [09:08<08:43,  2.14s/it, avr_loss=0.121]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [09:09<08:43,  2.15s/it, avr_loss=0.12]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [09:09<08:44,  2.15s/it, avr_loss=0.12]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [09:10<08:44,  2.15s/it, avr_loss=0.119]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [09:11<08:41,  2.14s/it, avr_loss=0.119]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [09:11<08:41,  2.14s/it, avr_loss=0.118]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [09:11<08:41,  2.15s/it, avr_loss=0.117]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [09:12<08:42,  2.15s/it, avr_loss=0.117]\n","steps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [09:12<08:42,  2.15s/it, avr_loss=0.118]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [09:13<08:39,  2.15s/it, avr_loss=0.118]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [09:13<08:39,  2.15s/it, avr_loss=0.118]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [09:14<08:39,  2.15s/it, avr_loss=0.117]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [09:14<08:40,  2.15s/it, avr_loss=0.117]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [09:15<08:40,  2.15s/it, avr_loss=0.117]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [09:16<08:37,  2.15s/it, avr_loss=0.117]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [09:16<08:37,  2.15s/it, avr_loss=0.117]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [09:16<08:37,  2.15s/it, avr_loss=0.117]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [09:17<08:38,  2.15s/it, avr_loss=0.116]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [09:17<08:38,  2.15s/it, avr_loss=0.116]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [09:18<08:35,  2.15s/it, avr_loss=0.116]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [09:18<08:35,  2.15s/it, avr_loss=0.116]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [09:18<08:35,  2.15s/it, avr_loss=0.115]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [09:19<08:36,  2.15s/it, avr_loss=0.113]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [09:19<08:36,  2.15s/it, avr_loss=0.112]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [09:20<08:33,  2.15s/it, avr_loss=0.112]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [09:20<08:33,  2.15s/it, avr_loss=0.112]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [09:20<08:33,  2.15s/it, avr_loss=0.112]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [09:21<08:34,  2.15s/it, avr_loss=0.112]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [09:21<08:34,  2.15s/it, avr_loss=0.112]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [09:22<08:31,  2.15s/it, avr_loss=0.112]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [09:22<08:31,  2.15s/it, avr_loss=0.113]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [09:23<08:31,  2.15s/it, avr_loss=0.113]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [09:23<08:31,  2.15s/it, avr_loss=0.114]\n","steps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [09:24<08:32,  2.15s/it, avr_loss=0.114]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [09:24<08:28,  2.15s/it, avr_loss=0.114]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [09:24<08:28,  2.15s/it, avr_loss=0.111]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [09:25<08:29,  2.15s/it, avr_loss=0.109]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [09:25<08:29,  2.15s/it, avr_loss=0.11]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [09:26<08:30,  2.15s/it, avr_loss=0.111]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [09:27<08:26,  2.15s/it, avr_loss=0.111]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [09:27<08:26,  2.15s/it, avr_loss=0.111]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [09:27<08:27,  2.15s/it, avr_loss=0.114]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [09:28<08:27,  2.15s/it, avr_loss=0.115]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [09:28<08:28,  2.15s/it, avr_loss=0.115]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [09:29<08:25,  2.15s/it, avr_loss=0.115]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [09:29<08:25,  2.15s/it, avr_loss=0.114]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [09:30<08:25,  2.15s/it, avr_loss=0.114]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [09:30<08:26,  2.15s/it, avr_loss=0.113]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [09:31<08:26,  2.16s/it, avr_loss=0.112]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [09:31<08:22,  2.15s/it, avr_loss=0.112]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [09:31<08:22,  2.15s/it, avr_loss=0.112]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [09:32<08:23,  2.15s/it, avr_loss=0.111]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [09:32<08:23,  2.15s/it, avr_loss=0.111]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [09:33<08:24,  2.16s/it, avr_loss=0.112]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [09:33<08:20,  2.15s/it, avr_loss=0.112]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [09:33<08:20,  2.15s/it, avr_loss=0.112]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [09:34<08:21,  2.15s/it, avr_loss=0.112]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [09:34<08:21,  2.15s/it, avr_loss=0.111]\n","steps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [09:35<08:22,  2.15s/it, avr_loss=0.112]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [09:35<08:18,  2.15s/it, avr_loss=0.112]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [09:35<08:18,  2.15s/it, avr_loss=0.11]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [09:36<08:19,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [09:36<08:19,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [09:37<08:19,  2.15s/it, avr_loss=0.112]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [09:38<08:16,  2.15s/it, avr_loss=0.112]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [09:38<08:16,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [09:38<08:16,  2.15s/it, avr_loss=0.11]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [09:39<08:17,  2.15s/it, avr_loss=0.11]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [09:39<08:17,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [09:40<08:14,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [09:40<08:14,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [09:40<08:14,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [09:41<08:15,  2.15s/it, avr_loss=0.111]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [09:42<08:15,  2.16s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [09:42<08:12,  2.15s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [09:42<08:12,  2.15s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [09:43<08:12,  2.15s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [09:43<08:13,  2.15s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [09:44<08:13,  2.16s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [09:45<08:10,  2.15s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [09:45<08:10,  2.15s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [09:45<08:10,  2.15s/it, avr_loss=0.113]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [09:46<08:11,  2.15s/it, avr_loss=0.114]\n","steps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [09:46<08:11,  2.16s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [09:47<08:08,  2.15s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [09:47<08:08,  2.15s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [09:47<08:08,  2.15s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [09:48<08:09,  2.15s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [09:48<08:09,  2.16s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [09:49<08:06,  2.15s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [09:49<08:06,  2.15s/it, avr_loss=0.115]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [09:49<08:06,  2.15s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [09:50<08:07,  2.15s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [09:50<08:07,  2.16s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [09:51<08:03,  2.15s/it, avr_loss=0.116]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [09:51<08:03,  2.15s/it, avr_loss=0.115]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [09:52<08:04,  2.15s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [09:52<08:04,  2.15s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [09:53<08:05,  2.16s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [09:53<08:01,  2.15s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [09:53<08:01,  2.15s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [09:54<08:02,  2.15s/it, avr_loss=0.114]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [09:54<08:02,  2.16s/it, avr_loss=0.112]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [09:55<08:03,  2.16s/it, avr_loss=0.112]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [09:56<07:59,  2.15s/it, avr_loss=0.112]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [09:56<07:59,  2.15s/it, avr_loss=0.11]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [09:56<08:00,  2.15s/it, avr_loss=0.109]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [09:57<08:00,  2.16s/it, avr_loss=0.11]\n","steps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [09:57<08:01,  2.16s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [09:58<07:57,  2.15s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [09:58<07:57,  2.15s/it, avr_loss=0.111]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [09:59<07:58,  2.15s/it, avr_loss=0.113]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [09:59<07:58,  2.16s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [10:00<07:59,  2.16s/it, avr_loss=0.113]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [10:00<07:55,  2.15s/it, avr_loss=0.113]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [10:00<07:55,  2.15s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [10:01<07:56,  2.15s/it, avr_loss=0.113]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [10:01<07:56,  2.16s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [10:02<07:57,  2.16s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [10:02<07:53,  2.15s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [10:02<07:53,  2.15s/it, avr_loss=0.11]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [10:03<07:54,  2.15s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [10:03<07:54,  2.16s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [10:04<07:54,  2.16s/it, avr_loss=0.11]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [10:04<07:51,  2.15s/it, avr_loss=0.11]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [10:04<07:51,  2.15s/it, avr_loss=0.11]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [10:05<07:51,  2.15s/it, avr_loss=0.11]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [10:05<07:52,  2.16s/it, avr_loss=0.11]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [10:06<07:52,  2.16s/it, avr_loss=0.111]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [10:07<07:49,  2.15s/it, avr_loss=0.111]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [10:07<07:49,  2.15s/it, avr_loss=0.111]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [10:07<07:49,  2.15s/it, avr_loss=0.112]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [10:08<07:50,  2.16s/it, avr_loss=0.113]\n","steps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [10:08<07:50,  2.16s/it, avr_loss=0.112]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [10:09<07:47,  2.15s/it, avr_loss=0.112]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [10:09<07:47,  2.15s/it, avr_loss=0.113]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [10:10<07:47,  2.16s/it, avr_loss=0.114]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [10:10<07:48,  2.16s/it, avr_loss=0.114]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [10:11<07:48,  2.16s/it, avr_loss=0.115]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [10:11<07:45,  2.15s/it, avr_loss=0.115]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [10:11<07:45,  2.15s/it, avr_loss=0.116]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [10:12<07:45,  2.16s/it, avr_loss=0.115]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [10:13<07:46,  2.16s/it, avr_loss=0.116]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [10:13<07:46,  2.16s/it, avr_loss=0.116]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [10:14<07:43,  2.15s/it, avr_loss=0.116]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [10:14<07:43,  2.15s/it, avr_loss=0.116]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [10:14<07:43,  2.16s/it, avr_loss=0.116]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [10:15<07:44,  2.16s/it, avr_loss=0.117]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [10:15<07:44,  2.16s/it, avr_loss=0.118]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [10:16<07:41,  2.16s/it, avr_loss=0.118]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [10:16<07:41,  2.16s/it, avr_loss=0.118]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [10:16<07:41,  2.16s/it, avr_loss=0.119]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [10:17<07:41,  2.16s/it, avr_loss=0.119]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [10:17<07:42,  2.16s/it, avr_loss=0.119]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [10:18<07:39,  2.16s/it, avr_loss=0.119]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [10:18<07:39,  2.16s/it, avr_loss=0.119]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [10:19<07:39,  2.16s/it, avr_loss=0.118]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [10:19<07:39,  2.16s/it, avr_loss=0.118]\n","steps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [10:20<07:40,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [10:20<07:36,  2.15s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [10:20<07:36,  2.15s/it, avr_loss=0.119]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [10:21<07:37,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [10:21<07:37,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [10:22<07:38,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [10:22<07:34,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [10:22<07:34,  2.16s/it, avr_loss=0.116]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [10:23<07:35,  2.16s/it, avr_loss=0.115]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [10:24<07:35,  2.16s/it, avr_loss=0.115]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [10:24<07:36,  2.16s/it, avr_loss=0.115]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [10:25<07:32,  2.16s/it, avr_loss=0.115]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [10:25<07:32,  2.16s/it, avr_loss=0.115]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [10:25<07:33,  2.16s/it, avr_loss=0.114]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [10:26<07:33,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [10:26<07:34,  2.16s/it, avr_loss=0.117]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [10:27<07:30,  2.16s/it, avr_loss=0.117]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [10:27<07:30,  2.16s/it, avr_loss=0.116]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [10:28<07:31,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [10:28<07:31,  2.16s/it, avr_loss=0.118]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [10:29<07:31,  2.16s/it, avr_loss=0.119]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [10:29<07:28,  2.16s/it, avr_loss=0.119]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [10:29<07:28,  2.16s/it, avr_loss=0.12]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [10:30<07:28,  2.16s/it, avr_loss=0.116]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [10:30<07:29,  2.16s/it, avr_loss=0.116]\n","steps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [10:31<07:29,  2.16s/it, avr_loss=0.116]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [10:31<07:26,  2.16s/it, avr_loss=0.116]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [10:31<07:26,  2.16s/it, avr_loss=0.116]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [10:32<07:26,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [10:32<07:27,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [10:33<07:27,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [10:33<07:24,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [10:33<07:24,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [10:34<07:24,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [10:34<07:24,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [10:35<07:25,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [10:36<07:22,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [10:36<07:22,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [10:36<07:22,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [10:37<07:22,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [10:37<07:23,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [10:38<07:20,  2.16s/it, avr_loss=0.114]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [10:38<07:20,  2.16s/it, avr_loss=0.113]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [10:39<07:20,  2.16s/it, avr_loss=0.113]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [10:39<07:20,  2.16s/it, avr_loss=0.113]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [10:40<07:21,  2.16s/it, avr_loss=0.113]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [10:40<07:18,  2.16s/it, avr_loss=0.113]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [10:40<07:18,  2.16s/it, avr_loss=0.113]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [10:41<07:18,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [10:41<07:18,  2.16s/it, avr_loss=0.115]\n","steps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [10:42<07:19,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [10:43<07:15,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [10:43<07:15,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [10:43<07:16,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [10:44<07:16,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [10:44<07:16,  2.16s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [10:45<07:13,  2.16s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [10:45<07:13,  2.16s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [10:45<07:14,  2.16s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [10:46<07:14,  2.16s/it, avr_loss=0.118]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [10:46<07:14,  2.16s/it, avr_loss=0.118]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [10:47<07:11,  2.16s/it, avr_loss=0.118]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [10:47<07:11,  2.16s/it, avr_loss=0.118]\n","saving checkpoint: /content/drive/MyDrive/AI/training/Rezcty_project/model/Rezcty_project-000006.safetensors\n","\n","epoch 7/10\n","epoch is incremented. current_epoch: 0, epoch: 7\n","epoch is incremented. current_epoch: 0, epoch: 7\n","\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [10:48<07:12,  2.16s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [10:49<07:13,  2.17s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [10:50<07:13,  2.17s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [10:50<07:10,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [10:50<07:10,  2.16s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [10:51<07:10,  2.16s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [10:51<07:11,  2.17s/it, avr_loss=0.114]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [10:52<07:11,  2.17s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [10:53<07:08,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [10:53<07:08,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [10:53<07:08,  2.16s/it, avr_loss=0.115]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [10:54<07:08,  2.17s/it, avr_loss=0.116]\n","steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [10:54<07:09,  2.17s/it, avr_loss=0.117]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [10:55<07:06,  2.16s/it, avr_loss=0.117]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [10:55<07:06,  2.16s/it, avr_loss=0.115]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [10:56<07:06,  2.17s/it, avr_loss=0.119]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [10:56<07:06,  2.17s/it, avr_loss=0.12]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [10:57<07:07,  2.17s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [10:57<07:04,  2.16s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [10:57<07:04,  2.16s/it, avr_loss=0.12]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [10:58<07:04,  2.17s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [10:58<07:04,  2.17s/it, avr_loss=0.12]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [10:59<07:05,  2.17s/it, avr_loss=0.12]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [10:59<07:01,  2.16s/it, avr_loss=0.12]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [10:59<07:01,  2.16s/it, avr_loss=0.122]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [11:00<07:02,  2.17s/it, avr_loss=0.122]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [11:00<07:02,  2.17s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [11:01<07:02,  2.17s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [11:01<06:59,  2.16s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [11:01<06:59,  2.16s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [11:02<07:00,  2.16s/it, avr_loss=0.121]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [11:03<07:00,  2.17s/it, avr_loss=0.122]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [11:03<07:00,  2.17s/it, avr_loss=0.123]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [11:04<06:57,  2.16s/it, avr_loss=0.123]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [11:04<06:57,  2.16s/it, avr_loss=0.123]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [11:04<06:58,  2.17s/it, avr_loss=0.124]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [11:05<06:58,  2.17s/it, avr_loss=0.123]\n","steps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [11:06<06:58,  2.17s/it, avr_loss=0.125]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [11:06<06:55,  2.17s/it, avr_loss=0.125]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [11:06<06:55,  2.17s/it, avr_loss=0.125]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [11:07<06:56,  2.17s/it, avr_loss=0.124]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [11:07<06:56,  2.17s/it, avr_loss=0.124]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [11:08<06:56,  2.17s/it, avr_loss=0.124]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [11:09<06:53,  2.17s/it, avr_loss=0.124]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [11:09<06:53,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [11:09<06:53,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [11:10<06:54,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [11:10<06:54,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [11:11<06:51,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [11:11<06:51,  2.17s/it, avr_loss=0.122]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [11:11<06:51,  2.17s/it, avr_loss=0.122]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [11:12<06:52,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [11:12<06:52,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [11:13<06:49,  2.17s/it, avr_loss=0.123]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [11:13<06:49,  2.17s/it, avr_loss=0.122]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [11:13<06:49,  2.17s/it, avr_loss=0.122]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [11:14<06:49,  2.17s/it, avr_loss=0.121]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [11:14<06:50,  2.17s/it, avr_loss=0.12]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [11:15<06:47,  2.17s/it, avr_loss=0.12]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [11:15<06:47,  2.17s/it, avr_loss=0.118]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [11:15<06:47,  2.17s/it, avr_loss=0.118]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [11:16<06:47,  2.17s/it, avr_loss=0.118]\n","steps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [11:17<06:47,  2.17s/it, avr_loss=0.117]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [11:17<06:44,  2.17s/it, avr_loss=0.117]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [11:17<06:44,  2.17s/it, avr_loss=0.117]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [11:18<06:45,  2.17s/it, avr_loss=0.116]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [11:18<06:45,  2.17s/it, avr_loss=0.119]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [11:19<06:46,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [11:20<06:42,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [11:20<06:42,  2.17s/it, avr_loss=0.119]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [11:20<06:43,  2.17s/it, avr_loss=0.117]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [11:21<06:43,  2.17s/it, avr_loss=0.115]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [11:21<06:43,  2.17s/it, avr_loss=0.116]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [11:22<06:40,  2.17s/it, avr_loss=0.116]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [11:22<06:40,  2.17s/it, avr_loss=0.116]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [11:23<06:41,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [11:23<06:41,  2.17s/it, avr_loss=0.117]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [11:24<06:41,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [11:24<06:38,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [11:24<06:38,  2.17s/it, avr_loss=0.119]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [11:25<06:38,  2.17s/it, avr_loss=0.119]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [11:25<06:39,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [11:26<06:39,  2.17s/it, avr_loss=0.117]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [11:26<06:36,  2.17s/it, avr_loss=0.117]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [11:26<06:36,  2.17s/it, avr_loss=0.116]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [11:27<06:36,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [11:27<06:37,  2.17s/it, avr_loss=0.118]\n","steps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [11:28<06:37,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [11:28<06:34,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [11:28<06:34,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [11:29<06:34,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [11:29<06:34,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [11:30<06:35,  2.17s/it, avr_loss=0.115]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [11:31<06:32,  2.17s/it, avr_loss=0.115]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [11:31<06:32,  2.17s/it, avr_loss=0.115]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [11:31<06:32,  2.17s/it, avr_loss=0.116]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [11:32<06:32,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [11:32<06:33,  2.17s/it, avr_loss=0.116]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [11:33<06:30,  2.17s/it, avr_loss=0.116]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [11:33<06:30,  2.17s/it, avr_loss=0.115]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [11:34<06:30,  2.17s/it, avr_loss=0.116]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [11:34<06:30,  2.17s/it, avr_loss=0.116]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [11:35<06:31,  2.17s/it, avr_loss=0.114]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [11:35<06:28,  2.17s/it, avr_loss=0.114]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [11:35<06:28,  2.17s/it, avr_loss=0.115]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [11:36<06:28,  2.17s/it, avr_loss=0.116]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [11:37<06:28,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [11:37<06:28,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [11:38<06:25,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [11:38<06:25,  2.17s/it, avr_loss=0.117]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [11:38<06:26,  2.17s/it, avr_loss=0.116]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [11:39<06:26,  2.17s/it, avr_loss=0.115]\n","steps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [11:39<06:26,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [11:40<06:23,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [11:40<06:23,  2.17s/it, avr_loss=0.118]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [11:40<06:24,  2.17s/it, avr_loss=0.115]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [11:41<06:24,  2.17s/it, avr_loss=0.115]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [11:41<06:24,  2.17s/it, avr_loss=0.115]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [11:42<06:21,  2.17s/it, avr_loss=0.115]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [11:42<06:21,  2.17s/it, avr_loss=0.115]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [11:42<06:21,  2.17s/it, avr_loss=0.115]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [11:43<06:22,  2.17s/it, avr_loss=0.115]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [11:43<06:22,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [11:44<06:19,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [11:44<06:19,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [11:45<06:19,  2.17s/it, avr_loss=0.118]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [11:45<06:19,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [11:46<06:20,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [11:46<06:17,  2.17s/it, avr_loss=0.117]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [11:46<06:17,  2.17s/it, avr_loss=0.118]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [11:47<06:17,  2.17s/it, avr_loss=0.118]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [11:48<06:17,  2.17s/it, avr_loss=0.119]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [11:48<06:18,  2.17s/it, avr_loss=0.119]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [11:49<06:15,  2.17s/it, avr_loss=0.119]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [11:49<06:15,  2.17s/it, avr_loss=0.119]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [11:49<06:15,  2.17s/it, avr_loss=0.119]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [11:50<06:15,  2.17s/it, avr_loss=0.119]\n","steps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [11:50<06:16,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [11:51<06:13,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [11:51<06:13,  2.17s/it, avr_loss=0.119]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [11:52<06:13,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [11:52<06:13,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [11:53<06:13,  2.17s/it, avr_loss=0.117]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [11:53<06:10,  2.17s/it, avr_loss=0.117]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [11:53<06:10,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [11:54<06:11,  2.17s/it, avr_loss=0.117]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [11:54<06:11,  2.17s/it, avr_loss=0.117]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [11:55<06:11,  2.17s/it, avr_loss=0.117]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [11:55<06:08,  2.17s/it, avr_loss=0.117]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [11:55<06:08,  2.17s/it, avr_loss=0.117]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [11:56<06:09,  2.17s/it, avr_loss=0.116]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [11:56<06:09,  2.17s/it, avr_loss=0.116]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [11:57<06:09,  2.17s/it, avr_loss=0.116]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [11:57<06:06,  2.17s/it, avr_loss=0.116]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [11:57<06:06,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [11:58<06:06,  2.17s/it, avr_loss=0.12]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [11:58<06:07,  2.17s/it, avr_loss=0.12]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [11:59<06:07,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [12:00<06:04,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [12:00<06:04,  2.17s/it, avr_loss=0.119]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [12:00<06:04,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [12:01<06:05,  2.17s/it, avr_loss=0.118]\n","steps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [12:02<06:05,  2.17s/it, avr_loss=0.118]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [12:02<06:02,  2.17s/it, avr_loss=0.118]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [12:02<06:02,  2.17s/it, avr_loss=0.118]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [12:03<06:02,  2.17s/it, avr_loss=0.116]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [12:03<06:02,  2.17s/it, avr_loss=0.117]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [12:04<06:03,  2.18s/it, avr_loss=0.116]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [12:04<06:00,  2.17s/it, avr_loss=0.116]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [12:04<06:00,  2.17s/it, avr_loss=0.115]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [12:05<06:00,  2.17s/it, avr_loss=0.118]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [12:05<06:00,  2.17s/it, avr_loss=0.117]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [12:06<06:01,  2.18s/it, avr_loss=0.118]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [12:07<05:58,  2.17s/it, avr_loss=0.118]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [12:07<05:58,  2.17s/it, avr_loss=0.118]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [12:07<05:58,  2.17s/it, avr_loss=0.119]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [12:08<05:58,  2.17s/it, avr_loss=0.117]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [12:08<05:58,  2.18s/it, avr_loss=0.117]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [12:09<05:55,  2.17s/it, avr_loss=0.117]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [12:09<05:55,  2.17s/it, avr_loss=0.116]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [12:09<05:56,  2.17s/it, avr_loss=0.114]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [12:10<05:56,  2.17s/it, avr_loss=0.115]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [12:10<05:56,  2.17s/it, avr_loss=0.115]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [12:11<05:53,  2.17s/it, avr_loss=0.115]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [12:11<05:53,  2.17s/it, avr_loss=0.116]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [12:11<05:54,  2.17s/it, avr_loss=0.116]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [12:12<05:54,  2.17s/it, avr_loss=0.116]\n","steps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [12:12<05:54,  2.17s/it, avr_loss=0.117]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [12:13<05:51,  2.17s/it, avr_loss=0.117]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [12:13<05:51,  2.17s/it, avr_loss=0.117]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [12:14<05:51,  2.17s/it, avr_loss=0.118]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [12:14<05:52,  2.17s/it, avr_loss=0.12]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [12:15<05:52,  2.18s/it, avr_loss=0.121]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [12:16<05:49,  2.17s/it, avr_loss=0.121]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [12:16<05:49,  2.17s/it, avr_loss=0.122]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [12:16<05:49,  2.17s/it, avr_loss=0.124]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [12:17<05:50,  2.18s/it, avr_loss=0.123]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [12:17<05:50,  2.18s/it, avr_loss=0.123]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [12:18<05:47,  2.17s/it, avr_loss=0.123]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [12:18<05:47,  2.17s/it, avr_loss=0.124]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [12:18<05:47,  2.17s/it, avr_loss=0.124]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [12:19<05:47,  2.17s/it, avr_loss=0.12]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [12:20<05:48,  2.18s/it, avr_loss=0.121]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [12:20<05:45,  2.17s/it, avr_loss=0.121]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [12:20<05:45,  2.17s/it, avr_loss=0.122]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [12:21<05:45,  2.17s/it, avr_loss=0.121]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [12:21<05:45,  2.17s/it, avr_loss=0.121]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [12:22<05:46,  2.18s/it, avr_loss=0.12]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [12:22<05:43,  2.17s/it, avr_loss=0.12]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [12:22<05:43,  2.17s/it, avr_loss=0.119]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [12:23<05:43,  2.17s/it, avr_loss=0.12]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [12:23<05:43,  2.17s/it, avr_loss=0.119]\n","steps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [12:24<05:43,  2.18s/it, avr_loss=0.12]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [12:24<05:40,  2.17s/it, avr_loss=0.12]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [12:24<05:40,  2.17s/it, avr_loss=0.12]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [12:25<05:41,  2.17s/it, avr_loss=0.12]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [12:25<05:41,  2.17s/it, avr_loss=0.121]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [12:26<05:41,  2.18s/it, avr_loss=0.121]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [12:27<05:38,  2.17s/it, avr_loss=0.121]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [12:27<05:38,  2.17s/it, avr_loss=0.121]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [12:27<05:39,  2.17s/it, avr_loss=0.122]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [12:28<05:39,  2.18s/it, avr_loss=0.121]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [12:28<05:39,  2.18s/it, avr_loss=0.123]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [12:29<05:36,  2.17s/it, avr_loss=0.123]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [12:29<05:36,  2.17s/it, avr_loss=0.125]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [12:30<05:37,  2.17s/it, avr_loss=0.124]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [12:30<05:37,  2.18s/it, avr_loss=0.124]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [12:31<05:37,  2.18s/it, avr_loss=0.124]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [12:32<05:34,  2.17s/it, avr_loss=0.124]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [12:32<05:34,  2.17s/it, avr_loss=0.125]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [12:32<05:34,  2.17s/it, avr_loss=0.125]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [12:33<05:35,  2.18s/it, avr_loss=0.126]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [12:33<05:35,  2.18s/it, avr_loss=0.126]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [12:34<05:32,  2.17s/it, avr_loss=0.126]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [12:34<05:32,  2.17s/it, avr_loss=0.125]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [12:34<05:32,  2.17s/it, avr_loss=0.124]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [12:35<05:32,  2.18s/it, avr_loss=0.124]\n","steps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [12:35<05:33,  2.18s/it, avr_loss=0.124]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [12:36<05:30,  2.17s/it, avr_loss=0.124]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [12:36<05:30,  2.17s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [12:36<05:30,  2.17s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [12:37<05:30,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [12:37<05:31,  2.18s/it, avr_loss=0.125]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [12:38<05:28,  2.17s/it, avr_loss=0.125]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [12:38<05:28,  2.17s/it, avr_loss=0.125]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [12:38<05:28,  2.17s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [12:39<05:28,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [12:40<05:28,  2.18s/it, avr_loss=0.125]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [12:40<05:26,  2.17s/it, avr_loss=0.125]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [12:40<05:26,  2.17s/it, avr_loss=0.125]\n","epoch 8/10\n","epoch is incremented. current_epoch: 0, epoch: 8\n","epoch is incremented. current_epoch: 0, epoch: 8\n","\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [12:41<05:26,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [12:42<05:26,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [12:42<05:26,  2.18s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [12:43<05:24,  2.18s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [12:43<05:24,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [12:44<05:24,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [12:44<05:24,  2.18s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [12:45<05:24,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [12:45<05:22,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [12:45<05:22,  2.18s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [12:46<05:22,  2.18s/it, avr_loss=0.127]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [12:47<05:22,  2.18s/it, avr_loss=0.126]\n","steps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [12:47<05:22,  2.18s/it, avr_loss=0.127]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [12:48<05:19,  2.18s/it, avr_loss=0.127]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [12:48<05:19,  2.18s/it, avr_loss=0.126]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [12:48<05:20,  2.18s/it, avr_loss=0.122]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [12:49<05:20,  2.18s/it, avr_loss=0.122]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [12:49<05:20,  2.18s/it, avr_loss=0.121]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [12:50<05:17,  2.18s/it, avr_loss=0.121]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [12:50<05:17,  2.18s/it, avr_loss=0.121]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [12:50<05:17,  2.18s/it, avr_loss=0.12]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [12:51<05:18,  2.18s/it, avr_loss=0.12]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [12:51<05:18,  2.18s/it, avr_loss=0.121]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [12:52<05:15,  2.18s/it, avr_loss=0.121]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [12:52<05:15,  2.18s/it, avr_loss=0.119]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [12:52<05:15,  2.18s/it, avr_loss=0.12]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [12:53<05:15,  2.18s/it, avr_loss=0.12]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [12:53<05:16,  2.18s/it, avr_loss=0.122]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [12:54<05:13,  2.18s/it, avr_loss=0.122]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [12:54<05:13,  2.18s/it, avr_loss=0.123]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [12:55<05:13,  2.18s/it, avr_loss=0.122]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [12:56<05:13,  2.18s/it, avr_loss=0.123]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [12:56<05:14,  2.18s/it, avr_loss=0.123]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [12:57<05:11,  2.18s/it, avr_loss=0.123]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [12:57<05:11,  2.18s/it, avr_loss=0.122]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [12:58<05:11,  2.18s/it, avr_loss=0.121]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [12:58<05:11,  2.18s/it, avr_loss=0.121]\n","steps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [12:59<05:12,  2.18s/it, avr_loss=0.119]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [13:00<05:09,  2.18s/it, avr_loss=0.119]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [13:00<05:09,  2.18s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [13:01<05:09,  2.18s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [13:01<05:10,  2.18s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [13:02<05:10,  2.19s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [13:02<05:07,  2.18s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [13:02<05:07,  2.18s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [13:03<05:07,  2.18s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [13:03<05:07,  2.18s/it, avr_loss=0.12]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [13:04<05:08,  2.18s/it, avr_loss=0.122]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [13:05<05:05,  2.18s/it, avr_loss=0.122]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [13:05<05:05,  2.18s/it, avr_loss=0.123]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [13:05<05:05,  2.18s/it, avr_loss=0.123]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [13:06<05:05,  2.18s/it, avr_loss=0.124]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [13:06<05:05,  2.18s/it, avr_loss=0.127]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [13:07<05:03,  2.18s/it, avr_loss=0.127]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [13:07<05:03,  2.18s/it, avr_loss=0.127]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [13:07<05:03,  2.18s/it, avr_loss=0.127]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [13:08<05:03,  2.18s/it, avr_loss=0.127]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [13:08<05:03,  2.18s/it, avr_loss=0.128]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [13:09<05:00,  2.18s/it, avr_loss=0.128]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [13:09<05:00,  2.18s/it, avr_loss=0.128]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [13:09<05:01,  2.18s/it, avr_loss=0.128]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [13:10<05:01,  2.18s/it, avr_loss=0.128]\n","steps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [13:10<05:01,  2.18s/it, avr_loss=0.128]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [13:11<04:58,  2.18s/it, avr_loss=0.128]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [13:11<04:58,  2.18s/it, avr_loss=0.129]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [13:12<04:58,  2.18s/it, avr_loss=0.129]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [13:12<04:59,  2.18s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [13:13<04:59,  2.19s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [13:13<04:56,  2.18s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [13:13<04:56,  2.18s/it, avr_loss=0.124]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [13:14<04:56,  2.18s/it, avr_loss=0.125]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [13:15<04:57,  2.18s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [13:15<04:57,  2.19s/it, avr_loss=0.125]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [13:16<04:54,  2.18s/it, avr_loss=0.125]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [13:16<04:54,  2.18s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [13:16<04:54,  2.18s/it, avr_loss=0.125]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [13:17<04:54,  2.18s/it, avr_loss=0.125]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [13:17<04:55,  2.19s/it, avr_loss=0.124]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [13:18<04:52,  2.18s/it, avr_loss=0.124]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [13:18<04:52,  2.18s/it, avr_loss=0.124]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [13:18<04:52,  2.18s/it, avr_loss=0.124]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [13:19<04:52,  2.18s/it, avr_loss=0.124]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [13:20<04:52,  2.19s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [13:20<04:50,  2.18s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [13:20<04:50,  2.18s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [13:21<04:50,  2.18s/it, avr_loss=0.126]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [13:21<04:50,  2.18s/it, avr_loss=0.127]\n","steps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [13:22<04:50,  2.19s/it, avr_loss=0.129]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [13:22<04:47,  2.18s/it, avr_loss=0.129]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [13:22<04:47,  2.18s/it, avr_loss=0.129]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [13:23<04:48,  2.18s/it, avr_loss=0.128]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [13:23<04:48,  2.18s/it, avr_loss=0.128]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [13:24<04:48,  2.19s/it, avr_loss=0.129]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [13:24<04:45,  2.18s/it, avr_loss=0.129]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [13:24<04:45,  2.18s/it, avr_loss=0.129]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [13:25<04:45,  2.18s/it, avr_loss=0.128]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [13:26<04:46,  2.18s/it, avr_loss=0.128]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [13:26<04:46,  2.19s/it, avr_loss=0.128]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [13:27<04:43,  2.18s/it, avr_loss=0.128]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [13:27<04:43,  2.18s/it, avr_loss=0.128]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [13:27<04:43,  2.18s/it, avr_loss=0.127]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [13:28<04:44,  2.19s/it, avr_loss=0.127]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [13:29<04:44,  2.19s/it, avr_loss=0.126]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [13:29<04:41,  2.18s/it, avr_loss=0.126]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [13:29<04:41,  2.18s/it, avr_loss=0.126]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [13:30<04:41,  2.18s/it, avr_loss=0.126]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [13:30<04:41,  2.19s/it, avr_loss=0.124]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [13:31<04:42,  2.19s/it, avr_loss=0.124]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [13:31<04:39,  2.18s/it, avr_loss=0.124]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [13:31<04:39,  2.18s/it, avr_loss=0.124]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [13:32<04:39,  2.18s/it, avr_loss=0.124]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [13:32<04:39,  2.19s/it, avr_loss=0.125]\n","steps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [13:33<04:39,  2.19s/it, avr_loss=0.124]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [13:34<04:37,  2.18s/it, avr_loss=0.124]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [13:34<04:37,  2.18s/it, avr_loss=0.124]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [13:34<04:37,  2.18s/it, avr_loss=0.125]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [13:35<04:37,  2.19s/it, avr_loss=0.125]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [13:35<04:37,  2.19s/it, avr_loss=0.125]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [13:36<04:34,  2.18s/it, avr_loss=0.125]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [13:36<04:34,  2.18s/it, avr_loss=0.124]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [13:36<04:35,  2.18s/it, avr_loss=0.124]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [13:37<04:35,  2.19s/it, avr_loss=0.123]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [13:37<04:35,  2.19s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [13:38<04:32,  2.18s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [13:38<04:32,  2.18s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [13:38<04:32,  2.18s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [13:39<04:33,  2.19s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [13:40<04:33,  2.19s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [13:40<04:30,  2.18s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [13:40<04:30,  2.18s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [13:41<04:30,  2.18s/it, avr_loss=0.12]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [13:41<04:31,  2.19s/it, avr_loss=0.12]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [13:42<04:31,  2.19s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [13:43<04:28,  2.18s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [13:43<04:28,  2.18s/it, avr_loss=0.121]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [13:43<04:28,  2.18s/it, avr_loss=0.12]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [13:44<04:28,  2.19s/it, avr_loss=0.119]\n","steps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [13:44<04:29,  2.19s/it, avr_loss=0.118]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [13:45<04:26,  2.18s/it, avr_loss=0.118]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [13:45<04:26,  2.18s/it, avr_loss=0.118]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [13:45<04:26,  2.18s/it, avr_loss=0.12]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [13:46<04:26,  2.19s/it, avr_loss=0.12]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [13:46<04:26,  2.19s/it, avr_loss=0.122]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [13:47<04:24,  2.18s/it, avr_loss=0.122]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [13:47<04:24,  2.18s/it, avr_loss=0.124]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [13:47<04:24,  2.18s/it, avr_loss=0.124]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [13:48<04:24,  2.19s/it, avr_loss=0.124]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [13:48<04:24,  2.19s/it, avr_loss=0.124]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [13:49<04:21,  2.18s/it, avr_loss=0.124]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [13:49<04:21,  2.18s/it, avr_loss=0.124]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [13:49<04:22,  2.18s/it, avr_loss=0.125]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [13:50<04:22,  2.19s/it, avr_loss=0.125]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [13:51<04:22,  2.19s/it, avr_loss=0.125]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [13:51<04:19,  2.18s/it, avr_loss=0.125]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [13:51<04:19,  2.18s/it, avr_loss=0.123]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [13:52<04:19,  2.18s/it, avr_loss=0.121]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [13:52<04:20,  2.19s/it, avr_loss=0.122]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [13:53<04:20,  2.19s/it, avr_loss=0.122]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [13:54<04:17,  2.18s/it, avr_loss=0.122]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [13:54<04:17,  2.18s/it, avr_loss=0.121]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [13:54<04:17,  2.19s/it, avr_loss=0.121]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [13:55<04:18,  2.19s/it, avr_loss=0.121]\n","steps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [13:56<04:18,  2.19s/it, avr_loss=0.122]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [13:56<04:15,  2.19s/it, avr_loss=0.122]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [13:56<04:15,  2.19s/it, avr_loss=0.122]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [13:57<04:15,  2.19s/it, avr_loss=0.122]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [13:57<04:15,  2.19s/it, avr_loss=0.126]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [13:58<04:16,  2.19s/it, avr_loss=0.126]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [13:59<04:13,  2.18s/it, avr_loss=0.126]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [13:59<04:13,  2.18s/it, avr_loss=0.126]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [13:59<04:13,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [14:00<04:13,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [14:00<04:13,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [14:01<04:11,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [14:01<04:11,  2.19s/it, avr_loss=0.122]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [14:01<04:11,  2.19s/it, avr_loss=0.122]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [14:02<04:11,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [14:03<04:11,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [14:03<04:09,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [14:03<04:09,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [14:04<04:09,  2.19s/it, avr_loss=0.124]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [14:04<04:09,  2.19s/it, avr_loss=0.123]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [14:05<04:09,  2.19s/it, avr_loss=0.124]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [14:05<04:07,  2.19s/it, avr_loss=0.124]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [14:05<04:07,  2.19s/it, avr_loss=0.124]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [14:06<04:07,  2.19s/it, avr_loss=0.124]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [14:07<04:07,  2.19s/it, avr_loss=0.124]\n","steps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [14:07<04:07,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [14:08<04:04,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [14:08<04:04,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [14:08<04:05,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [14:09<04:05,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [14:10<04:05,  2.19s/it, avr_loss=0.122]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [14:10<04:02,  2.19s/it, avr_loss=0.122]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [14:10<04:02,  2.19s/it, avr_loss=0.122]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [14:11<04:02,  2.19s/it, avr_loss=0.122]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [14:11<04:03,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [14:12<04:03,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [14:12<04:00,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [14:12<04:00,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [14:13<04:00,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [14:13<04:00,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [14:14<04:00,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [14:15<03:58,  2.19s/it, avr_loss=0.123]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [14:15<03:58,  2.19s/it, avr_loss=0.122]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [14:15<03:58,  2.19s/it, avr_loss=0.122]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [14:16<03:58,  2.19s/it, avr_loss=0.125]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [14:16<03:58,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [14:17<03:56,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [14:17<03:56,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [14:17<03:56,  2.19s/it, avr_loss=0.124]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [14:18<03:56,  2.19s/it, avr_loss=0.125]\n","steps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [14:18<03:56,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [14:19<03:53,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [14:19<03:53,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [14:19<03:54,  2.19s/it, avr_loss=0.127]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [14:20<03:54,  2.19s/it, avr_loss=0.127]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [14:20<03:54,  2.19s/it, avr_loss=0.127]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [14:21<03:51,  2.19s/it, avr_loss=0.127]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [14:21<03:51,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [14:22<03:51,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [14:22<03:52,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [14:23<03:52,  2.19s/it, avr_loss=0.125]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [14:24<03:49,  2.19s/it, avr_loss=0.125]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [14:24<03:49,  2.19s/it, avr_loss=0.124]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [14:24<03:49,  2.19s/it, avr_loss=0.125]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [14:25<03:50,  2.19s/it, avr_loss=0.124]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [14:25<03:50,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [14:26<03:47,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [14:26<03:47,  2.19s/it, avr_loss=0.126]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [14:26<03:47,  2.19s/it, avr_loss=0.128]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [14:27<03:47,  2.19s/it, avr_loss=0.127]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [14:27<03:47,  2.19s/it, avr_loss=0.129]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [14:28<03:45,  2.19s/it, avr_loss=0.129]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [14:28<03:45,  2.19s/it, avr_loss=0.13]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [14:29<03:45,  2.19s/it, avr_loss=0.13]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [14:29<03:45,  2.19s/it, avr_loss=0.132]\n","steps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [14:30<03:45,  2.19s/it, avr_loss=0.133]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [14:30<03:43,  2.19s/it, avr_loss=0.133]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [14:30<03:43,  2.19s/it, avr_loss=0.129]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [14:31<03:43,  2.19s/it, avr_loss=0.129]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [14:31<03:43,  2.19s/it, avr_loss=0.13]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [14:32<03:43,  2.19s/it, avr_loss=0.13]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [14:32<03:40,  2.19s/it, avr_loss=0.13]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [14:32<03:40,  2.19s/it, avr_loss=0.132]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [14:33<03:41,  2.19s/it, avr_loss=0.13]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [14:33<03:41,  2.19s/it, avr_loss=0.129]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [14:34<03:41,  2.19s/it, avr_loss=0.129]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [14:35<03:38,  2.19s/it, avr_loss=0.129]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [14:35<03:38,  2.19s/it, avr_loss=0.129]\n","saving checkpoint: /content/drive/MyDrive/AI/training/Rezcty_project/model/Rezcty_project-000008.safetensors\n","\n","epoch 9/10\n","epoch is incremented. current_epoch: 0, epoch: 9\n","epoch is incremented. current_epoch: 0, epoch: 9\n","\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [14:37<03:39,  2.19s/it, avr_loss=0.128]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [14:37<03:39,  2.19s/it, avr_loss=0.128]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [14:38<03:39,  2.20s/it, avr_loss=0.127]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [14:39<03:37,  2.19s/it, avr_loss=0.127]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [14:39<03:37,  2.19s/it, avr_loss=0.127]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [14:39<03:37,  2.19s/it, avr_loss=0.127]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [14:40<03:37,  2.19s/it, avr_loss=0.127]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [14:40<03:37,  2.20s/it, avr_loss=0.128]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [14:41<03:34,  2.19s/it, avr_loss=0.128]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [14:41<03:34,  2.19s/it, avr_loss=0.128]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [14:41<03:34,  2.19s/it, avr_loss=0.128]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [14:42<03:35,  2.19s/it, avr_loss=0.128]\n","steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [14:42<03:35,  2.20s/it, avr_loss=0.128]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [14:43<03:32,  2.19s/it, avr_loss=0.128]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [14:43<03:32,  2.19s/it, avr_loss=0.128]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [14:43<03:32,  2.19s/it, avr_loss=0.128]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [14:44<03:32,  2.19s/it, avr_loss=0.129]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [14:44<03:32,  2.20s/it, avr_loss=0.13]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [14:45<03:30,  2.19s/it, avr_loss=0.13]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [14:45<03:30,  2.19s/it, avr_loss=0.131]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [14:46<03:30,  2.19s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [14:46<03:30,  2.19s/it, avr_loss=0.134]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [14:47<03:30,  2.20s/it, avr_loss=0.134]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [14:47<03:28,  2.19s/it, avr_loss=0.134]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [14:47<03:28,  2.19s/it, avr_loss=0.134]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [14:48<03:28,  2.19s/it, avr_loss=0.134]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [14:48<03:28,  2.19s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [14:49<03:28,  2.20s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [14:50<03:26,  2.19s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [14:50<03:26,  2.19s/it, avr_loss=0.134]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [14:50<03:26,  2.19s/it, avr_loss=0.134]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [14:51<03:26,  2.20s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [14:52<03:26,  2.20s/it, avr_loss=0.132]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [14:52<03:23,  2.19s/it, avr_loss=0.132]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [14:52<03:23,  2.19s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [14:53<03:24,  2.19s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [14:53<03:24,  2.20s/it, avr_loss=0.133]\n","steps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [14:54<03:24,  2.20s/it, avr_loss=0.133]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [14:54<03:21,  2.19s/it, avr_loss=0.133]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [14:54<03:21,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [14:55<03:21,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [14:55<03:22,  2.20s/it, avr_loss=0.133]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [14:56<03:22,  2.20s/it, avr_loss=0.133]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [14:57<03:19,  2.19s/it, avr_loss=0.133]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [14:57<03:19,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [14:57<03:19,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [14:58<03:19,  2.20s/it, avr_loss=0.133]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [14:58<03:19,  2.20s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [14:59<03:17,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [14:59<03:17,  2.19s/it, avr_loss=0.133]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [14:59<03:17,  2.19s/it, avr_loss=0.134]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [15:00<03:17,  2.20s/it, avr_loss=0.134]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [15:00<03:17,  2.20s/it, avr_loss=0.131]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [15:01<03:15,  2.19s/it, avr_loss=0.131]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [15:01<03:15,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [15:01<03:15,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [15:02<03:15,  2.20s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [15:02<03:15,  2.20s/it, avr_loss=0.131]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [15:03<03:13,  2.19s/it, avr_loss=0.131]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [15:03<03:13,  2.19s/it, avr_loss=0.132]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [15:04<03:13,  2.19s/it, avr_loss=0.131]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [15:04<03:13,  2.20s/it, avr_loss=0.13]\n","steps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [15:05<03:13,  2.20s/it, avr_loss=0.131]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [15:06<03:10,  2.19s/it, avr_loss=0.131]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [15:06<03:10,  2.19s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [15:06<03:11,  2.20s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [15:07<03:11,  2.20s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [15:07<03:11,  2.20s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [15:08<03:08,  2.19s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [15:08<03:08,  2.19s/it, avr_loss=0.128]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [15:08<03:08,  2.20s/it, avr_loss=0.128]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [15:09<03:08,  2.20s/it, avr_loss=0.129]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [15:09<03:09,  2.20s/it, avr_loss=0.129]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [15:10<03:06,  2.19s/it, avr_loss=0.129]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [15:10<03:06,  2.19s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [15:11<03:06,  2.20s/it, avr_loss=0.129]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [15:11<03:06,  2.20s/it, avr_loss=0.129]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [15:12<03:06,  2.20s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [15:12<03:04,  2.19s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [15:12<03:04,  2.19s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [15:13<03:04,  2.20s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [15:13<03:04,  2.20s/it, avr_loss=0.13]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [15:14<03:04,  2.20s/it, avr_loss=0.128]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [15:14<03:02,  2.19s/it, avr_loss=0.128]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [15:14<03:02,  2.19s/it, avr_loss=0.129]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [15:15<03:02,  2.19s/it, avr_loss=0.127]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [15:15<03:02,  2.20s/it, avr_loss=0.127]\n","steps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [15:16<03:02,  2.20s/it, avr_loss=0.125]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [15:16<02:59,  2.19s/it, avr_loss=0.125]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [15:16<02:59,  2.19s/it, avr_loss=0.126]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [15:17<02:59,  2.20s/it, avr_loss=0.126]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [15:18<03:00,  2.20s/it, avr_loss=0.127]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [15:18<03:00,  2.20s/it, avr_loss=0.127]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [15:19<02:57,  2.19s/it, avr_loss=0.127]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [15:19<02:57,  2.19s/it, avr_loss=0.127]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [15:20<02:57,  2.20s/it, avr_loss=0.128]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [15:20<02:57,  2.20s/it, avr_loss=0.129]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [15:21<02:58,  2.20s/it, avr_loss=0.129]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [15:21<02:55,  2.19s/it, avr_loss=0.129]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [15:21<02:55,  2.19s/it, avr_loss=0.131]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [15:22<02:55,  2.20s/it, avr_loss=0.13]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [15:22<02:55,  2.20s/it, avr_loss=0.13]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [15:23<02:55,  2.20s/it, avr_loss=0.131]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [15:23<02:53,  2.19s/it, avr_loss=0.131]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [15:23<02:53,  2.19s/it, avr_loss=0.13]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [15:24<02:53,  2.20s/it, avr_loss=0.13]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [15:25<02:53,  2.20s/it, avr_loss=0.131]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [15:25<02:53,  2.20s/it, avr_loss=0.131]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [15:26<02:51,  2.19s/it, avr_loss=0.131]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [15:26<02:51,  2.19s/it, avr_loss=0.131]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [15:26<02:51,  2.20s/it, avr_loss=0.13]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [15:27<02:51,  2.20s/it, avr_loss=0.13]\n","steps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [15:27<02:51,  2.20s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [15:28<02:48,  2.19s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [15:28<02:48,  2.19s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [15:28<02:49,  2.20s/it, avr_loss=0.127]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [15:29<02:49,  2.20s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [15:29<02:49,  2.20s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [15:30<02:46,  2.19s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [15:30<02:46,  2.19s/it, avr_loss=0.128]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [15:31<02:46,  2.20s/it, avr_loss=0.128]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [15:31<02:46,  2.20s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [15:32<02:47,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [15:32<02:44,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [15:32<02:44,  2.20s/it, avr_loss=0.131]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [15:33<02:44,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [15:34<02:44,  2.20s/it, avr_loss=0.131]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [15:34<02:44,  2.20s/it, avr_loss=0.131]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [15:35<02:42,  2.20s/it, avr_loss=0.131]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [15:35<02:42,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [15:35<02:42,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [15:36<02:42,  2.20s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [15:36<02:42,  2.20s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [15:37<02:40,  2.20s/it, avr_loss=0.129]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [15:37<02:40,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [15:37<02:40,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [15:38<02:40,  2.20s/it, avr_loss=0.13]\n","steps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [15:38<02:40,  2.20s/it, avr_loss=0.13]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [15:39<02:38,  2.20s/it, avr_loss=0.13]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [15:39<02:38,  2.20s/it, avr_loss=0.13]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [15:40<02:38,  2.20s/it, avr_loss=0.127]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [15:40<02:38,  2.20s/it, avr_loss=0.128]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [15:41<02:38,  2.20s/it, avr_loss=0.126]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [15:41<02:35,  2.19s/it, avr_loss=0.126]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [15:41<02:35,  2.19s/it, avr_loss=0.125]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [15:42<02:35,  2.20s/it, avr_loss=0.125]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [15:42<02:36,  2.20s/it, avr_loss=0.126]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [15:43<02:36,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [15:43<02:33,  2.19s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [15:43<02:33,  2.19s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [15:44<02:33,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [15:44<02:33,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [15:45<02:33,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [15:46<02:31,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [15:46<02:31,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [15:46<02:31,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [15:47<02:31,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [15:48<02:31,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [15:48<02:29,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [15:48<02:29,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [15:49<02:29,  2.20s/it, avr_loss=0.129]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [15:49<02:29,  2.20s/it, avr_loss=0.128]\n","steps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [15:50<02:29,  2.20s/it, avr_loss=0.127]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [15:50<02:27,  2.20s/it, avr_loss=0.127]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [15:50<02:27,  2.20s/it, avr_loss=0.128]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [15:51<02:27,  2.20s/it, avr_loss=0.128]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [15:51<02:27,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [15:52<02:27,  2.20s/it, avr_loss=0.125]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [15:52<02:24,  2.20s/it, avr_loss=0.125]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [15:52<02:24,  2.20s/it, avr_loss=0.125]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [15:53<02:24,  2.20s/it, avr_loss=0.125]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [15:53<02:25,  2.20s/it, avr_loss=0.125]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [15:54<02:25,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [15:54<02:22,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [15:54<02:22,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [15:55<02:22,  2.20s/it, avr_loss=0.125]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [15:55<02:22,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [15:56<02:22,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [15:57<02:20,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [15:57<02:20,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [15:57<02:20,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [15:58<02:20,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [15:58<02:20,  2.20s/it, avr_loss=0.123]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [15:59<02:18,  2.20s/it, avr_loss=0.123]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [15:59<02:18,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [16:00<02:18,  2.20s/it, avr_loss=0.124]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [16:00<02:18,  2.20s/it, avr_loss=0.123]\n","steps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [16:01<02:18,  2.20s/it, avr_loss=0.123]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [16:01<02:16,  2.20s/it, avr_loss=0.123]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [16:01<02:16,  2.20s/it, avr_loss=0.123]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [16:02<02:16,  2.20s/it, avr_loss=0.122]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [16:03<02:16,  2.20s/it, avr_loss=0.121]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [16:03<02:16,  2.20s/it, avr_loss=0.121]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [16:04<02:13,  2.20s/it, avr_loss=0.121]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [16:04<02:13,  2.20s/it, avr_loss=0.12]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [16:04<02:14,  2.20s/it, avr_loss=0.118]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [16:05<02:14,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [16:05<02:14,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [16:06<02:11,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [16:06<02:11,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [16:06<02:11,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [16:07<02:11,  2.20s/it, avr_loss=0.117]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [16:07<02:11,  2.20s/it, avr_loss=0.118]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [16:08<02:09,  2.20s/it, avr_loss=0.118]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [16:08<02:09,  2.20s/it, avr_loss=0.119]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [16:08<02:09,  2.20s/it, avr_loss=0.119]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [16:09<02:09,  2.20s/it, avr_loss=0.117]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [16:09<02:09,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [16:10<02:07,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [16:10<02:07,  2.20s/it, avr_loss=0.117]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [16:11<02:07,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [16:11<02:07,  2.20s/it, avr_loss=0.116]\n","steps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [16:12<02:07,  2.20s/it, avr_loss=0.116]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [16:12<02:05,  2.20s/it, avr_loss=0.116]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [16:12<02:05,  2.20s/it, avr_loss=0.115]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [16:13<02:05,  2.20s/it, avr_loss=0.114]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [16:14<02:05,  2.20s/it, avr_loss=0.113]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [16:14<02:05,  2.20s/it, avr_loss=0.114]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [16:15<02:03,  2.20s/it, avr_loss=0.114]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [16:15<02:03,  2.20s/it, avr_loss=0.115]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [16:15<02:03,  2.20s/it, avr_loss=0.115]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [16:16<02:03,  2.20s/it, avr_loss=0.116]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [16:17<02:03,  2.20s/it, avr_loss=0.115]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [16:17<02:00,  2.20s/it, avr_loss=0.115]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [16:17<02:00,  2.20s/it, avr_loss=0.117]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [16:18<02:00,  2.20s/it, avr_loss=0.116]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [16:18<02:00,  2.20s/it, avr_loss=0.116]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [16:19<02:01,  2.20s/it, avr_loss=0.115]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [16:19<01:58,  2.20s/it, avr_loss=0.115]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [16:19<01:58,  2.20s/it, avr_loss=0.114]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [16:20<01:58,  2.20s/it, avr_loss=0.112]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [16:20<01:58,  2.20s/it, avr_loss=0.113]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [16:21<01:58,  2.20s/it, avr_loss=0.111]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [16:21<01:56,  2.20s/it, avr_loss=0.111]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [16:21<01:56,  2.20s/it, avr_loss=0.111]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [16:22<01:56,  2.20s/it, avr_loss=0.11]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [16:22<01:56,  2.20s/it, avr_loss=0.111]\n","steps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [16:23<01:56,  2.20s/it, avr_loss=0.112]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [16:23<01:54,  2.20s/it, avr_loss=0.112]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [16:23<01:54,  2.20s/it, avr_loss=0.113]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [16:24<01:54,  2.20s/it, avr_loss=0.113]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [16:25<01:54,  2.20s/it, avr_loss=0.114]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [16:25<01:54,  2.20s/it, avr_loss=0.115]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [16:26<01:52,  2.20s/it, avr_loss=0.115]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [16:26<01:52,  2.20s/it, avr_loss=0.114]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [16:26<01:52,  2.20s/it, avr_loss=0.114]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [16:27<01:52,  2.20s/it, avr_loss=0.114]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [16:27<01:52,  2.20s/it, avr_loss=0.116]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [16:28<01:49,  2.20s/it, avr_loss=0.116]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [16:28<01:49,  2.20s/it, avr_loss=0.116]\n","epoch 10/10\n","epoch is incremented. current_epoch: 0, epoch: 10\n","epoch is incremented. current_epoch: 0, epoch: 10\n","\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [16:29<01:49,  2.20s/it, avr_loss=0.116]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [16:30<01:50,  2.20s/it, avr_loss=0.116]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [16:30<01:50,  2.20s/it, avr_loss=0.115]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [16:31<01:47,  2.20s/it, avr_loss=0.115]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [16:31<01:47,  2.20s/it, avr_loss=0.118]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [16:31<01:47,  2.20s/it, avr_loss=0.119]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [16:32<01:47,  2.20s/it, avr_loss=0.118]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [16:32<01:47,  2.20s/it, avr_loss=0.118]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [16:33<01:45,  2.20s/it, avr_loss=0.118]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [16:33<01:45,  2.20s/it, avr_loss=0.116]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [16:34<01:45,  2.20s/it, avr_loss=0.116]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [16:34<01:45,  2.20s/it, avr_loss=0.116]\n","steps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [16:35<01:45,  2.20s/it, avr_loss=0.117]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [16:35<01:43,  2.20s/it, avr_loss=0.117]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [16:35<01:43,  2.20s/it, avr_loss=0.117]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [16:36<01:43,  2.20s/it, avr_loss=0.119]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [16:36<01:43,  2.20s/it, avr_loss=0.119]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [16:37<01:43,  2.20s/it, avr_loss=0.118]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [16:37<01:41,  2.20s/it, avr_loss=0.118]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [16:37<01:41,  2.20s/it, avr_loss=0.118]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [16:38<01:41,  2.20s/it, avr_loss=0.116]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [16:38<01:41,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [16:39<01:41,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [16:40<01:38,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [16:40<01:38,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [16:40<01:38,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [16:41<01:39,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [16:41<01:39,  2.20s/it, avr_loss=0.114]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [16:42<01:36,  2.20s/it, avr_loss=0.114]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [16:42<01:36,  2.20s/it, avr_loss=0.111]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [16:43<01:36,  2.20s/it, avr_loss=0.111]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [16:43<01:36,  2.20s/it, avr_loss=0.111]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [16:44<01:36,  2.20s/it, avr_loss=0.112]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [16:44<01:34,  2.20s/it, avr_loss=0.112]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [16:44<01:34,  2.20s/it, avr_loss=0.113]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [16:45<01:34,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [16:46<01:34,  2.20s/it, avr_loss=0.115]\n","steps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [16:46<01:34,  2.20s/it, avr_loss=0.116]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [16:47<01:32,  2.20s/it, avr_loss=0.116]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [16:47<01:32,  2.20s/it, avr_loss=0.116]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [16:47<01:32,  2.20s/it, avr_loss=0.116]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [16:48<01:32,  2.20s/it, avr_loss=0.114]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [16:48<01:32,  2.20s/it, avr_loss=0.114]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [16:49<01:30,  2.20s/it, avr_loss=0.114]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [16:49<01:30,  2.20s/it, avr_loss=0.114]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [16:49<01:30,  2.20s/it, avr_loss=0.115]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [16:50<01:30,  2.20s/it, avr_loss=0.116]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [16:50<01:30,  2.20s/it, avr_loss=0.114]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [16:51<01:27,  2.20s/it, avr_loss=0.114]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [16:51<01:27,  2.20s/it, avr_loss=0.112]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [16:51<01:27,  2.20s/it, avr_loss=0.111]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [16:52<01:28,  2.20s/it, avr_loss=0.111]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [16:52<01:28,  2.20s/it, avr_loss=0.111]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [16:53<01:25,  2.20s/it, avr_loss=0.111]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [16:53<01:25,  2.20s/it, avr_loss=0.109]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [16:54<01:25,  2.20s/it, avr_loss=0.109]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [16:54<01:25,  2.20s/it, avr_loss=0.109]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [16:55<01:25,  2.20s/it, avr_loss=0.109]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [16:55<01:23,  2.20s/it, avr_loss=0.109]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [16:55<01:23,  2.20s/it, avr_loss=0.109]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [16:56<01:23,  2.20s/it, avr_loss=0.11]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [16:57<01:23,  2.20s/it, avr_loss=0.11]\n","steps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [16:57<01:23,  2.20s/it, avr_loss=0.112]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [16:58<01:21,  2.20s/it, avr_loss=0.112]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [16:58<01:21,  2.20s/it, avr_loss=0.112]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [16:58<01:21,  2.20s/it, avr_loss=0.112]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [16:59<01:21,  2.20s/it, avr_loss=0.113]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [16:59<01:21,  2.20s/it, avr_loss=0.115]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [17:00<01:19,  2.20s/it, avr_loss=0.115]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [17:00<01:19,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [17:01<01:19,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [17:01<01:19,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [17:02<01:19,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [17:02<01:16,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [17:02<01:16,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [17:03<01:17,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [17:03<01:17,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [17:04<01:17,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [17:04<01:14,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [17:04<01:14,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [17:05<01:14,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [17:05<01:14,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [17:06<01:14,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [17:06<01:12,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [17:06<01:12,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [17:07<01:12,  2.20s/it, avr_loss=0.116]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [17:08<01:12,  2.20s/it, avr_loss=0.117]\n","steps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [17:08<01:12,  2.20s/it, avr_loss=0.116]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [17:09<01:10,  2.20s/it, avr_loss=0.116]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [17:09<01:10,  2.20s/it, avr_loss=0.114]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [17:09<01:10,  2.20s/it, avr_loss=0.114]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [17:10<01:10,  2.20s/it, avr_loss=0.114]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [17:11<01:10,  2.20s/it, avr_loss=0.113]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [17:11<01:08,  2.20s/it, avr_loss=0.113]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [17:11<01:08,  2.20s/it, avr_loss=0.112]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [17:12<01:08,  2.20s/it, avr_loss=0.111]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [17:12<01:08,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [17:13<01:08,  2.20s/it, avr_loss=0.111]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [17:14<01:06,  2.20s/it, avr_loss=0.111]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [17:14<01:06,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [17:14<01:06,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [17:15<01:06,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [17:15<01:06,  2.20s/it, avr_loss=0.109]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [17:16<01:03,  2.20s/it, avr_loss=0.109]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [17:16<01:03,  2.20s/it, avr_loss=0.109]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [17:16<01:03,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [17:17<01:03,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [17:17<01:03,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [17:18<01:01,  2.20s/it, avr_loss=0.11]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [17:18<01:01,  2.20s/it, avr_loss=0.111]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [17:18<01:01,  2.20s/it, avr_loss=0.112]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [17:19<01:01,  2.20s/it, avr_loss=0.112]\n","steps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [17:19<01:01,  2.20s/it, avr_loss=0.112]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [17:20<00:59,  2.20s/it, avr_loss=0.112]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [17:20<00:59,  2.20s/it, avr_loss=0.111]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [17:20<00:59,  2.20s/it, avr_loss=0.111]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [17:21<00:59,  2.20s/it, avr_loss=0.11]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [17:22<00:59,  2.20s/it, avr_loss=0.111]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [17:22<00:57,  2.20s/it, avr_loss=0.111]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [17:22<00:57,  2.20s/it, avr_loss=0.113]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [17:23<00:57,  2.20s/it, avr_loss=0.113]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [17:23<00:57,  2.20s/it, avr_loss=0.112]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [17:24<00:57,  2.20s/it, avr_loss=0.112]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [17:25<00:55,  2.20s/it, avr_loss=0.112]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [17:25<00:55,  2.20s/it, avr_loss=0.111]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [17:25<00:55,  2.20s/it, avr_loss=0.112]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [17:26<00:55,  2.20s/it, avr_loss=0.111]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [17:26<00:55,  2.20s/it, avr_loss=0.113]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [17:27<00:52,  2.20s/it, avr_loss=0.113]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [17:27<00:52,  2.20s/it, avr_loss=0.113]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [17:28<00:52,  2.20s/it, avr_loss=0.112]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [17:28<00:52,  2.20s/it, avr_loss=0.114]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [17:29<00:52,  2.20s/it, avr_loss=0.114]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [17:29<00:50,  2.20s/it, avr_loss=0.114]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [17:29<00:50,  2.20s/it, avr_loss=0.116]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [17:30<00:50,  2.20s/it, avr_loss=0.115]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [17:30<00:50,  2.20s/it, avr_loss=0.115]\n","steps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [17:31<00:50,  2.20s/it, avr_loss=0.115]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [17:31<00:48,  2.20s/it, avr_loss=0.115]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [17:31<00:48,  2.20s/it, avr_loss=0.116]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [17:32<00:48,  2.20s/it, avr_loss=0.116]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [17:32<00:48,  2.20s/it, avr_loss=0.115]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [17:33<00:48,  2.20s/it, avr_loss=0.117]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [17:33<00:46,  2.20s/it, avr_loss=0.117]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [17:33<00:46,  2.20s/it, avr_loss=0.115]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [17:34<00:46,  2.20s/it, avr_loss=0.117]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [17:35<00:46,  2.20s/it, avr_loss=0.116]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [17:35<00:46,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [17:36<00:44,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [17:36<00:44,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [17:37<00:44,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [17:37<00:44,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [17:38<00:44,  2.21s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [17:39<00:41,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [17:39<00:41,  2.20s/it, avr_loss=0.113]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [17:40<00:41,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [17:40<00:41,  2.21s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [17:41<00:41,  2.21s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [17:42<00:39,  2.20s/it, avr_loss=0.112]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [17:42<00:39,  2.20s/it, avr_loss=0.113]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [17:42<00:39,  2.20s/it, avr_loss=0.116]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [17:43<00:39,  2.21s/it, avr_loss=0.116]\n","steps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [17:43<00:39,  2.21s/it, avr_loss=0.116]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [17:44<00:37,  2.20s/it, avr_loss=0.116]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [17:44<00:37,  2.20s/it, avr_loss=0.116]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [17:44<00:37,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [17:45<00:37,  2.21s/it, avr_loss=0.116]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [17:45<00:37,  2.21s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [17:46<00:35,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [17:46<00:35,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [17:47<00:35,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [17:47<00:35,  2.21s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [17:48<00:35,  2.21s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [17:48<00:33,  2.20s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [17:48<00:33,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [17:49<00:33,  2.20s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [17:49<00:33,  2.21s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [17:50<00:33,  2.21s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [17:50<00:30,  2.20s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [17:50<00:30,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [17:51<00:30,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [17:51<00:30,  2.21s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [17:52<00:30,  2.21s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [17:53<00:28,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [17:53<00:28,  2.20s/it, avr_loss=0.114]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [17:53<00:28,  2.20s/it, avr_loss=0.115]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [17:54<00:28,  2.21s/it, avr_loss=0.116]\n","steps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [17:55<00:28,  2.21s/it, avr_loss=0.117]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [17:55<00:26,  2.20s/it, avr_loss=0.117]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [17:55<00:26,  2.20s/it, avr_loss=0.117]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [17:56<00:26,  2.21s/it, avr_loss=0.118]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [17:56<00:26,  2.21s/it, avr_loss=0.119]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [17:57<00:26,  2.21s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [17:57<00:24,  2.20s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [17:57<00:24,  2.20s/it, avr_loss=0.121]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [17:58<00:24,  2.21s/it, avr_loss=0.121]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [17:58<00:24,  2.21s/it, avr_loss=0.121]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [17:59<00:24,  2.21s/it, avr_loss=0.122]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [18:00<00:22,  2.20s/it, avr_loss=0.122]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [18:00<00:22,  2.20s/it, avr_loss=0.122]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [18:00<00:22,  2.21s/it, avr_loss=0.122]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [18:01<00:22,  2.21s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [18:01<00:22,  2.21s/it, avr_loss=0.119]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [18:02<00:19,  2.20s/it, avr_loss=0.119]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [18:02<00:19,  2.20s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [18:02<00:19,  2.21s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [18:03<00:19,  2.21s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [18:03<00:19,  2.21s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [18:04<00:17,  2.20s/it, avr_loss=0.12]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [18:04<00:17,  2.20s/it, avr_loss=0.123]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [18:04<00:17,  2.21s/it, avr_loss=0.124]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [18:05<00:17,  2.21s/it, avr_loss=0.124]\n","steps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [18:05<00:17,  2.21s/it, avr_loss=0.123]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [18:06<00:15,  2.20s/it, avr_loss=0.123]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [18:06<00:15,  2.20s/it, avr_loss=0.123]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [18:07<00:15,  2.21s/it, avr_loss=0.125]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [18:07<00:15,  2.21s/it, avr_loss=0.127]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [18:08<00:15,  2.21s/it, avr_loss=0.127]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [18:09<00:13,  2.20s/it, avr_loss=0.127]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [18:09<00:13,  2.20s/it, avr_loss=0.126]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [18:09<00:13,  2.21s/it, avr_loss=0.126]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [18:10<00:13,  2.21s/it, avr_loss=0.125]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [18:10<00:13,  2.21s/it, avr_loss=0.125]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [18:11<00:11,  2.21s/it, avr_loss=0.125]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [18:11<00:11,  2.21s/it, avr_loss=0.127]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [18:12<00:11,  2.21s/it, avr_loss=0.129]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [18:12<00:11,  2.21s/it, avr_loss=0.129]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [18:13<00:11,  2.21s/it, avr_loss=0.128]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [18:13<00:08,  2.20s/it, avr_loss=0.128]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [18:13<00:08,  2.20s/it, avr_loss=0.128]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [18:14<00:08,  2.21s/it, avr_loss=0.128]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [18:14<00:08,  2.21s/it, avr_loss=0.127]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [18:15<00:08,  2.21s/it, avr_loss=0.127]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [18:15<00:06,  2.20s/it, avr_loss=0.127]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [18:15<00:06,  2.20s/it, avr_loss=0.128]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [18:16<00:06,  2.21s/it, avr_loss=0.128]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [18:16<00:06,  2.21s/it, avr_loss=0.125]\n","steps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [18:17<00:06,  2.21s/it, avr_loss=0.125]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [18:17<00:04,  2.20s/it, avr_loss=0.125]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [18:17<00:04,  2.20s/it, avr_loss=0.125]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [18:18<00:04,  2.21s/it, avr_loss=0.126]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [18:18<00:04,  2.21s/it, avr_loss=0.124]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [18:19<00:04,  2.21s/it, avr_loss=0.123]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [18:20<00:02,  2.20s/it, avr_loss=0.123]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [18:20<00:02,  2.20s/it, avr_loss=0.123]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [18:20<00:02,  2.21s/it, avr_loss=0.124]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [18:21<00:02,  2.21s/it, avr_loss=0.124]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [18:21<00:02,  2.21s/it, avr_loss=0.123]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [18:22<00:00,  2.21s/it, avr_loss=0.123]\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [18:22<00:00,  2.21s/it, avr_loss=0.123]\n","saving checkpoint: /content/drive/MyDrive/AI/training/Rezcty_project/model/Rezcty_project.safetensors\n","model saved.\n","\n","steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [18:23<00:00,  2.21s/it, avr_loss=0.123]\n","\n","ğŸ‰ Training selesai dengan sukses!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# ==============================================================================\n","#\n","# ==============================================================================\n","\n","# ------------------------------------------------------------------------------\n"," Setup Environment yang Lebih Stabil\n","# ------------------------------------------------------------------------------\n","import os\n","import shutil\n","import subprocess\n","import sys\n","\n","def run_command(command, check=True):\n","    \"\"\"Jalankan command dengan error handling yang lebih baik\"\"\"\n","    try:\n","        result = subprocess.run(command, shell=True, check=check,\n","                              capture_output=True, text=True)\n","        if result.stdout:\n","            print(result.stdout)\n","        return result\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Error running command: {command}\")\n","        print(f\"Error: {e.stderr}\")\n","        if check:\n","            raise\n","        return e\n","\n","print(\"ğŸš€ Memulai setup lingkungan...\")\n","\n","# Pindah ke direktori content dan bersihkan jika ada\n","os.chdir('/content/')\n","if os.path.exists('/content/sd-scripts'):\n","    shutil.rmtree('/content/sd-scripts')\n","\n","# Clone repository\n","run_command('git clone https://github.com/kohya-ss/sd-scripts.git')\n","os.chdir('/content/sd-scripts/')\n","\n","print(\"\\nğŸ”§ Memasang dependensi dengan urutan yang tepat...\")\n","\n","# Uninstall conflicting packages dulu\n","run_command('pip uninstall -y peft torchaudio tensorflow', check=False)\n","\n","# Install torch dan xformers dulu\n","run_command('pip install torch==2.3.0 torchvision==0.18.0 --index-url https://download.pytorch.org/whl/cu121')\n","run_command('pip install xformers==0.0.26.post1 --index-url https://download.pytorch.org/whl/cu121')\n","\n","# Install dependencies satu per satu untuk kontrol yang lebih baik\n","dependencies = [\n","    'accelerate==0.30.0',\n","    'transformers==4.44.0',\n","    'diffusers[torch]==0.25.0',\n","    'bitsandbytes==0.44.0',\n","    'safetensors==0.4.2',\n","    'lion-pytorch==0.0.6',\n","    'prodigyopt==1.0',\n","    'opencv-python==4.8.1.78',\n","    'einops==0.7.0',\n","    'ftfy==6.1.1',\n","    'tensorboard',\n","    'rich==13.7.0',\n","    'imagesize==1.4.1',\n","    'toml==0.10.2',\n","    'voluptuous==0.13.1',\n","    'huggingface_hub>=0.28.1'\n","]\n","\n","for dep in dependencies:\n","    run_command(f'pip install {dep}')\n","\n","# Install package dalam editable mode\n","run_command('pip install -e .')\n","\n","print(\"\\nâœ… Instalasi selesai dengan sukses!\")\n","\n","# ------------------------------------------------------------------------------\n","# Bagian 2: Konfigurasi Accelerate\n","# ------------------------------------------------------------------------------\n","print(\"\\nâš™ï¸ Mengkonfigurasi accelerate...\")\n","\n","# Buat konfigurasi accelerate secara programmatic\n","accelerate_config = \"\"\"compute_environment: LOCAL_MACHINE\n","deepspeed_config: {}\n","distributed_type: 'NO'\n","downcast_bf16: 'no'\n","gpu_ids: all\n","machine_rank: 0\n","main_training_function: main\n","mixed_precision: fp16\n","num_machines: 1\n","num_processes: 1\n","rdzv_backend: static\n","same_network: true\n","tpu_env: []\n","tpu_use_cluster: false\n","tpu_use_sudo: false\n","use_cpu: false\n","\"\"\"\n","\n","# Simpan konfigurasi\n","os.makedirs(os.path.expanduser('~/.cache/huggingface/accelerate'), exist_ok=True)\n","with open(os.path.expanduser('~/.cache/huggingface/accelerate/default_config.yaml'), 'w') as f:\n","    f.write(accelerate_config)\n","\n","print(\"âœ… Accelerate dikonfigurasi\")\n","\n","# ------------------------------------------------------------------------------\n","# Bagian 3: Hubungkan ke Drive\n","# ------------------------------------------------------------------------------\n","print(\"\\nğŸ”— Menghubungkan ke Google Drive...\")\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ------------------------------------------------------------------------------\n","# Bagian 4: Validasi Setup\n","# ------------------------------------------------------------------------------\n","print(\"\\nğŸ” Memvalidasi instalasi...\")\n","\n","# Test import critical modules\n","try:\n","    import torch\n","    import transformers\n","    import diffusers\n","    import accelerate\n","    print(f\"âœ… PyTorch: {torch.__version__}\")\n","    print(f\"âœ… Transformers: {transformers.__version__}\")\n","    print(f\"âœ… Diffusers: {diffusers.__version__}\")\n","    print(f\"âœ… Accelerate: {accelerate.__version__}\")\n","    print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n","    if torch.cuda.is_available():\n","        print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n","        print(f\"âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n","except ImportError as e:\n","    print(f\"âŒ Import error: {e}\")\n","\n","print(\"\\nğŸ¯ Setup selesai!\")\n","\n","# ------------------------------------------------------------------------------\n","# Bagian 5: Fungsi Training yang Diperbaiki\n","# ------------------------------------------------------------------------------\n","\n","def setup_training_paths(project_name, instance_name=None, class_name=\"person\", repeats=10):\n","    \"\"\"Setup path training dengan validasi dan penamaan folder yang tepat\"\"\"\n","    base_model_path = \"/content/drive/MyDrive/AI/models/stable-diffusion-v1-5-fp16\"\n","    project_folder = f\"/content/drive/MyDrive/AI/training/{project_name}\"\n","\n","    # Gunakan project_name sebagai instance_name jika tidak dispesifikasi\n","    if instance_name is None:\n","        instance_name = project_name.lower().replace(\"_\", \"\").replace(\"-\", \"\")\n","\n","    # Format folder DreamBooth yang benar\n","    dreambooth_folder_name = f\"{repeats}_{instance_name}_{class_name}\"\n","\n","    paths = {\n","        'base_model': base_model_path,\n","        'project_folder': project_folder,\n","        'train_data_dir': project_folder,  # Root project folder untuk DreamBooth\n","        'images_folder': f\"{project_folder}/images\",\n","        'output_dir': f\"{project_folder}/model\",\n","        'logging_dir': f\"{project_folder}/log\",\n","        'dreambooth_folder': os.path.join(project_folder, dreambooth_folder_name),  # Langsung di root\n","        'instance_name': instance_name,\n","        'class_name': class_name,\n","        'repeats': repeats\n","    }\n","\n","    # Validasi base model\n","    if not os.path.exists(paths['base_model']):\n","        print(f\"âŒ Base model tidak ditemukan: {paths['base_model']}\")\n","        print(\"Pastikan model Stable Diffusion 1.5 sudah ada di Drive\")\n","        return None\n","\n","    # Cek struktur folder dan perbaiki jika perlu\n","    images_folder = paths['images_folder']\n","\n","    # Cek apakah menggunakan struktur DreamBooth atau dataset biasa\n","    image_extensions = ('.jpg', '.jpeg', '.png', '.webp', '.bmp')\n","\n","    # Cek gambar langsung di folder images\n","    direct_images = []\n","    if os.path.exists(images_folder):\n","        for file in os.listdir(images_folder):\n","            if file.lower().endswith(image_extensions):\n","                direct_images.append(file)\n","\n","    # Cek subfolder DreamBooth yang sudah ada di root project\n","    existing_dreambooth_folders = []\n","    if os.path.exists(paths['project_folder']):\n","        for item in os.listdir(paths['project_folder']):\n","            item_path = os.path.join(paths['project_folder'], item)\n","            if os.path.isdir(item_path) and '_' in item:\n","                # Cek format DreamBooth: number_name_class\n","                parts = item.split('_')\n","                if len(parts) >= 3 and parts[0].isdigit():\n","                    # Cek apakah folder berisi gambar\n","                    subfolder_images = [f for f in os.listdir(item_path)\n","                                      if f.lower().endswith(image_extensions)]\n","                    if subfolder_images:\n","                        existing_dreambooth_folders.append((item, len(subfolder_images)))\n","\n","    print(f\"ğŸ“Š Ditemukan {len(direct_images)} gambar di folder images\")\n","    print(f\"ğŸ“ Ditemukan {len(existing_dreambooth_folders)} folder DreamBooth yang sudah ada\")\n","\n","    # Jika ada gambar di folder images, pindahkan ke struktur DreamBooth\n","    if direct_images:\n","        print(f\"ğŸ”„ Membuat folder DreamBooth: {dreambooth_folder_name}\")\n","        os.makedirs(paths['dreambooth_folder'], exist_ok=True)\n","\n","        # Pindahkan semua gambar ke folder DreamBooth di root project\n","        moved_count = 0\n","        for img_file in direct_images:\n","            src = os.path.join(images_folder, img_file)\n","            dst = os.path.join(paths['dreambooth_folder'], img_file)\n","            if not os.path.exists(dst):  # Hindari overwrite\n","                shutil.move(src, dst)\n","                moved_count += 1\n","\n","            # Cek dan pindahkan caption file jika ada\n","            caption_file = os.path.splitext(img_file)[0] + '.txt'\n","            src_caption = os.path.join(images_folder, caption_file)\n","            dst_caption = os.path.join(paths['dreambooth_folder'], caption_file)\n","            if os.path.exists(src_caption) and not os.path.exists(dst_caption):\n","                shutil.move(src_caption, dst_caption)\n","\n","        print(f\"âœ… Dipindahkan {moved_count} gambar ke {paths['dreambooth_folder']}\")\n","        existing_dreambooth_folders.append((dreambooth_folder_name, moved_count))\n","\n","    # Hitung total gambar dari semua folder DreamBooth\n","    total_images = sum(count for _, count in existing_dreambooth_folders)\n","\n","    if total_images == 0:\n","        print(\"âŒ Tidak ada gambar training yang ditemukan\")\n","        print(\"ğŸ’¡ Struktur folder yang benar:\")\n","        print(f\"   ğŸ“ {project_name}/\")\n","        print(f\"   â”œâ”€â”€ ğŸ“ {dreambooth_folder_name}/\")\n","        print(\"   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ image1.jpg\")\n","        print(\"   â”‚   â”œâ”€â”€ ğŸ“ image1.txt (opsional)\")\n","        print(\"   â”‚   â””â”€â”€ ...\")\n","        print(f\"   â”œâ”€â”€ ğŸ“ model/ (output)\")\n","        print(f\"   â””â”€â”€ ğŸ“ log/ (logging)\")\n","        print(f\"\\nğŸ¯ Instance name: '{instance_name}' (trigger word untuk memanggil LoRA)\")\n","        print(f\"ğŸ¯ Class name: '{class_name}' (kategori umum)\")\n","        print(f\"ğŸ¯ Repeats: {repeats}x per epoch\")\n","        return None\n","\n","    print(f\"âœ… Total {total_images} gambar siap untuk training\")\n","    print(f\"ğŸ¯ Instance name: '{instance_name}' (gunakan ini sebagai trigger word)\")\n","    print(f\"ğŸ¯ Class name: '{class_name}'\")\n","    print(f\"ğŸ¯ Repeats: {repeats}x per epoch\")\n","    print(f\"ğŸ“ Folder training: {dreambooth_folder_name}\")\n","\n","    # Validasi caption files\n","    print(\"\\nğŸ” Memvalidasi caption files...\")\n","    validate_caption_files(paths['dreambooth_folder'])\n","\n","    # Buat direktori output\n","    os.makedirs(paths['output_dir'], exist_ok=True)\n","    os.makedirs(paths['logging_dir'], exist_ok=True)\n","\n","    return paths\n","\n","def start_training(project_name, instance_name=None, class_name=\"person\", repeats=10, **kwargs):\n","    \"\"\"Mulai training dengan parameter yang lebih optimal\"\"\"\n","\n","    # Setup paths\n","    paths = setup_training_paths(project_name, instance_name, class_name, repeats)\n","    if not paths:\n","        return False\n","\n","    # Parameter default yang sudah dioptimalkan\n","    default_params = {\n","        'max_train_epochs': 10,\n","        'learning_rate': 1e-4,\n","        'network_dim': 32,\n","        'network_alpha': 16,\n","        'train_batch_size': 1,\n","        'gradient_accumulation_steps': 4,\n","        'mixed_precision': 'fp16',\n","        'optimizer_type': 'AdamW8bit',\n","        'lr_scheduler': 'cosine_with_restarts',\n","        'lr_warmup_steps': 100,\n","        'save_every_n_epochs': 2,\n","        'save_model_as': 'safetensors',\n","        'clip_skip': 2,\n","        'min_bucket_reso': 256,\n","        'max_bucket_reso': 1024,\n","        'seed': 42,\n","        'resolution': 512\n","    }\n","\n","    # Update dengan parameter yang diberikan\n","    default_params.update(kwargs)\n","\n","    # Build command dengan handling boolean yang benar\n","    cmd_parts = [\n","        'python', 'train_network.py',\n","        f'--pretrained_model_name_or_path=\"{paths[\"base_model\"]}\"',\n","        f'--train_data_dir=\"{paths[\"train_data_dir\"]}\"',  # Project folder untuk DreamBooth\n","        f'--output_dir=\"{paths[\"output_dir\"]}\"',\n","        f'--logging_dir=\"{paths[\"logging_dir\"]}\"',\n","        f'--output_name=\"{project_name}\"',\n","        '--network_module=networks.lora',\n","        '--enable_bucket',\n","        '--cache_latents',\n","        '--cache_latents_to_disk',\n","        '--caption_extension=.txt',  # PERBAIKAN: Gunakan .txt bukan .caption\n","        '--shuffle_caption',\n","        '--keep_tokens=1',\n","        '--bucket_reso_steps=64',\n","        '--console_log_simple',  # Penting untuk Colab\n","        '--xformers'  # Untuk memory efficiency\n","    ]\n","\n","    # Tambahkan parameter dengan handling khusus untuk boolean\n","    for key, value in default_params.items():\n","        if isinstance(value, bool):\n","            if value:\n","                cmd_parts.append(f'--{key}')\n","            # Boolean False tidak perlu ditambahkan ke command\n","        else:\n","            cmd_parts.append(f'--{key}={value}')\n","\n","    # Gabungkan command\n","    command = ' '.join(cmd_parts)\n","\n","    print(f\"\\nğŸ”¥ Memulai pelatihan untuk '{project_name}'...\")\n","    print(f\"ğŸ“ Command: {command[:100]}...\")\n","\n","    try:\n","        # Jalankan training\n","        process = subprocess.Popen(\n","            command,\n","            shell=True,\n","            stdout=subprocess.PIPE,\n","            stderr=subprocess.STDOUT,\n","            universal_newlines=True,\n","            bufsize=1\n","        )\n","\n","        # Stream output real-time\n","        for line in iter(process.stdout.readline, ''):\n","            print(line.strip())\n","\n","        process.wait()\n","\n","        if process.returncode == 0:\n","            print(\"\\nğŸ‰ Training selesai dengan sukses!\")\n","            return True\n","        else:\n","            print(f\"\\nâŒ Training gagal dengan return code: {process.returncode}\")\n","            return False\n","\n","    except Exception as e:\n","        print(f\"\\nâŒ Error saat training: {e}\")\n","        return False\n","\n","# ------------------------------------------------------------------------------\n","# Fungsi Validasi Caption Files\n","# ------------------------------------------------------------------------------\n","\n","def validate_caption_files(dreambooth_folder):\n","    \"\"\"Validasi dan perbaiki caption files\"\"\"\n","    if not os.path.exists(dreambooth_folder):\n","        print(f\"âŒ Folder tidak ditemukan: {dreambooth_folder}\")\n","        return False\n","\n","    image_extensions = ('.jpg', '.jpeg', '.png', '.webp', '.bmp')\n","    images = [f for f in os.listdir(dreambooth_folder) if f.lower().endswith(image_extensions)]\n","\n","    caption_count = 0\n","    missing_captions = []\n","\n","    for img_file in images:\n","        base_name = os.path.splitext(img_file)[0]\n","        txt_file = f\"{base_name}.txt\"\n","        txt_path = os.path.join(dreambooth_folder, txt_file)\n","\n","        if os.path.exists(txt_path):\n","            caption_count += 1\n","            # Cek isi caption\n","            with open(txt_path, 'r', encoding='utf-8') as f:\n","                content = f.read().strip()\n","                if not content:\n","                    print(f\"âš ï¸ Caption kosong: {txt_file}\")\n","        else:\n","            missing_captions.append(img_file)\n","\n","    print(f\"ğŸ“ Caption files ditemukan: {caption_count}/{len(images)}\")\n","\n","    if missing_captions:\n","        print(f\"âš ï¸ Missing caption files untuk:\")\n","        for img in missing_captions[:5]:  # Show first 5\n","            print(f\"   - {img}\")\n","        if len(missing_captions) > 5:\n","            print(f\"   ... dan {len(missing_captions) - 5} lainnya\")\n","\n","        # Auto-generate missing captions\n","        print(\"ğŸ”„ Membuat caption files yang hilang...\")\n","        for img_file in missing_captions:\n","            base_name = os.path.splitext(img_file)[0]\n","            txt_file = f\"{base_name}.txt\"\n","            txt_path = os.path.join(dreambooth_folder, txt_file)\n","\n","            # Default caption berdasarkan folder name\n","            folder_name = os.path.basename(dreambooth_folder)\n","            parts = folder_name.split('_')\n","            if len(parts) >= 3:\n","                instance_name = parts[1]\n","                class_name = parts[2]\n","                default_caption = f\"a photo of {instance_name} {class_name}, high quality\"\n","            else:\n","                default_caption = \"a high quality photo\"\n","\n","            with open(txt_path, 'w', encoding='utf-8') as f:\n","                f.write(default_caption)\n","\n","            print(f\"   âœ… Dibuat: {txt_file} -> '{default_caption}'\")\n","\n","    return True\n","\n","def quick_test_training(project_name, instance_name=None, class_name=\"person\", repeats=10):\n","    \"\"\"Test training dengan parameter minimal untuk debugging\"\"\"\n","\n","    paths = setup_training_paths(project_name, instance_name, class_name, repeats)\n","    if not paths:\n","        return False\n","\n","    # Command yang sangat sederhana untuk test - menggunakan project folder sebagai train_data_dir\n","    cmd_parts = [\n","        'python', 'train_network.py',\n","        f'--pretrained_model_name_or_path={paths[\"base_model\"]}',\n","        f'--train_data_dir={paths[\"train_data_dir\"]}',  # Project folder yang berisi folder DreamBooth\n","        f'--output_dir={paths[\"output_dir\"]}',\n","        f'--output_name={project_name}',\n","        '--network_module=networks.lora',\n","        '--network_dim=16',\n","        '--network_alpha=8',\n","        '--resolution=512',\n","        '--train_batch_size=1',\n","        '--max_train_epochs=1',  # Hanya 1 epoch untuk testing\n","        '--learning_rate=1e-4',\n","        '--mixed_precision=fp16',\n","        '--save_model_as=safetensors',\n","        '--caption_extension=.txt',  # PERBAIKAN: Gunakan .txt\n","        '--enable_bucket',\n","        '--console_log_simple'\n","    ]\n","\n","    command = ' '.join(cmd_parts)\n","\n","    print(f\"\\nğŸ§ª Menjalankan test training untuk '{project_name}'...\")\n","    print(f\"ğŸ¯ Trigger word: '{paths['instance_name']}'\")\n","    print(f\"ğŸ“ Training data path: {paths['train_data_dir']}\")\n","    print(f\"ğŸ“ Command: {command}\")\n","\n","    try:\n","        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=1800)  # 30 menit timeout\n","\n","        print(\"STDOUT:\")\n","        print(result.stdout)\n","\n","        if result.stderr:\n","            print(\"STDERR:\")\n","            print(result.stderr)\n","\n","        if result.returncode == 0:\n","            print(\"\\nğŸ‰ Test training berhasil!\")\n","            print(f\"ğŸ’¡ Untuk generate gambar, gunakan prompt: '{paths['instance_name']} {paths['class_name']}'\")\n","            return True\n","        else:\n","            print(f\"\\nâŒ Test training gagal dengan return code: {result.returncode}\")\n","            return False\n","\n","    except subprocess.TimeoutExpired:\n","        print(\"\\nâ° Training timeout (30 menit)\")\n","        return False\n","    except Exception as e:\n","        print(f\"\\nâŒ Error: {e}\")\n","        return False\n","\n","# ------------------------------------------------------------------------------\n","# Contoh Penggunaan\n","# ------------------------------------------------------------------------------\n","\n","# Untuk memulai training, jalankan:\n","# start_training(\"Rezcty_project\", max_train_epochs=15, learning_rate=5e-5)\n","\n","# Untuk test training sederhana:\n","# quick_test_training(\"Rezcty_project\")\n","\n","print(\"\"\"\n","ğŸ¯ PANDUAN PENAMAAN FOLDER DREAMBOOTH:\n","\n","Format: [repeats]_[instance_name]_[class_name]\n","\n","ğŸ“– CONTOH PENAMAAN:\n","1. Untuk karakter \"Rezcty\": 10_rezcty_person\n","2. Untuk karakter anime \"Sakura\": 15_sakura_girl\n","3. Untuk objek mobil: 20_mycar_car\n","4. Untuk hewan \"Fluffy\": 12_fluffy_cat\n","\n","ğŸ¯ CARA PENGGUNAAN:\n","\n","1. Training dengan nama default (otomatis dari project_name):\n","   quick_test_training(\"Rezcty_project\")\n","   # Akan membuat: 10_rezctyproject_person\n","\n","2. Training dengan custom instance name:\n","   quick_test_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\", repeats=15)\n","   # Akan membuat: 15_rezcty_person\n","\n","3. Training penuh:\n","   start_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\")\n","\n","ğŸ’¡ TIPS:\n","- Instance name = trigger word untuk memanggil LoRA\n","- Gunakan nama unik, hindari kata umum\n","- Semakin sedikit gambar â†’ repeats lebih tinggi\n","- 5-10 gambar = 15-20 repeats\n","- 10-20 gambar = 10-15 repeats\n","- 20+ gambar = 5-10 repeats\n","\n","ğŸ“ STRUKTUR FOLDER AKHIR:\n","/content/drive/MyDrive/AI/training/Rezcty_project/\n","â””â”€â”€ images/\n","    â””â”€â”€ 15_rezcty_person/\n","        â”œâ”€â”€ photo1.jpg\n","        â”œâ”€â”€ photo1.txt (opsional)\n","        â””â”€â”€ ...\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Hz0xCWFnMGd","executionInfo":{"status":"ok","timestamp":1754387067986,"user_tz":-420,"elapsed":59092,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"ab3a2e8e-4fe1-448c-f5b7-e205277907d7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ Memulai setup lingkungan...\n","\n","ğŸ”§ Memasang dependensi dengan urutan yang tepat...\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torchvision==0.18.0 in /usr/local/lib/python3.11/dist-packages (0.18.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n","\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Requirement already satisfied: xformers==0.0.26.post1 in /usr/local/lib/python3.11/dist-packages (0.0.26.post1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.26.post1) (1.26.4)\n","Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.26.post1) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->xformers==0.0.26.post1) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->xformers==0.0.26.post1) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0->xformers==0.0.26.post1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0->xformers==0.0.26.post1) (1.3.0)\n","\n","Requirement already satisfied: accelerate==0.30.0 in /usr/local/lib/python3.11/dist-packages (0.30.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (6.0.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (0.24.5)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.30.0) (12.5.82)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.0) (4.67.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.30.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2025.7.14)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==0.30.0) (1.3.0)\n","\n","Requirement already satisfied: transformers==4.44.0 in /usr/local/lib/python3.11/dist-packages (4.44.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (0.24.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (0.4.2)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (4.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (2025.7.14)\n","\n","Requirement already satisfied: diffusers==0.25.0 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.25.0) (0.25.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (8.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (3.18.0)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (0.24.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (0.4.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (11.3.0)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.25.0) (2.3.0+cu121)\n","Requirement already satisfied: accelerate>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.25.0) (0.30.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (6.0.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (2025.3.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->diffusers[torch]==0.25.0) (12.5.82)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.23.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4->diffusers[torch]==0.25.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.4->diffusers[torch]==0.25.0) (1.3.0)\n","\n","Requirement already satisfied: bitsandbytes==0.44.0 in /usr/local/lib/python3.11/dist-packages (0.44.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.44.0) (2.3.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.44.0) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.44.0) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes==0.44.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->bitsandbytes==0.44.0) (1.3.0)\n","\n","Requirement already satisfied: safetensors==0.4.2 in /usr/local/lib/python3.11/dist-packages (0.4.2)\n","\n","Requirement already satisfied: lion-pytorch==0.0.6 in /usr/local/lib/python3.11/dist-packages (0.0.6)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from lion-pytorch==0.0.6) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->lion-pytorch==0.0.6) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6->lion-pytorch==0.0.6) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.6->lion-pytorch==0.0.6) (1.3.0)\n","\n","Requirement already satisfied: prodigyopt==1.0 in /usr/local/lib/python3.11/dist-packages (1.0)\n","\n","Requirement already satisfied: opencv-python==4.8.1.78 in /usr/local/lib/python3.11/dist-packages (4.8.1.78)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python==4.8.1.78) (1.26.4)\n","\n","Requirement already satisfied: einops==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n","\n","Requirement already satisfied: ftfy==6.1.1 in /usr/local/lib/python3.11/dist-packages (6.1.1)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy==6.1.1) (0.2.13)\n","\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.74.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (25.0)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","\n","Requirement already satisfied: rich==13.7.0 in /usr/local/lib/python3.11/dist-packages (13.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.0) (0.1.2)\n","\n","Requirement already satisfied: imagesize==1.4.1 in /usr/local/lib/python3.11/dist-packages (1.4.1)\n","\n","Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.11/dist-packages (0.10.2)\n","\n","Requirement already satisfied: voluptuous==0.13.1 in /usr/local/lib/python3.11/dist-packages (0.13.1)\n","\n","Obtaining file:///content/sd-scripts\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Installing collected packages: library\n","  Running setup.py develop for library\n","Successfully installed library-0.0.0\n","\n","\n","âœ… Instalasi selesai dengan sukses!\n","\n","âš™ï¸ Mengkonfigurasi accelerate...\n","âœ… Accelerate dikonfigurasi\n","\n","ğŸ”— Menghubungkan ke Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","ğŸ” Memvalidasi instalasi...\n","âœ… PyTorch: 2.3.0+cu121\n","âœ… Transformers: 4.44.0\n","âœ… Diffusers: 0.25.0\n","âœ… Accelerate: 0.30.0\n","âœ… CUDA available: True\n","âœ… GPU: Tesla T4\n","âœ… VRAM: 14.7 GB\n","\n","ğŸ¯ Setup selesai!\n","\n","ğŸ¯ PANDUAN PENAMAAN FOLDER DREAMBOOTH:\n","\n","Format: [repeats]_[instance_name]_[class_name]\n","\n","ğŸ“– CONTOH PENAMAAN:\n","1. Untuk karakter \"Rezcty\": 10_rezcty_person\n","2. Untuk karakter anime \"Sakura\": 15_sakura_girl  \n","3. Untuk objek mobil: 20_mycar_car\n","4. Untuk hewan \"Fluffy\": 12_fluffy_cat\n","\n","ğŸ¯ CARA PENGGUNAAN:\n","\n","1. Training dengan nama default (otomatis dari project_name):\n","   quick_test_training(\"Rezcty_project\")\n","   # Akan membuat: 10_rezctyproject_person\n","\n","2. Training dengan custom instance name:\n","   quick_test_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\", repeats=15)\n","   # Akan membuat: 15_rezcty_person\n","\n","3. Training penuh:\n","   start_training(\"Rezcty_project\", instance_name=\"rezcty\", class_name=\"person\")\n","\n","ğŸ’¡ TIPS:\n","- Instance name = trigger word untuk memanggil LoRA\n","- Gunakan nama unik, hindari kata umum\n","- Semakin sedikit gambar â†’ repeats lebih tinggi\n","- 5-10 gambar = 15-20 repeats\n","- 10-20 gambar = 10-15 repeats  \n","- 20+ gambar = 5-10 repeats\n","\n","ğŸ“ STRUKTUR FOLDER AKHIR:\n","/content/drive/MyDrive/AI/training/Rezcty_project/\n","â””â”€â”€ images/\n","    â””â”€â”€ 15_rezcty_person/\n","        â”œâ”€â”€ photo1.jpg\n","        â”œâ”€â”€ photo1.txt (opsional)\n","        â””â”€â”€ ...\n","\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn.functional as F\n","from safetensors.torch import load_file as safe_load\n","from itertools import combinations\n","from collections import Counter\n","import numpy as np\n","from scipy.stats import skew\n","\n","# ==== KONFIGURASI ====\n","input_dir = \"/content/drive/MyDrive/analisis/input/\"\n","output_log = \"/content/drive/MyDrive/analisis/hasil/perbandingan_lanjutan.txt\"\n","os.makedirs(os.path.dirname(output_log), exist_ok=True)\n","\n","# ==== FUNGSI PENDUKUNG ====\n","def load_tensor_file(path):\n","    try:\n","        return safe_load(path)\n","    except Exception as e:\n","        print(f\"âŒ Gagal load {path}: {e}\")\n","        return None\n","\n","def cosine_similarity(t1, t2):\n","    if t1.numel() != t2.numel():\n","        return float('nan')\n","    t1 = t1.flatten()\n","    t2 = t2.flatten()\n","    return F.cosine_similarity(t1.unsqueeze(0), t2.unsqueeze(0)).item()\n","\n","def key_scope(key):\n","    if key.startswith(\"lora_te_text_model_encoder\"):\n","        return \"TextEncoder\"\n","    elif key.startswith(\"lora_unet\"):\n","        return \"UNet\"\n","    else:\n","        return \"Lainnya\"\n","\n","def statistik_distribusi(name, data):\n","    hasil = []\n","    if not data:\n","        return [f\"Tidak ada data untuk {name}\"]\n","\n","    hasil.append(f\"\\nğŸ“ˆ Statistik distribusi {name}:\")\n","    hasil.append(f\" - Mean     : {np.mean(data):.6f}\")\n","    hasil.append(f\" - Median   : {np.median(data):.6f}\")\n","    hasil.append(f\" - Std Dev  : {np.std(data):.6f}\")\n","    hasil.append(f\" - Skewness : {skew(data):.6f}\")\n","    if name == \"CosSim\":\n","        outlier = len([x for x in data if x < 0.7])\n","        hasil.append(f\" - CosSim < 0.7 (low similarity): {outlier}\")\n","    return hasil\n","\n","# ==== ANALISIS PASANGAN ====\n","def analyze_pair(file1, file2):\n","    t1 = load_tensor_file(file1)\n","    t2 = load_tensor_file(file2)\n","\n","    if t1 is None or t2 is None:\n","        return f\"\\nâŒ Gagal memuat file: {file1} atau {file2}\\n\"\n","\n","    keys1 = set(t1.keys())\n","    keys2 = set(t2.keys())\n","\n","    if keys1 != keys2:\n","        return f\"\\nâ— Key mismatch antara:\\n- {os.path.basename(file1)}\\n- {os.path.basename(file2)}\\n\"\n","\n","    total_keys = len(keys1)\n","    identik = 0\n","    beda_rinci = []\n","    cos_sims = []\n","    mses = []\n","    norm_ratios = []\n","    cos_diff_map = []\n","    scope_counter = Counter()\n","    high_norm_keys = []\n","    norm_ratio_map = []\n","\n","    for key in sorted(keys1):\n","        tensor_a = t1[key]\n","        tensor_b = t2[key]\n","\n","        if tensor_a.shape != tensor_b.shape:\n","            continue\n","\n","        if torch.equal(tensor_a, tensor_b):\n","            identik += 1\n","        else:\n","            try:\n","                mse = F.mse_loss(tensor_a, tensor_b).item()\n","                cos_sim = cosine_similarity(tensor_a, tensor_b)\n","                delta_norm = torch.norm(tensor_a - tensor_b).item()\n","                norm_ratio = delta_norm / (torch.norm(tensor_a).item() + 1e-8)\n","\n","                mses.append(mse)\n","                cos_sims.append(cos_sim)\n","                norm_ratios.append(norm_ratio)\n","                cos_diff_map.append((key, cos_sim))\n","                norm_ratio_map.append((key, norm_ratio))\n","\n","                scope = key_scope(key)\n","                scope_counter[scope] += 1\n","\n","                if norm_ratio > 0.05:\n","                    high_norm_keys.append((key, norm_ratio))\n","\n","                beda_rinci.append((key, 'Berbeda', f\"MSE={mse:.6f}\", f\"CosSim={cos_sim:.6f}\"))\n","\n","            except Exception as e:\n","                beda_rinci.append((key, 'Gagal hitung', str(e), 'n/a'))\n","\n","    log = []\n","    log.append(f\"\\nğŸ“Š Perbandingan: {os.path.basename(file1)} <--> {os.path.basename(file2)}\")\n","    log.append(f\"ğŸ”¢ Total key: {total_keys}\")\n","    log.append(f\"âœ… Identik: {identik}\")\n","    log.append(f\"âš ï¸ Berbeda: {len(beda_rinci)}\")\n","\n","    if beda_rinci:\n","        log.append(\"\\nğŸ” Contoh perbedaan (maks 10):\")\n","        for entry in beda_rinci[:10]:\n","            log.append(f\" - {entry[0]} â†’ {entry[1]}, {entry[2]}, {entry[3]}\")\n","\n","    if cos_sims and mses:\n","        log.append(\"\\nğŸ“Š Statistik MSE:\")\n","        log.append(f\" - Rata-rata: {np.mean(mses):.6e}\")\n","        log.append(f\" - Maksimum : {np.max(mses):.6e}\")\n","        log.append(f\" - Minimum : {np.min(mses):.6e}\")\n","\n","        log.append(\"\\nğŸ“Š Statistik Cosine Similarity:\")\n","        log.append(f\" - Rata-rata: {np.mean(cos_sims):.6f}\")\n","        log.append(f\" - Maksimum : {np.max(cos_sims):.6f}\")\n","        log.append(f\" - Minimum : {np.min(cos_sims):.6f}\")\n","\n","    log.extend(statistik_distribusi(\"CosSim\", cos_sims))\n","    log.extend(statistik_distribusi(\"MSE\", mses))\n","\n","    if cos_diff_map:\n","        cos_diff_map.sort(key=lambda x: x[1])\n","        log.append(\"\\nğŸ”¥ 5 Key paling berbeda (CosSim rendah):\")\n","        for key, cs in cos_diff_map[:5]:\n","            log.append(f\" - {key} â†’ CosSim={cs:.6f}\")\n","\n","    if norm_ratio_map:\n","        norm_ratio_map.sort(key=lambda x: x[1], reverse=True)\n","        log.append(f\"\\nğŸ“› Top 5 Key dengan norm delta tertinggi:\")\n","        for k, v in norm_ratio_map[:5]:\n","            log.append(f\" - {k} â†’ NormRatio={v:.6f}\")\n","\n","    if scope_counter:\n","        log.append(\"\\nğŸ§  Distribusi perubahan berdasarkan modul:\")\n","        for scope, count in scope_counter.items():\n","            log.append(f\" - {scope}: {count} perubahan\")\n","\n","    scope_norm_sum = Counter()\n","    for key, ratio in norm_ratio_map:\n","        scope = key_scope(key)\n","        scope_norm_sum[scope] += ratio\n","\n","    if scope_norm_sum:\n","        log.append(\"\\nğŸ“Š Akumulasi perubahan norm delta per modul:\")\n","        for scope, value in scope_norm_sum.items():\n","            log.append(f\" - {scope}: {value:.4f}\")\n","\n","    if high_norm_keys:\n","        log.append(f\"\\nâš ï¸ Key dengan norm delta > 5%: {len(high_norm_keys)}\")\n","        for k, v in high_norm_keys[:5]:\n","            log.append(f\" - {k} â†’ NormDelta={v:.4f}\")\n","\n","    return '\\n'.join(log)\n","\n","# ==== FUNGSI UTAMA ====\n","def bandingkan_semua_file(folder_path, output_file):\n","    files = sorted([f for f in os.listdir(folder_path) if f.endswith('.safetensors')])\n","    full_paths = [os.path.join(folder_path, f) for f in files]\n","\n","    hasil = []\n","    hasil.append(f\"ğŸ“ Total file ditemukan: {len(files)}\\n\")\n","    if len(files) < 2:\n","        hasil.append(\"âŒ Minimal 2 file diperlukan untuk perbandingan.\")\n","    else:\n","        for f1, f2 in combinations(full_paths, 2):\n","            hasil.append(analyze_pair(f1, f2))\n","            hasil.append(\"\\n\" + \"-\" * 80 + \"\\n\")\n","\n","    with open(output_file, 'w') as out_f:\n","        out_f.write('\\n'.join(hasil))\n","\n","    print(f\"âœ… Perbandingan selesai. Hasil disimpan ke:\\n{output_file}\")\n","\n","# ==== EKSEKUSI ====\n","bandingkan_semua_file(input_dir, output_log)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L37XuDkay0zG","executionInfo":{"status":"ok","timestamp":1754390448536,"user_tz":-420,"elapsed":42315,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"71f4b8e1-ba18-4924-fb2e-d5ca135ecadf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Perbandingan selesai. Hasil disimpan ke:\n","/content/drive/MyDrive/analisis/hasil/perbandingan_lanjutan.txt\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rgiiMe7zPQ8","executionInfo":{"status":"ok","timestamp":1754390343236,"user_tz":-420,"elapsed":9588,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"3c3e7984-3a1b-4807-80b3-845bfb404dcd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!rm -rf /content/drive/MyDrive/AI/training/"],"metadata":{"id":"6K-tNM8Bi9G6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install \"numpy <2.0\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":481},"id":"H9DD_3s4ZkHy","executionInfo":{"status":"ok","timestamp":1754383462946,"user_tz":-420,"elapsed":21494,"user":{"displayName":"Ilyas Rizal","userId":"13148396777181863818"}},"outputId":"deba6dbb-e668-4cb9-c142-311dd08aab08"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy<2.0\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"699bdd0789634a4ba24f6a01396b6d8a"}},"metadata":{}}]}]}